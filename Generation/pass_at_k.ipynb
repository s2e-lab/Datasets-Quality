{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Union\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pass_at_k(\n",
    "    num_samples: Union[int, List[int], np.ndarray],\n",
    "    num_correct: Union[List[int], np.ndarray],\n",
    "    k: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Estimates pass@k of each problem and returns them in an array.\n",
    "    \"\"\"\n",
    "\n",
    "    def estimator(n: int, c: int, k: int) -> float:\n",
    "        \"\"\"\n",
    "        Calculates 1 - comb(n - c, k) / comb(n, k).\n",
    "        \"\"\"\n",
    "        if n - c < k:\n",
    "            return 1.0\n",
    "        return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "\n",
    "    if isinstance(num_samples, int):\n",
    "        num_samples_it = itertools.repeat(num_samples, len(num_correct))\n",
    "    else:\n",
    "        assert len(num_samples) == len(num_correct)\n",
    "        num_samples_it = iter(num_samples)\n",
    "\n",
    "    return np.array([estimator(int(n), int(c), k) for n, c in zip(num_samples_it, num_correct)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Output/GPT3.5_Output_Java_1.0_result.jsonl') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['original', 'P13', 'all', 'P8', 'P6', 'P1', 'P15', 'P16'])\n"
     ]
    }
   ],
   "source": [
    "problem_mapping = defaultdict(list)\n",
    "problem_mapping_count = defaultdict(int)\n",
    "for d in data:\n",
    "    id = d['task_id']\n",
    "    splitted = id.split('_')\n",
    "    problem_mapping_count[splitted[0]] += 1\n",
    "    # if len(splitted) == 1:\n",
    "    #     problem_mapping['original'].append(d)\n",
    "    # else:\n",
    "    #     problem_mapping[splitted[1]].append(d)\n",
    "\n",
    "for d in data:\n",
    "    id = d['task_id']\n",
    "    splitted = id.split('_')\n",
    "    if len(splitted) == 1:\n",
    "        problem_mapping['original'].append(d)\n",
    "    else:\n",
    "        problem_mapping[splitted[1]].append(d)\n",
    "        if problem_mapping_count[splitted[0]] == 2:\n",
    "            problem_mapping['all'].append(d)\n",
    "\n",
    "print(problem_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type: original\n",
      "len: 161\n",
      "Pass@1: 0.8760869565217392\n",
      "Pass@3: 0.9449384330391197\n",
      "Pass@10: 0.9612148855317519\n",
      "Problem type: P13\n",
      "len: 161\n",
      "Pass@1: 0.8599378881987577\n",
      "Pass@3: 0.9409502015909338\n",
      "Pass@10: 0.9556892831223158\n",
      "pair len: 161\n",
      "Pass@1: 0.8760869565217391\n",
      "Pass@3: 0.9449384330391195\n",
      "Pass@10: 0.9612148855317519\n",
      "Problem type: all\n",
      "len: 161\n",
      "Pass@1: 0.7127329192546584\n",
      "Pass@3: 0.7613272311212815\n",
      "Pass@10: 0.769873450012096\n",
      "pair len: 161\n",
      "Pass@1: 0.8760869565217392\n",
      "Pass@3: 0.9449384330391195\n",
      "Pass@10: 0.9612148855317519\n",
      "Problem type: P8\n",
      "len: 67\n",
      "Pass@1: 0.5152985074626867\n",
      "Pass@3: 0.5469096823574434\n",
      "Pass@10: 0.5521579409454277\n",
      "pair len: 67\n",
      "Pass@1: 0.8126865671641792\n",
      "Pass@3: 0.9128829536527887\n",
      "Pass@10: 0.9441142702775714\n",
      "Problem type: P6\n",
      "len: 6\n",
      "Pass@1: 0.0\n",
      "Pass@3: 0.0\n",
      "Pass@10: 0.0\n",
      "pair len: 6\n",
      "Pass@1: 0.875\n",
      "Pass@3: 0.975877192982456\n",
      "Pass@10: 0.9999900770024609\n",
      "Problem type: P1\n",
      "len: 21\n",
      "Pass@1: 0.8833333333333332\n",
      "Pass@3: 0.9502506265664159\n",
      "Pass@10: 0.9523809523809523\n",
      "pair len: 21\n",
      "Pass@1: 0.8999999999999999\n",
      "Pass@3: 0.9520050125313284\n",
      "Pass@10: 0.9523809523809523\n",
      "Problem type: P15\n",
      "len: 1\n",
      "Pass@1: 0.0\n",
      "Pass@3: 0.0\n",
      "Pass@10: 0.0\n",
      "pair len: 1\n",
      "Pass@1: 0.0\n",
      "Pass@3: 0.0\n",
      "Pass@10: 0.0\n",
      "Problem type: P16\n",
      "len: 1\n",
      "Pass@1: 0.5499999999999998\n",
      "Pass@3: 0.9263157894736842\n",
      "Pass@10: 1.0\n",
      "pair len: 1\n",
      "Pass@1: 0.75\n",
      "Pass@3: 0.9912280701754386\n",
      "Pass@10: 1.0\n"
     ]
    }
   ],
   "source": [
    "result_data = []\n",
    "for key in problem_mapping.keys():\n",
    "    problems = problem_mapping[key]\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    for d in problems:\n",
    "        for i in range(20):\n",
    "            results[d['task_id']].append(d[f'result_{i}']['passed'])\n",
    "\n",
    "    \n",
    "    total, correct = [], []\n",
    "    for result in results.values():\n",
    "        total.append(len(result))\n",
    "        correct.append(sum(result))\n",
    "    pass_at_1 = estimate_pass_at_k(total, correct, 1)\n",
    "    pass_at_3 = estimate_pass_at_k(total, correct, 3)\n",
    "    pass_at_10 = estimate_pass_at_k(total, correct, 10)\n",
    "    print(f'Problem type: {key}')\n",
    "    print(f'len: {len(total)}')\n",
    "    print(f'Pass@1: {np.mean(pass_at_1)}')\n",
    "    print(f'Pass@3: {np.mean(pass_at_3)}')\n",
    "    print(f'Pass@10: {np.mean(pass_at_10)}')\n",
    "\n",
    "    if key !='original':\n",
    "        pair_results = defaultdict(list)\n",
    "        pair_problems = problem_mapping['original']\n",
    "       \n",
    "        for id in results.keys():\n",
    "            id = id.split('_')[0]\n",
    "            for d in pair_problems:\n",
    "                if d['task_id'] == id:\n",
    "                    for i in range(20):\n",
    "                        pair_results[d['task_id']].append(d[f'result_{i}']['passed'])\n",
    "        \n",
    "        \n",
    "        print(f'pair len: {len(pair_results)}')\n",
    "\n",
    "        total, correct = [], []\n",
    "        for result in pair_results.values():\n",
    "            total.append(len(result))\n",
    "            correct.append(sum(result))\n",
    "        pair_pass_at_1 = estimate_pass_at_k(total, correct, 1)\n",
    "        pair_pass_at_3 = estimate_pass_at_k(total, correct, 3)\n",
    "        pair_pass_at_10 = estimate_pass_at_k(total, correct, 10)\n",
    "        print(f'Pass@1: {np.mean(pair_pass_at_1)}')\n",
    "        print(f'Pass@3: {np.mean(pair_pass_at_3)}')\n",
    "        print(f'Pass@10: {np.mean(pair_pass_at_10)}')\n",
    "        result_data.append(['GPT-3.5','Java',key,len(total), np.mean(pass_at_1), np.mean(pass_at_3), np.mean(pass_at_10), np.mean(pair_pass_at_1), np.mean(pair_pass_at_3), np.mean(pair_pass_at_10)])\n",
    "    else:\n",
    "        result_data.append(['GPT-3.5','Java',key,len(total), np.mean(pass_at_1), np.mean(pass_at_3), np.mean(pass_at_10), 0, 0, 0])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(result_data, columns=['Model','Language','Total', 'Problem Type', 'Pass@1', 'Pass@3', 'Pass@10', 'Pair Pass@1', 'Pair Pass@3', 'Pair Pass@10'])\n",
    "df.to_csv('./Output/GPT3.5_Output_Java_1.0_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pairwise comparison\n",
    "# 2. Fix with 'all'\n",
    "# 3. Keep the completion as it is.\n",
    "# 4. Starcoder\n",
    "# 5. Java\n",
    "# 6. Code clone.\n",
    "# 7. Change the result for rq2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
