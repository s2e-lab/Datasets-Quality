[{"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " cycle(*args, **kwds): Cycles the specified input in perpetuity by default, or for the specified number of times.", "Heuristic": ["H1"]}, {"nl": " How to augument the datapipe by repeating it six times.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " enumerate(*args, **kwds): Adds an index to an existing DataPipe through enumeration, with the index starting from 0 by default.", "Heuristic": ["H1"]}, {"nl": " Assign indexs to the datepipe object.", "Heuristic": ["H1"]}, {"nl": " How to get one training data from the batch_dp", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " demux(datapipe: torch.utils.data.dataset.IterDataPipe, num_instances: int, classifier_fn: Callable[[+T_co], Union[int, NoneType]], drop_none: bool = False, buffer_size: int = 1000): Splits the input DataPipe into multiple child DataPipes, using the given classification function.", "Heuristic": ["H1"]}, {"nl": " Split into 2 sub-datapipes by the odd_or_even function", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " fork(datapipe: torch.utils.data.dataset.IterDataPipe, num_instances: int, buffer_size: int = 1000): Creates multiple instances of the same Iterable DataPipe.", "Heuristic": ["H1"]}, {"nl": " Clone the source datapipe two times", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " zip_with_iter(source_datapipe: IterDataPipe, ref_datapipe: IterDataPipe, key_fn: Callable, ref_key_fn: Optional[Callable] = None, keep_key: bool = False, buffer_size: int = 10000, merge_fn: Optional[Callable] = None): Zips two IterDataPipes together based on the matching key.", "Heuristic": ["H1"]}, {"nl": " Putting two IterDataPipes together based on their key.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " zip_with_map(source_iterdatapipe: IterDataPipe, map_datapipe: MapDataPipe, key_fn: Callable, merge_fn: Optional[Callable] = None): Joins the items from the source IterDataPipe with items from a MapDataPipe.", "Heuristic": ["H1"]}, {"nl": " Attach the elements in the source IterDataPipe to the elements in the MapDataPipe.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " SampleMultiplexer(*args, **kwds): Takes a `Dict` of (IterDataPipe, Weight), and yields items by sampling from these DataPipes with respect to their weights.", "Heuristic": ["H1"]}, {"nl": " Take samples from these DataPipes based on their weights with random seed 0, until all of them are exhausted.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " unzip(source_datapipe: torch.utils.data.dataset.IterDataPipe[typing.Sequence[~T]], sequence_length: int, buffer_size: int = 1000, columns_to_skip: Union[Sequence[int], NoneType] = None): Takes in a DataPipe of Sequences, unpacks each Sequence, and return the elements in separate DataPipes based on their position in the Sequence.", "Heuristic": ["H1"]}, {"nl": " Unzip the three tuples, and return these elements in separate DataPipes, depending on their location.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " batch(datapipe: IterDataPipe, batch_size: int, drop_last: bool = False, wrapper_class=List): Creates mini-batches of data.", "Heuristic": ["H1"]}, {"nl": " bucketbatch(datapipe: torch.utils.data.dataset.IterDataPipe[+T_co], batch_size: int, drop_last: bool = False, batch_num: int = 100, bucket_num: int = 1, sort_key: Union[Callable, NoneType] = None, in_batch_shuffle: bool = True): Creates mini-batches of data from sorted bucket.", "Heuristic": ["H1"]}, {"nl": " Divide datapipes into 3 batches and discard if the last batch is not reached.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " bucketbatch(datapipe: torch.utils.data.dataset.IterDataPipe[+T_co], batch_size: int, drop_last: bool = False, batch_num: int = 100, bucket_num: int = 1, sort_key: Union[Callable, NoneType] = None, in_batch_shuffle: bool = True): Creates mini-batches of data from sorted bucket.", "Heuristic": ["H1"]}, {"nl": " Create batch datapipe with batch size 3, batch num is 100, and drop the last batch if it is not full.", "Heuristic": ["H1"]}, {"nl": " Also, useing the sort_bucket function to sort the bucket, where the bucket_num is 1.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " groupby(datapipe: IterDataPipe[torch.utils.data.datapipes.iter.grouping.T_co], group_key_fn: Callable, *, buffer_size: int = 10000, group_size: Optional[int] = None, guaranteed_group_size: Optional[int] = None, drop_remaining: bool = False): Groups data from input IterDataPipe by keys which are generated from ``group_key_fn``, and yields a ``DataChunk`` with batch size up to ``group_size`` if defined.", "Heuristic": ["H1"]}, {"nl": " Group by file name (except extension), we set the buffer size and group size to 3, and the guaranteed group size to 2.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " HttpReader(source_datapipe: IterDataPipe[str], timeout: Optional[float] = None): Takes file URLs (HTTP URLs pointing to files), and yields tuples of file URL and IO stream.", "Heuristic": ["H1"]}, {"nl": " Using IterableWrapper to the file url and HttpReader to read the file", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " flatmap(*args, **kwds): Applies a function over each item from the source DataPipe, then flattens the outputs to a single, unnested IterDataPipe.", "Heuristic": ["H1"]}, {"nl": " Each item in the source_dp is applied mutiple_fn function and the output is then tiled to a single, unnested one.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " map(datapipe: IterDataPipe, fn: Callable, input_col=None, output_col=None): Applies a function over each item from the source DataPipe.", "Heuristic": ["H1"]}, {"nl": " Method 1", "Heuristic": []}, {"nl": " Invocation via functional form is preferred", "Heuristic": []}, {"nl": " Method 2", "Heuristic": []}, {"nl": " We discourage the usage of `lambda` functions as they are not serializable with `pickle`", "Heuristic": []}, {"nl": " Using `lambda` to implement add_two rather than add_one that is mentioned in above.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " filter(datapipe: IterDataPipe, filter_fn: Callable, drop_empty_batches: bool = True): Filters out elements from the source datapipe according to input ``filter_fn``.", "Heuristic": ["H1"]}, {"nl": " Filtering by the above function", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " header(source_datapipe: IterDataPipe[torchdata.datapipes.iter.util.header.T_co], limit: int = 10): Yields elements from the source DataPipe from the start, up to the specfied limit.", "Heuristic": ["H1"]}, {"nl": " How to get the first three elements of a datapipe?", "Heuristic": ["H1"]}, {"nl": " Each element in a batch is a `Dict`", "Heuristic": []}, {"nl": " Takes an input DataPipe with batches of data, processes the batches one and produces a Dict for each batch.", "Heuristic": []}, {"nl": " We only need the column 'a' from each batch.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " batch(datapipe: MapDataPipe[T], batch_size: int, drop_last: bool = False, wrapper_class=DataChunk): Create mini-batches of data.", "Heuristic": ["H1"]}, {"nl": " Using functional form (recommended)", "Heuristic": []}, {"nl": " Using class constructor", "Heuristic": []}, {"nl": " Get the mapper datapipe (map_dp_1) batch datas with the batch size of 2.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " HttpReader(source_datapipe: IterDataPipe[str], timeout: Optional[float] = None): Takes file URLs (HTTP URLs pointing to files), and yields tuples of file URL and IO stream.", "Heuristic": ["H1"]}, {"nl": " Read the URL using the HTTP protocol and process the csv file.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " map(datapipe: IterDataPipe, fn: Callable, input_col=None, output_col=None): Applies a function over each item from the source DataPipe.", "Heuristic": ["H1"]}, {"nl": " HttpReader(source_datapipe: IterDataPipe[str], timeout: Optional[float] = None): Takes file URLs (HTTP URLs pointing to files), and yields tuples of file URL and IO stream.", "Heuristic": ["H1"]}, {"nl": " Read the URL using the HTTP protocol and process the csv file.", "Heuristic": ["H1"]}, {"nl": " Then, we map the datapipe using lambda_func_ to get what we want.", "Heuristic": ["H1"]}, {"nl": " Read the URL using the HTTP protocol and process the csv file.", "Heuristic": ["H1"]}, {"nl": " Then, we map the datapipe using lambda_func_ to get what we want.", "Heuristic": ["H1"]}, {"nl": " How to get all batches from a datapipe with batch size 2?", "Heuristic": ["H1"]}, {"nl": " Furthermore, the batches should be mapped using lambda_batch.", "Heuristic": []}, {"nl": " Augument the datapipe with repeat three times and sample the data.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " concat(*args, **kwds): Concatenates multiple Iterable DataPipes.", "Heuristic": ["H1"]}, {"nl": " First we concatenate two datapipes and then repeat the concatenated datapipe three times.", "Heuristic": ["H1"]}, {"nl": " According to the merge_fn, we zip the above two datapipes and keep the key True.", "Heuristic": ["H1"]}, {"nl": " Whatsmore, cycle the zipped datapipe three times.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " zip_with_iter(source_datapipe: IterDataPipe, ref_datapipe: IterDataPipe, key_fn: Callable, ref_key_fn: Optional[Callable] = None, keep_key: bool = False, buffer_size: int = 10000, merge_fn: Optional[Callable] = None): Zips two IterDataPipes together based on the matching key.", "Heuristic": ["H1"]}, {"nl": " We zipp the above two data pipes and set keep_key to True according to merge_fn.", "Heuristic": ["H1"]}, {"nl": " Also, enumerating the zipped datapipe.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " zip_with_iter(source_datapipe: IterDataPipe, ref_datapipe: IterDataPipe, key_fn: Callable, ref_key_fn: Optional[Callable] = None, keep_key: bool = False, buffer_size: int = 10000, merge_fn: Optional[Callable] = None): Zips two IterDataPipes together based on the matching key.", "Heuristic": ["H1"]}, {"nl": " Zipping the above two data pipes and set keep_key to True according to merge_fn. ", "Heuristic": ["H1"]}, {"nl": " Moreover, transform its type to List and get the first element.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " zip_with_map(source_iterdatapipe: IterDataPipe, map_datapipe: MapDataPipe, key_fn: Callable, merge_fn: Optional[Callable] = None): Joins the items from the source IterDataPipe with items from a MapDataPipe.", "Heuristic": ["H1"]}, {"nl": " Using merge_fn to zip the two data pipes.", "Heuristic": ["H1"]}, {"nl": " Repeating three times to argument the zipped data pipe.", "Heuristic": []}, {"nl": " Using merge_fn to zip the two data pipes, and repeating three times to argument the zipped data pipe.", "Heuristic": ["H1"]}, {"nl": " Finally, we convert the result type to a list and take the second element of each tuple.", "Heuristic": []}, {"nl": " Using merge_fn to zip the two data pipes, and repeating three times to argument the zipped data pipe, and then sampling the result.", "Heuristic": ["H1"]}, {"nl": " Finally, we convert the result type to a list and take the third element of each tuple.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " groupby(datapipe: IterDataPipe[torch.utils.data.datapipes.iter.grouping.T_co], group_key_fn: Callable, *, buffer_size: int = 10000, group_size: Optional[int] = None, guaranteed_group_size: Optional[int] = None, drop_remaining: bool = False): Groups data from input IterDataPipe by keys which are generated from ``group_key_fn``, and yields a ``DataChunk`` with batch size up to ``group_size`` if defined.", "Heuristic": ["H1"]}, {"nl": " Group the files by their file name using the group_fn function.", "Heuristic": ["H1"]}, {"nl": " Then, reserving the length of group result greater than 1.", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " collate(datapipe: IterDataPipe, collate_fn: Callable = <function default_collate>): Collates samples from DataPipe to Tensor(s) by a custom collate function.", "Heuristic": ["H1"]}, {"nl": " map(datapipe: IterDataPipe, fn: Callable, input_col=None, output_col=None): Applies a function over each item from the source DataPipe.", "Heuristic": ["H1"]}, {"nl": " First get the head 2 elements", "Heuristic": []}, {"nl": " Second make the datapipe tensor-like by using `collate_fn`", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " collate(datapipe: IterDataPipe, collate_fn: Callable = <function default_collate>): Collates samples from DataPipe to Tensor(s) by a custom collate function.", "Heuristic": ["H1"]}, {"nl": " filter(datapipe: IterDataPipe, filter_fn: Callable, drop_empty_batches: bool = True): Filters out elements from the source datapipe according to input ``filter_fn``.", "Heuristic": ["H1"]}, {"nl": " Filter the value smaller than 5", "Heuristic": []}, {"nl": " Second make the datapipe tensor-like by using `collate_fn`", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " demux(datapipe: torch.utils.data.dataset.IterDataPipe, num_instances: int, classifier_fn: Callable[[+T_co], Union[int, NoneType]], drop_none: bool = False, buffer_size: int = 1000): Splits the input DataPipe into multiple child DataPipes, using the given classification function.", "Heuristic": ["H1"]}, {"nl": " Split the source datapipe into two datapipes by applying the function `great_than_5`", "Heuristic": ["H1"]}, {"nl": " Given the weight, how to sample from two datapipes?", "Heuristic": ["H1"]}, {"nl": " Note that the sample seed is set to 1 for reproducibility", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " map(datapipe: IterDataPipe, fn: Callable, input_col=None, output_col=None): Applies a function over each item from the source DataPipe.", "Heuristic": ["H1"]}, {"nl": " unzip(source_datapipe: torch.utils.data.dataset.IterDataPipe[typing.Sequence[~T]], sequence_length: int, buffer_size: int = 1000, columns_to_skip: Union[Sequence[int], NoneType] = None): Takes in a DataPipe of Sequences, unpacks each Sequence, and return the elements in separate DataPipes based on their position in the Sequence.", "Heuristic": ["H1"]}, {"nl": " I would like assgin dp1 to be a datapipe that contains the first column of raw_dp", "Heuristic": ["H1"]}, {"nl": " and dp2 to be a datapipe that contains the second column of raw_dp", "Heuristic": ["H1"]}, {"nl": " and dp3 to be a datapipe that contains the third column of raw_dp", "Heuristic": ["H1"]}, {"nl": " How to do this?", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " batch(datapipe: IterDataPipe, batch_size: int, drop_last: bool = False, wrapper_class=List): Creates mini-batches of data.", "Heuristic": ["H1"]}, {"nl": " Make a batch operation on the datapipe `dp` of size 3 with droping last batch if it is not full.", "Heuristic": ["H1"]}, {"nl": " And then get the first two batches.", "Heuristic": []}, {"nl": " Batch on data pipe `dp1` of size 4 and discard the last batch if they are not filled, and then obtain the first two batches.", "Heuristic": []}, {"nl": " Then the above result is concatenated with the datapipe `dp2`.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " concat(*args, **kwds): Concatenates multiple Iterable DataPipes.", "Heuristic": ["H1"]}, {"nl": " add_index(*args, **kwds): Adds an index to an existing Iterable DataPipe with.", "Heuristic": ["H1"]}, {"nl": " Concatenate two datapipes and add corresponding indices with the name `Ids`.", "Heuristic": ["H1"]}, {"nl": " Join the two data pipes and add an index with the name `Ids`.", "Heuristic": []}, {"nl": " Then create three copies of the datapipe.", "Heuristic": ["H1"]}, {"nl": " Join the three data pipes and obtain the enumerated datapipe.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " flatmap(*args, **kwds): Applies a function over each item from the source DataPipe, then flattens the outputs to a single, unnested IterDataPipe.", "Heuristic": ["H1"]}, {"nl": " I want to augment the source datapipe with the above function, which will return nine elements.", "Heuristic": ["H1"]}, {"nl": " Then we flatten the nine elements into a single datapipe.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " HttpReader(source_datapipe: IterDataPipe[str], timeout: Optional[float] = None): Takes file URLs (HTTP URLs pointing to files), and yields tuples of file URL and IO stream.", "Heuristic": ["H1"]}, {"nl": " Read the URL using the HTTP protocol and parse the csv file as a dictionary.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " concat(*args, **kwds): Concatenate multiple Map DataPipes.", "Heuristic": ["H1"]}, {"nl": " concat two datapipes", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " mux(*datapipes): Yields one element at a time from each of the input Iterable DataPipes.", "Heuristic": ["H1"]}, {"nl": " One element is generated from each input Iterable DataPipes in turn, until the end when the shortest input DataPipe is used up.", "Heuristic": []}, {"nl": " convert integer to float Tensor using `int2tensor`.", "Heuristic": ["H1"]}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " unbatch(datapipe: IterDataPipe, unbatch_level: int = 1): Undoes batching of data.", "Heuristic": ["H1"]}, {"nl": " Does the unbatch processing of data, the level is setted by default to 1.", "Heuristic": ["H1"]}, {"nl": " generating bytes where the chunk is set to one.", "Heuristic": ["H1"]}, {"nl": " Put the above DataPipes into one list obj, and remove the last number from each element (e.g., \"1\" in \"dog1\")", "Heuristic": []}, {"nl": " Please use the following APIs to solve the task:", "Heuristic": []}, {"nl": " groupby(datapipe: IterDataPipe[torch.utils.data.datapipes.iter.grouping.T_co], group_key_fn: Callable, *, buffer_size: int = 10000, group_size: Optional[int] = None, guaranteed_group_size: Optional[int] = None, drop_remaining: bool = False): Groups data from input IterDataPipe by keys which are generated from ``group_key_fn``, and yields a ``DataChunk`` with batch size up to ``group_size`` if defined.", "Heuristic": ["H1"]}, {"nl": " header(source_datapipe: IterDataPipe[torchdata.datapipes.iter.util.header.T_co], limit: int = 10): Yields elements from the source DataPipe from the start, up to the specfied limit.", "Heuristic": ["H1"]}, {"nl": " group by source_dp using the ``group_fn`` function and obtain the header groups by default, assign the result to the new variable ``header_groups``.", "Heuristic": ["H1"]}]