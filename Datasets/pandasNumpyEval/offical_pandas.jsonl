{"task_id": "PandasEval/0", "prompt": "import pandas as pd\nimport numpy as np\n\ndef drop_rows_col_nan(df, col_name):\n    # How to drop rows of Pandas DataFrame whose value in a certain column is NaN\n    return ", "entry_point": "drop_rows_col_nan", "canonical_solution": ["df.dropna(subset=[col_name])"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'drapna'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame([[1,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[1,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n    assert candidate(pd.DataFrame([[5,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,3],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n    assert candidate(pd.DataFrame([[5,2,1],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[np.nan,2,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n    assert candidate(pd.DataFrame([[5,2,1],[np.nan,3,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[np.nan,3,3],[1,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n    assert candidate(pd.DataFrame([[5,2,1],[np.nan,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[np.nan,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n    assert candidate(pd.DataFrame([[5,2,1],[3,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[3,3,3],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'B').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['B']))\n    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'C').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['C']))\n    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']), 'A').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[1,2,np.nan]], columns=['A','B','C']).dropna(subset=['A']))\n    assert candidate(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[np.nan,2,np.nan]], columns=['A','B','C']), 'A').equals(pd.DataFrame([[5,2,1],[3,3,np.nan],[np.nan,np.nan,3],[np.nan,2,np.nan]], columns=['A','B','C']).dropna(subset=['A']))\n\n\n"}
{"task_id": "PandasEval/1", "prompt": "import pandas as pd\nimport numpy as np\n\ndef replacing_blank_with_nan(df):\n    # replace field that's entirely space (or empty) with NaN using regex\n    # return the result\n", "entry_point": "replacing_blank_with_nan", "canonical_solution": ["    return df.replace(r'^\\s*$', np.nan, regex=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'replace'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [1.0, 2.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [1.0, 2.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [1.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [1.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [4.0, 15.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [4.0, 15.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, 4.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 4.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [4.0, 15.0, 16.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [4.0, 15.0, 16.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [14.0, 15.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [14.0, 15.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [21.0, 12.0, ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [21.0, 12.0, np.nan], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, 2.0, ' '], 'b': [24.0, 25.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, 2.0, np.nan], 'b': [24.0, 25.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [2.0, ' ', ' '], 'b': [4.0, 5.0, 6.0]})).astype(np.float).equals(pd.DataFrame({'a': [2.0, np.nan , np.nan], 'b': [4.0, 5.0, 6.0]}))\n\n"}
{"task_id": "PandasEval/2", "prompt": "import pandas as pd\n\ndata = pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})\n# How do I change the column labels of a pandas DataFrame from ['A', 'B', 'C'] to ['a', 'b', 'c']?\ndata.columns = ", "entry_point": "none", "canonical_solution": ["['a', 'b', 'c']"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': '_'\n}\n\n\ndef check():\n    assert data.equals(pd.DataFrame({'a':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n\n\n"}
{"task_id": "PandasEval/3", "prompt": "import pandas as pd\n\ndef add_zeros_to_string(df, col_name):\n    # Add Leading Zeros to Strings at `col_name` in Pandas Dataframe\n    # The maximum length of the string is 15\n    # Return the dataframe\n", "entry_point": "add_zeros_to_string", "canonical_solution": ["    df[col_name] = df[col_name].apply(lambda x: '{0:0>15}'.format(x))\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'round'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1234556,3456], 'B': [\"abc\", \"def\"]}), \"A\").equals(pd.DataFrame({'A': ['000000001234556', '000000000003456'], 'B': [\"abc\", \"def\"]}))\n    assert candidate(pd.DataFrame({'A': [1234556,3456], 'B': ['abc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234556', '000000000003456'], 'B': ['abc', 'ddd']}))\n    assert candidate(pd.DataFrame({'A': [1234556,3456], 'B': ['rsc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234556', '000000000003456'], 'B': ['rsc', 'ddd']}))\n    assert candidate(pd.DataFrame({'A': [1234556,34561], 'B': ['rsc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234556', '000000000034561'], 'B': ['rsc', 'ddd']}))\n    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['rsc', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['rsc', 'ddd']}))\n    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['aaa', 'ddd']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['aaa', 'ddd']}))\n    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['aaa', 'cas']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['aaa', 'cas']}))\n    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['csd', 'cas']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['csd', 'cas']}))\n    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['rrr', 'cas']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['rrr', 'cas']}))\n    assert candidate(pd.DataFrame({'A': [1234553,34561], 'B': ['rrr', 'ras']}), 'A').equals(pd.DataFrame({'A': ['000000001234553', '000000000034561'], 'B': ['rrr', 'ras']}))\n\n\n"}
{"task_id": "PandasEval/4", "prompt": "import pandas as pd\n\ndef get_data_frame_from_list(list_of_lists):\n    # list_of_lists format: [header, [row1], [row2], ...]\n    # header format: [column1, column2, ...]\n    # row format: [value1, value2, ...]\n    # How to convert list to dataframe?\n    # Return the dataframe\n", "entry_point": "get_data_frame_from_list", "canonical_solution": ["    return pd.DataFrame(list_of_lists[1:], columns=list_of_lists[0])"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'DataFrame'\n}\n\n\ndef check(candidate):\n    assert candidate([['Heading1', 'Heading2'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading1', 'Heading2']))\n    assert candidate([['Heading1', 'Heading3'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading1', 'Heading3']))\n    assert candidate([['Heading2', 'Heading3'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading2', 'Heading3']))\n    assert candidate([['Heading2', 'Heading3'], [2 , 2], [3, 4]]).equals(pd.DataFrame([[2, 2], [3, 4]], columns=['Heading2', 'Heading3']))\n    assert candidate([['Heading5', 'Heading3'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading5', 'Heading3']))\n    assert candidate([['Heading2', 'Heading9'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading2', 'Heading9']))\n    assert candidate([['Heading2', 'Heading3'], [11 , 12], [3, 4]]).equals(pd.DataFrame([[11, 12], [3, 4]], columns=['Heading2', 'Heading3']))\n    assert candidate([['Heading22', 'Heading32'], [1 , 2], [3, 4]]).equals(pd.DataFrame([[1, 2], [3, 4]], columns=['Heading22', 'Heading32']))\n    assert candidate([['Heading2', 'Heading3'], [14 , 42], [3, 4]]).equals(pd.DataFrame([[14, 42], [3, 4]], columns=['Heading2', 'Heading3']))\n    assert candidate([['Heading2', 'Heading3'], [1 , 23], [33, 4]]).equals(pd.DataFrame([[1, 23], [33, 4]], columns=['Heading2', 'Heading3']))\n\n"}
{"task_id": "PandasEval/5", "prompt": "import pandas as pd\n\ndef make_df_all_cols_lower(data):\n    # I want to make all column headers in my pandas data frame lower case\n    # Return the changed dataframe\n    ", "entry_point": "make_df_all_cols_lower", "canonical_solution": ["data.columns = map(str.lower, data.columns)\n    return data", "data.columns = [x.lower() for x in data.columns]\n    return data"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'lower'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'a':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n    assert candidate(pd.DataFrame({'A':range(3), 'D':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'a':range(3), 'd':range(3,0,-1), 'c':list('abc')}))\n    assert candidate(pd.DataFrame({'T':range(3), 'D':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'t':range(3), 'd':range(3,0,-1), 'c':list('abc')}))\n    assert candidate(pd.DataFrame({'T':range(3), 'Y':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'t':range(3), 'y':range(3,0,-1), 'c':list('abc')}))\n    assert candidate(pd.DataFrame({'T':range(3), 'Y':range(3,0,-1), 'i':list('abc')})).equals(pd.DataFrame({'t':range(3), 'y':range(3,0,-1), 'i':list('abc')}))\n    assert candidate(pd.DataFrame({'T':range(3), 'Y':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'t':range(3), 'y':range(3,0,-1), 'l':list('abc')}))\n    assert candidate(pd.DataFrame({'k':range(3), 'Y':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'k':range(3), 'y':range(3,0,-1), 'l':list('abc')}))\n    assert candidate(pd.DataFrame({'k':range(3), 'J':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'k':range(3), 'j':range(3,0,-1), 'l':list('abc')}))\n    assert candidate(pd.DataFrame({'W':range(3), 'J':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'w':range(3), 'j':range(3,0,-1), 'l':list('abc')}))\n    assert candidate(pd.DataFrame({'W':range(3), 'A':range(3,0,-1), 'L':list('abc')})).equals(pd.DataFrame({'w':range(3), 'a':range(3,0,-1), 'l':list('abc')}))\n\n"}
{"task_id": "PandasEval/6", "prompt": "import pandas as pd\nimport numpy as np\n\nmy_df = pd.DataFrame({'col1': [1,2,3], 'col2': [1.0,2.0,3.0]})\n# I need to change the dtype of multiple columns but the dataframe has different kind of dtypes. \n# Some columns dtypes are float64 whereas some columns are int64\n# I need to change all float64 to float32.\ncols =", "entry_point": "none", "canonical_solution": [" my_df.select_dtypes(include=['float64']).columns\nmy_df[cols] = my_df[cols].astype(np.float32)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'astype'\n}\n\n\ndef check():\n    assert my_df.equals(pd.DataFrame({'col1': [1,2,3], 'col2': [np.float32(1.0),np.float32(2.0),np.float32(3.0)]}))\n\n\n"}
{"task_id": "PandasEval/7", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({\n'date': [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"friday\"],\n'value': [1, 2, 3, 4]\n})\n\n# transfer column date to datetime type\n# when there is a string that is not capable of beeing turned into datetime format, skip that row,\n# use errors='coerce' for this\ndf['date'] =", "entry_point": "none", "canonical_solution": [" pd.to_datetime(df['date'], errors='coerce')"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'to_datetime'\n}\n\n\ndef check():\n    tmp = pd.DataFrame({'date': [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"friday\"],'value': [1, 2, 3, 4]})\n    tmp['date'] = pd.to_datetime(tmp['date'], errors='coerce')\n    df.equals(tmp)\n\n\n"}
{"task_id": "PandasEval/8", "prompt": "import pandas as pd\ndf = pd.DataFrame({'col1': [1,2,3], 'col2': ['Jimmy','Tom','Jimmy']})\n# I have a dataframe that has two columns, the second column is one of only a few values. \n# I want to return a dataframe where only the rows where that col2 had a specific value 'Jimmy' are included.\nnew_df =", "entry_point": "none", "canonical_solution": [" df[df.iloc[:, 1] == 'Jimmy']"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'iloc'\n}\n\n\ndef check():\n    assert new_df.equals(pd.DataFrame({'col1': [1, 3], 'col2': ['Jimmy', 'Jimmy']}, index=[0, 2]))\n\n\n"}
{"task_id": "PandasEval/9", "prompt": "import pandas as pd\n\ndef extract_first_and_last_df(df):\n    # Extract first and last row of a dataframe in pandas\n    # Return the dataframe with the first and last row\n", "entry_point": "extract_first_and_last_df", "canonical_solution": ["    return df.iloc[[0, -1]]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'iloc'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [1, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [12, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [12, 2], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [1, 3, 23], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 23], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [1, 33, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [1, 23, 2], 'b': [4, 43, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [123, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [123, 2], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [1, 3, 2], 'b': [4, 344, 2]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [1, 3, 342], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 342], 'b': [4, 2]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [1, 3, 2], 'b': [4, 4, 234]})).equals(pd.DataFrame({'a': [1, 2], 'b': [4, 234]}, index=[0, 2]))\n    assert candidate(pd.DataFrame({'a': [1, 3, 223], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [1, 223], 'b': [4, 2]}, index=[0, 2]))\n\n\n"}
{"task_id": "PandasEval/10", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'Sp': ['MM1', 'MM1', 'MM1', 'MM2', 'MM2', 'MM2', 'MM4', 'MM4', 'MM4'],\n                   'Mt': ['S1', 'S1', 'S3', 'S3', 'S4', 'S4', 'S2', 'S2', 'S2'],\n                   'Value': ['a', 'n', 'cb', 'mk', 'bg', 'dgd', 'rd', 'cb', 'uyi'],\n                   'num': [3, 2, 5, 8, 10, 1, 2, 2, 7]})\n\n# How do I find all rows in a pandas DataFrame which have the max value for 'num' column, after grouping by 'Mt' column?\nnew_df =", "entry_point": "none", "canonical_solution": [" df.groupby('Mt').apply(lambda x: x.loc[x.num == x.num.max()])"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'groupby_loc_max'\n}\n\n\ndef check():\n    assert new_df.equals(df.groupby('Mt').apply(lambda x: x.loc[x.num == x.num.max()]))\n\n\n"}
{"task_id": "PandasEval/11", "prompt": "import pandas as pd\n\ndef select_rows_from_column(df, col_name, values):\n    # How do I select rows from a DataFrame df based on column values?\n    # Return rows whose column value named `col_name` is in an iterable `values`\n", "entry_point": "select_rows_from_column", "canonical_solution": ["    return df[df[col_name].isin(values)]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'isin'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]}), 'c1', [11, 12]).equals(pd.DataFrame({'c1': [11, 12], 'c2': [110, 120]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [110]}, index=[1]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]}), 'c1', [12]).equals(pd.DataFrame({'c1': [12], 'c2': [120]}, index=[2]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 122]}), 'c1', [12]).equals(pd.DataFrame({'c1': [12], 'c2': [122]}, index=[2]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 238]}), 'c1', [12]).equals(pd.DataFrame({'c1': [12], 'c2': [238]}, index=[2]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 1100, 238]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [1100]}, index=[1]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 1800, 238]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [1800]}, index=[1]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 521, 238]}), 'c1', [11]).equals(pd.DataFrame({'c1': [11], 'c2': [521]}, index=[1]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 521, 238]}), 'c1', [10]).equals(pd.DataFrame({'c1': [10], 'c2': [100]}, index=[0]))\n    assert candidate(pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 521, 238]}), 'c1', [10, 12]).equals(pd.DataFrame({'c1': [10, 12], 'c2': [100, 238]}, index=[0, 2]))\n\n"}
{"task_id": "PandasEval/12", "prompt": "import pandas as pd\n\ndef get_row_count(df):\n    \"\"\"\n    Return the row count of df\n    \"\"\"\n", "entry_point": "get_row_count", "canonical_solution": ["    return len(df.index)", "    return df.shape[0]", "    return df[df.columns[0]].count()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'shape'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [1, 2, 3, 4], 'b': [4, 5, 6, 7]})) == 4\n    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})) == 3\n    assert candidate(pd.DataFrame({'a': [1, 2, 5], 'b': [8, 5, 6]})) == 3\n    assert candidate(pd.DataFrame({'a': [125, 2, 5], 'b': [683, 5, 6]})) == 3\n    assert candidate(pd.DataFrame({'a': [125, 2], 'b': [5, 6]})) == 2\n    assert candidate(pd.DataFrame({'a': [125, 5], 'b': [182, 513]})) == 2\n    assert candidate(pd.DataFrame({'a': [125], 'b': [513]})) == 1\n    assert candidate(pd.DataFrame({'a': [125, 1, 2, 3, 4], 'b': [513, 0, 0, 0, 0]})) == 5\n    assert candidate(pd.DataFrame({'a': [125, 1, 2, 3, 4, 6], 'b': [513, 0, 0, 0, 0, 1]})) == 6\n    assert candidate(pd.DataFrame({'a': [125, 1, 2, 3, 4, 6, 7], 'b': [513, 0, 0, 0, 0, 1, 2]})) == 7\n\n"}
{"task_id": "PandasEval/13", "prompt": "import pandas as pd\n\ndef create_empty_df(col_names):\n    # Pandas create empty DataFrame with only column names\n    # Return: DataFrame\n", "entry_point": "create_empty_df", "canonical_solution": ["    return pd.DataFrame(columns=col_names)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'DataFrame'\n}\n\n\ndef check(candidate):\n    assert candidate(['A', 'B', 'C']).equals(pd.DataFrame(columns=['A', 'B', 'C']))\n    assert candidate(['A', 'd', 'C']).equals(pd.DataFrame(columns=['A', 'd', 'C']))\n    assert candidate(['A', 'B', 'E']).equals(pd.DataFrame(columns=['A', 'B', 'E']))\n    assert candidate(['A', 'Q', 'C']).equals(pd.DataFrame(columns=['A', 'Q', 'C']))\n    assert candidate(['X', 'B', 'C']).equals(pd.DataFrame(columns=['X', 'B', 'C']))\n    assert candidate(['A', 'B', 'N']).equals(pd.DataFrame(columns=['A', 'B', 'N']))\n    assert candidate(['A', 'G', 'C']).equals(pd.DataFrame(columns=['A', 'G', 'C']))\n    assert candidate(['T', 'B', 'C']).equals(pd.DataFrame(columns=['T', 'B', 'C']))\n    assert candidate(['A', 'S', 'C']).equals(pd.DataFrame(columns=['A', 'S', 'C']))\n    assert candidate(['A', 'B', 'V']).equals(pd.DataFrame(columns=['A', 'B', 'V']))\n\n\n"}
{"task_id": "PandasEval/14", "prompt": "import pandas as pd\n\ndef f(x):\n    a = x['Value'].iat[2] - x['Value'].iat[1]\n    b = x['Value'].iat[3] - x['Value'].iat[0]\n    c = x['ID'].iat[2] + ' - ' + x['ID'].iat[1]\n    d = x['ID'].iat[3] + ' - ' + x['ID'].iat[0]\n    return pd.DataFrame({'Value': [a,b], 'ID':[c,d]})\n\ndef calculate_row_diff_groupwise(df):\n    # I need to calculate the difference between two rows groupwise using pandas.\n    # To calculate the sum I would use pandas.groupby('Group').sum(), but how do you calculate the difference between rows where the row ordering is important?\n    # I think we need custom function with apply which return DataFrame for each group, for select by position is used iat:\n    # Return the result\n", "entry_point": "calculate_row_diff_groupwise", "canonical_solution": ["    return df.groupby('Group').apply(f).reset_index(level=1, drop=True).reset_index()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'groupby_apply_reset_index'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 5, 4], 'ID': ['dki', 'two', 'three', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [2, 1], 'ID': ['three - two', 'msra - dki']}))\n    assert candidate(pd.DataFrame({'Group': ['Tom', 'Tom', 'Tom', 'Tom'], 'Value': [3, 3, 5, 4], 'ID': ['pku', 'dki', 'msra', 'thu']})).equals(pd.DataFrame({'Group': ['Tom', 'Tom'], 'Value': [2, 1], 'ID': ['msra - dki', 'thu - pku']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'two', 'three', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['three - two', 'msra - dki']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'four', 'three', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['three - four', 'msra - dki']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'four', 'five', 'msra']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['five - four', 'msra - dki']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['dki', 'four', 'five', 'ucas']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['five - four', 'ucas - dki']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 4], 'ID': ['iscas', 'four', 'five', 'ucas']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 1], 'ID': ['five - four', 'ucas - iscas']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 5], 'ID': ['iscas', 'four', 'five', 'ucas']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 2], 'ID': ['five - four', 'ucas - iscas']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 5], 'ID': ['iscas', 'four', 'five', 'PKU']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 2], 'ID': ['five - four', 'PKU - iscas']}))\n    assert candidate(pd.DataFrame({'Group': ['M1', 'M1', 'M1', 'M1'], 'Value': [3, 3, 6, 5], 'ID': ['thu', 'four', 'five', 'PKU']})).equals(pd.DataFrame({'Group': ['M1', 'M1'], 'Value': [3, 2], 'ID': ['five - four', 'PKU - thu']}))\n\n\n"}
{"task_id": "PandasEval/15", "prompt": "import pandas as pd\nimport numpy as np\n\ndef if_any_value_is_nan(df):\n    # How to check if any value is NaN in a Pandas DataFrame? Return the result.\n    ", "entry_point": "if_any_value_is_nan", "canonical_solution": ["return df.isnull().values.any()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'isnull_value_any'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [np.nan, 2, 3], 'B': [1, 2, 3], 'C': [1, 2, 3]})) == True\n    assert candidate(pd.DataFrame({'A': [np.nan, np.nan, 3], 'B': [1, 2, 3], 'C': [1, 2, 3]})) == True\n    assert candidate(pd.DataFrame({'A': [np.nan, np.nan, 3], 'B': [1, np.nan, 3], 'C': [1, 2, 3]})) == True\n    assert candidate(pd.DataFrame({'A': [np.nan, np.nan, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 3]})) == True\n    assert candidate(pd.DataFrame({'A': [7, 6, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 3]})) == True\n    assert candidate(pd.DataFrame({'A': [7, 8, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 18]})) == True\n    assert candidate(pd.DataFrame({'A': [7, 6, 3], 'B': [1, np.nan, 8], 'C': [1, 2, 18]})) == True\n    assert candidate(pd.DataFrame({'A': [7, 8, 3], 'B': [1, 8, 8], 'C': [1, 2, 18]})) == False\n    assert candidate(pd.DataFrame({'A': [7, 8, 3], 'B': [81, 5, 8], 'C': [1, 2, 18]})) == False\n    assert candidate(pd.DataFrame({'A': [7, 94, 3], 'B': [81, 5, 8], 'C': [1, 2, 18]})) == False\n\n"}
{"task_id": "PandasEval/16", "prompt": "import pandas as pd\n\ndef add_column_to_dataframe(df, column_name, column_data):\n    # How to add a new column to an existing DataFrame?\n    # I would like to add a new column data with the column name, to the existing dataframe\n", "entry_point": "add_column_to_dataframe", "canonical_solution": ["    df[column_name] = column_data\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'add_column'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}), 'e', [10, 11, 12]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9], 'e': [10, 11, 12]}))\n    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}), 'd', [10, 11, 12]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9], 'd': [10, 11, 12]}))\n    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'd', [10, 11, 12]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'd': [10, 11, 12]}))\n    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'd', [5, 2, 1]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'd': [5, 2, 1]}))\n    assert candidate(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'h', [5, 2, 1]).equals(pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'h': [5, 2, 1]}))\n    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9]}), 'h', [5, 2, 1]).equals(pd.DataFrame({'g': [1, 2, 3], 'b': [4, 5, 6], 'f': [7, 8, 9], 'h': [5, 2, 1]}))\n    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 8, 9]}), 'h', [5, 2, 1]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 8, 9], 'h': [5, 2, 1]}))\n    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6]}), 'h', [5, 6, 6]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6], 'h': [5, 6, 6]}))\n    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6]}), 'h', [5, 8, 8]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [4, 5, 6], 'f': [7, 6, 6], 'h': [5, 8, 8]}))\n    assert candidate(pd.DataFrame({'g': [1, 2, 3], 'r': [6, 6, 6], 'f': [7, 6, 6]}), 'h', [5, 8, 8]).equals(pd.DataFrame({'g': [1, 2, 3], 'r': [6, 6, 6], 'f': [7, 6, 6], 'h': [5, 8, 8]}))\n\n"}
{"task_id": "PandasEval/17", "prompt": "import pandas as pd\n\ndef remove_duplicates_by_column(df, col1, col2):\n    # I have a dataframe with repeat values in column `col1`. I want to drop duplicates, keeping the row with the last value in column `col2`.\n    # How would I do that?\n    # return the final dataframe\n", "entry_point": "remove_duplicates_by_column", "canonical_solution": ["    return df.drop_duplicates(subset=col1, keep=\"last\")"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'drop_duplicates'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [100, 300, 500]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [300, 500]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [100, 350, 500]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 500]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [100, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [120, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [531, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [123, 350, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [350, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [123, 125, 600]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [123, 125, 532]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 532]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [74, 125, 532]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 532]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [1, 1, 3], 'B': [74, 125, 45]}), 'A', 'B').equals(pd.DataFrame({'A': [1, 3], 'B': [125, 45]}, index=[1, 2]))\n\n\n"}
{"task_id": "PandasEval/18", "prompt": "import pandas as pd\n\ndef get_values_at_nth_rows(df, n, column_name):\n    \"\"\"\n    how do I get the value at an nth row of a given column name in Pandas?\n    return the value\n    \"\"\"\n", "entry_point": "get_values_at_nth_rows", "canonical_solution": ["    return df[column_name].iloc[n]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'tail'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 0, 'A') == 1\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 1, 'A') == 2\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 2, 'A') == 3\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 2, 'B') == 500\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 1, 'B') == 300\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 0, 'B') == 100\n    assert candidate(pd.DataFrame({'A': [5, 2, 3], 'B': [100, 300, 500]}), 0, 'B') == 100\n    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [100, 300, 500]}), 0, 'B') == 100\n    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 500]}), 0, 'B') == 500\n    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 100]}), 0, 'B') == 500\n\n\n"}
{"task_id": "PandasEval/19", "prompt": "import pandas as pd\ndef creating_df_with_same_as_other(df_original):\n    # creating a new dataframe of all same with df_original one, but no any rows\n    # return the new dataframe\n    ", "entry_point": "creating_df_with_same_as_other", "canonical_solution": ["    df_copy = df_original.iloc[:0,:].copy()\n    return df_copy"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'tail'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [1, 0, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [1, 0, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [5, 0, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [5, 0, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [5, 2, 3], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [5, 2, 3], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [100, 300, 500]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [100, 300, 500]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 500]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 300, 500]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 500]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 500]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 100]})).equals(pd.DataFrame({'A': [5, 2, 1], 'B': [500, 200, 100]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [5, 20, 1], 'B': [500, 200, 100]})).equals(pd.DataFrame({'A': [5, 20, 1], 'B': [500, 200, 100]}).iloc[:0,:].copy())\n    assert candidate(pd.DataFrame({'A': [50, 20, 1], 'B': [500, 200, 100]})).equals(pd.DataFrame({'A': [50, 20, 1], 'B': [500, 200, 100]}).iloc[:0,:].copy())\n\n\n"}
{"task_id": "PandasEval/20", "prompt": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'A':[1,4], 'B':[np.nan,301]})\n# # counting the number of missing/NaN in each column\n# Get a series with the number of missing/NaN in each column\ncount_series =", "entry_point": "none", "canonical_solution": [" df.isnull().sum()", " df.isnull().sum(axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'isnull_sum'\n}\n\n\ndef check():\n    assert count_series.equals(pd.Series([0, 1], index=['A', 'B']))\n\n\n"}
{"task_id": "PandasEval/21", "prompt": "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'a': [4, 1, 7, 3], 'b': [5, 2, 9, 6], 'c': [6, 3, 2, 8]})\n# I would like to create new dataframe out of the old one in a way that there will only be values that exceed the mean value of the column. \n# We can compare values and then add NaNs by indexing or `where`\n# We want remove NaNs also in first rows add custom function with `dropna`\ndf = ", "entry_point": "none", "canonical_solution": ["df[df>df.mean()].apply(lambda x: pd.Series(x.dropna().values))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'mean_apply'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'a': [4.0, 7.0], 'b': [9.0, 6.0], 'c': [6.0, 8.0]}))\n\n\n"}
{"task_id": "PandasEval/22", "prompt": "import pandas as pd\n\ndef normalize(df):\n    # Normalization using pandas\n    # We simply subtract the mean and divide by standard deviation on df.iloc[:,0,-1] obj with axis is zero.\n    # Return the normalized dataframe\n    ", "entry_point": "normalize", "canonical_solution": ["df.iloc[:,0:-1] = df.iloc[:,0:-1].apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n    return df", "func_ = lambda x: (x-x.mean()) / x.std()\n    df.iloc[:,0:-1] = df.iloc[:,0:-1].apply(func_, axis=0)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'iloc_apply_lambda_mean_std'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'C':list('abc')}))\n    assert candidate(pd.DataFrame({'M':[1,2,3], 'S':[100,300,500], 'R':list('zan')})).equals(pd.DataFrame({'M':[-1.0,0.0,1.0],'S':[-1.0, 0.0, 1.0],'R':list('zan')}))\n    assert candidate(pd.DataFrame({'U':[2,4,6], 'C':[100,300,500], 'S':list('yao')})).equals(pd.DataFrame({'U':[-1.0, 0.0, 1.0], 'C':[-1.0, 0.0, 1.0], 'S':list('yao')}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('bbc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'C':list('bbc')}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('bbb')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'C':list('bbb')}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'D':list('bbb')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'D':list('bbb')}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,200,300], 'D':list('bbb')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'D':list('bbb')}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,200,300], 'e':list('cdf')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'e':list('cdf')}))\n    assert candidate(pd.DataFrame({'A':[3,4,5], 'B':[300,400,500], 'e':list('cdf')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'e':list('cdf')}))\n    assert candidate(pd.DataFrame({'A':[3,4,5], 'B':[300,400,500], 'R':list('abc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'R':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[3,4,5], 'B':[300,400,500], 'P':list('abc')})).equals(pd.DataFrame({'A':[-1.0,0.0,1.0],'B':[-1.0,0.0,1.0],'P':list('abc')}))\n\n"}
{"task_id": "PandasEval/23", "prompt": "import pandas as pd\nimport numpy as np\n\ndef find_columns_name_lists(df):\n    # How do I determine which columns contain NaN values? In particular, can I get a list of the column names containing NaNs?\n    # Return a list of the column names containing NaNs\n", "entry_point": "find_columns_name_lists", "canonical_solution": ["    return df.columns[df.isna().any()].tolist()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'find_columns_name_lists'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [2,3,4]})) == ['pear']\n    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n    assert candidate(pd.DataFrame({'pear': [np.nan,3,3], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'ccc': [np.nan,3,4]})) == ['pear', 'ccc']\n    assert candidate(pd.DataFrame({'ddd': [np.nan,2,3], 'apple': [np.nan,3,4]})) == ['ddd', 'apple']\n    assert candidate(pd.DataFrame({'pear': [np.nan,24,3], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n    assert candidate(pd.DataFrame({'pear': [np.nan,2,453], 'apple': [np.nan,3,4]})) == ['pear', 'apple']\n    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [np.nan,34,45]})) == ['pear', 'apple']\n    assert candidate(pd.DataFrame({'pear': [np.nan,2,3], 'apple': [np.nan,3,433]})) == ['pear', 'apple']\n    assert candidate(pd.DataFrame({'pear': [np.nan,32,33], 'apple': [np.nan,32,43]})) == ['pear', 'apple']\n\n\n"}
{"task_id": "PandasEval/24", "prompt": "import pandas as pd\n\ndef round_a_single_column(df):\n    # Round a single column `A`\n    # Return the dataframe\n", "entry_point": "round_a_single_column", "canonical_solution": ["    df.A = df.A.round()\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'round'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1.23, 2.34, 3.45], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 3.0], 'B': [4.56, 5.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.41, 2.34, 3.45], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 3.0], 'B': [4.56, 5.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.41, 2.36, 3.45], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 3.0], 'B': [4.56, 5.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.41, 2.36, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.41, 2.56, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 3.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.31, 2.56, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 3.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 3.55], 'B': [4.56, 5.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 5.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 3.55], 'B': [4.56, 3.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 3.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 4.15], 'B': [4.56, 3.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 3.67, 6.78]}))\n    assert candidate(pd.DataFrame({'A': [1.31, 1.56, 4.05], 'B': [4.56, 3.67, 6.78]})).equals(pd.DataFrame({'A': [1.0, 2.0, 4.0], 'B': [4.56, 3.67, 6.78]}))\n\n\n"}
{"task_id": "PandasEval/25", "prompt": "import pandas as pd\ndf = pd.DataFrame({\n    'id': [220, 220, 220, 826, 826, 826, 901, 901, 901],\n    'product': [6647, 6647, 6647, 3380, 3380, 3380, 4555, 4555, 4555],\n    'date': ['2014-09-01', '2014-09-03', '2014-10-16', '2014-11-11', '2014-12-09', '2015-05-19', '2014-09-01', '2014-10-05', '2014-11-01']\n})\n\n# How to group values of pandas dataframe and select the latest by date from each group?\n# Sorting values by `date` (ascending is True), and then grouping by `id`\nlast_df =", "entry_point": "none", "canonical_solution": [" df.sort_values('date', ascending=True)\nlast_df = last_df.groupby('id').last()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'sort_values_groupby_last'\n}\n\n\ndef check():\n    assert last_df.equals(df.sort_values('date', ascending=True).groupby('id').last())\n\n\n"}
{"task_id": "PandasEval/26", "prompt": "import pandas as pd\nimport numpy as np\n\ndef shift_column_up_by_one(df):\n    # Shift column in pandas dataframe up by one?\n    # In detail, in 'gdp' column, shift up by one and return dataframe with the changed gdp column.\n    ", "entry_point": "shift_column_up_by_one", "canonical_solution": ["df['gdp'] = df['gdp'].shift(1)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'shift'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [2.0,4.0],'cap': [8, 7]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,2.0],'cap': [8, 7]}))\n    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [2.0,4.0],'cap': [9, 7]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,2.0],'cap': [9, 7]}))\n    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [2.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,2.0],'cap': [9, 3]}))\n    assert candidate(pd.DataFrame({'y': [1,2],'gdp': [3.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [1,2],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n    assert candidate(pd.DataFrame({'y': [5,2],'gdp': [3.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [5,2],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,4.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,8.0],'cap': [9, 3]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [9, 3]}))\n    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,8.0],'cap': [19, 3]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [19, 3]}))\n    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [3.0,8.0],'cap': [19, 13]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,3.0],'cap': [19, 13]}))\n    assert candidate(pd.DataFrame({'y': [5,1],'gdp': [13.0,8.0],'cap': [19, 13]})).equals(pd.DataFrame({'y': [5,1],'gdp': [np.nan,13.0],'cap': [19, 13]}))\n\n\n"}
{"task_id": "PandasEval/27", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'line_date': [1, 2, 3], 'line_num': [1, 0, 6], 'line_text': list('abc')})\n# I need to remain the rows where line_num is not equal to 0. What's the most efficient way to do it?\n# it should be as simple as:\nn_df =", "entry_point": "none", "canonical_solution": [" df[df.line_num != 0]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'df_none'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({\"line_date\": [1, 3], \"line_num\": [1, 6], \"line_text\": list(\"ac\")}, index=[0, 2]))\n\n\n"}
{"task_id": "PandasEval/28", "prompt": "import pandas as pd\n\ndef is_df_exist(df):\n    # In my code, I have several variables which can either contain a pandas DataFrame or nothing at all.\n    # Let's say I want to test and see if a certain DataFrame has been created yet or not.\n", "entry_point": "is_df_exist", "canonical_solution": ["    if df is None:\n        return False\n    else:\n        return True"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'df_none'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')})) == True\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[2,300,500], 'C':list('abc')})) == True\n    assert candidate(pd.DataFrame({'A':[13,2,3], 'B':[2,300,500], 'C':list('abc')})) == True\n    assert candidate(pd.DataFrame({'D':[1,2,3], 'B':[2,300,500], 'C':list('dct')})) == True\n    assert candidate(pd.DataFrame({'A':[1,25,34], 'B':[2,300,500], 'C':list('abc')})) == True\n    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[2,300,500], 'C':list('abc')})) == True\n    assert candidate(None) == False\n    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[2,3,500], 'C':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[2,3,5], 'C':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,23,3], 'S':[5,2,1], 'C':list('abc')}))\n\n\n"}
{"task_id": "PandasEval/29", "prompt": "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'A': [1, 4, 7, np.nan], 'B': [np.nan, 2, 5, np.nan], 'C': [np.nan, np.nan, 3, 6]})\n# Move next value to first empty row pandas\n# how do i move each value from a column to the first empty \"row/cell\" in pandas?\n# use sorted to align non NULL data at the top, use dropna to drop all rows with all NaN\nnew_df =", "entry_point": "none", "canonical_solution": [" df.apply(lambda x: sorted(x, key=pd.isnull)).dropna(how = 'all')"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'apply_dropna_sorted'\n}\n\n\ndef check(candidate):\n    assert new_df.equals(pd.DataFrame({'A': [1.0, 4.0, 7.0], 'B': [2.0, 5.0, np.nan], 'C': [3.0, 6.0, np.nan]}))\n\n\n"}
{"task_id": "PandasEval/30", "prompt": "import pandas as pd\n\n# I want to create a dataframe with one of the column as a list or array.\ndf = pd.DataFrame({'Name':['Juda','Pri']})\nemails = {'a@a.com','b@b.com'}\ndf['Email'] = ''\n# After you assign a list like or array like value to the columns, the column should be considered as type object\n# Now I want to assign the emails to first row and the 'Email' column\n", "entry_point": "none", "canonical_solution": ["df.Email = df.Email.astype(object)\ndf.loc[0].Email = emails"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'astype_loc'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'Name':['Juda','Pri'],'Email':[{'a@a.com','b@b.com'}, '']}))\n\n\n"}
{"task_id": "PandasEval/31", "prompt": "import pandas as pd\n\ndef drop_consecutive_duplicates(series):\n    # Drop consecutive duplicates\n    # Return the result\n", "entry_point": "drop_consecutive_duplicates", "canonical_solution": ["    return series.loc[series.shift(-1) != series]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'loc'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.Series([1, 2, 2, 3, 2])).equals(pd.Series([1, 2, 3, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 4, 2])).equals(pd.Series([1, 2, 4, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 5, 2])).equals(pd.Series([1, 2, 5, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 6, 2])).equals(pd.Series([1, 2, 6, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 7, 2])).equals(pd.Series([1, 2, 7, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 8, 2])).equals(pd.Series([1, 2, 8, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 9, 2])).equals(pd.Series([1, 2, 9, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 10, 2])).equals(pd.Series([1, 2, 10, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 11, 2])).equals(pd.Series([1, 2, 11, 2], index=[0, 2, 3, 4]))\n    assert candidate(pd.Series([1, 2, 2, 13, 2])).equals(pd.Series([1, 2, 13, 2], index=[0, 2, 3, 4]))\n\n\n"}
{"task_id": "PandasEval/32", "prompt": "import pandas as pd\n\n# creating a Series from a list [56, 24, 421, 90]\nmy_series = ", "entry_point": "none", "canonical_solution": ["pd.Series([56, 24, 421, 90])"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'Series'\n}\n\n\ndef check():\n    assert my_series.equals(pd.Series([56, 24, 421, 90]))\n\n\n"}
{"task_id": "PandasEval/33", "prompt": "import pandas as pd\n\ndef get_last_n_rows(df, n):\n    # How to get the last N rows of a pandas DataFrame?\n", "entry_point": "get_last_n_rows", "canonical_solution": ["    return df.tail(n)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'tail'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [300, 500]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [11, 2, 3], 'B': [100, 300, 500]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [300, 500]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [11, 2, 3], 'B': [100, 400, 500]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [400, 500]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [11, 2, 3], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [2, 3], 'B': [400, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [11, 20, 3], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [20, 3], 'B': [400, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [11, 52, 13], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [52, 13], 'B': [400, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [84, 52, 13], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [52, 13], 'B': [400, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [84, 52, 82], 'B': [100, 400, 600]}), 2).equals(pd.DataFrame({'A': [52, 82], 'B': [400, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [84, 52, 82], 'B': [100, 512, 600]}), 2).equals(pd.DataFrame({'A': [52, 82], 'B': [512, 600]}, index=[1, 2]))\n    assert candidate(pd.DataFrame({'A': [84, 52, 82], 'B': [100, 512, 777]}), 2).equals(pd.DataFrame({'A': [52, 82], 'B': [512, 777]}, index=[1, 2]))\n\n\n"}
{"task_id": "PandasEval/34", "prompt": "import pandas as pd\n\ndef append_dict_to_df(df, dictionary):\n    # append dictionary to data frame\n    # return the data frame\n", "entry_point": "append_dict_to_df", "canonical_solution": ["    df = df.append(dictionary, ignore_index=True)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'append'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame(), {'B': 100, 'C': 200}).equals(pd.DataFrame({'B': [100.0], 'C': [200.0]}))\n    assert candidate(pd.DataFrame(), {'B': 110, 'C': 200}).equals(pd.DataFrame({'B': [110.0], 'C': [200.0]}))\n    assert candidate(pd.DataFrame(), {'B': 120, 'C': 200}).equals(pd.DataFrame({'B': [120.0], 'C': [200.0]}))\n    assert candidate(pd.DataFrame(), {'B': 150, 'C': 200}).equals(pd.DataFrame({'B': [150.0], 'C': [200.0]}))\n    assert candidate(pd.DataFrame(), {'B': 150, 'C': 220}).equals(pd.DataFrame({'B': [150.0], 'C': [220.0]}))\n    assert candidate(pd.DataFrame(), {'B': 154, 'C': 220}).equals(pd.DataFrame({'B': [154.0], 'C': [220.0]}))\n    assert candidate(pd.DataFrame(), {'B': 164, 'C': 220}).equals(pd.DataFrame({'B': [164.0], 'C': [220.0]}))\n    assert candidate(pd.DataFrame(), {'B': 164, 'C': 240}).equals(pd.DataFrame({'B': [164.0], 'C': [240.0]}))\n    assert candidate(pd.DataFrame(), {'B': 164, 'C': 244}).equals(pd.DataFrame({'B': [164.0], 'C': [244.0]}))\n    assert candidate(pd.DataFrame(), {'B': 184, 'C': 244}).equals(pd.DataFrame({'B': [184.0], 'C': [244.0]}))\n\n\n"}
{"task_id": "PandasEval/35", "prompt": "import pandas as pd\n\ndef remove_duplicates_by_col_names(df):\n    \"\"\"\n    Here's a one solution to remove columns based on duplicate column names:\n    Return the duplicated dataframe\n    \"\"\"\n", "entry_point": "remove_duplicates_by_col_names", "canonical_solution": ["    return df.loc[:,~df.columns.duplicated()]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'loc'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,2,3], 'B':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,2,4], 'B':[100,300,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,2,4], 'B':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[100,300,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[100,312,500], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[100,312,213], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[973,312,213], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'B':[973,312,111], 'B':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'B':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'C':[973,312,111], 'C':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'C':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'C':[973,312,122], 'C':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'C':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,3,4], 'C':[973,312,55], 'C':list('abc')})).equals(pd.DataFrame({'A':[1,3,4], 'C':list('abc')}))\n\n\n"}
{"task_id": "PandasEval/36", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'a': [0, 1], 'b': [5, 3]})\n# How to obtain pandas DataFrame without index\n# I want to print the whole dataframe, but I don't want to print the index\ndf_string =", "entry_point": "none", "canonical_solution": [" df.to_string(index=False)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'to_string'\n}\n\n\ndef check():\n    assert df_string == ' a  b\n 0  5\n 1  3'\n\n\n"}
{"task_id": "PandasEval/37", "prompt": "import pandas as pd\n\ndata = {'col_0': ['a', 'a', 'a', 'a', 'b','b','b'], 'col_1': [-2, -7, 6, 8, -5, 2, 6]}\ndf = pd.DataFrame(data)\n# What I want is to clip the values of `col_1` between -2 to 2 if `col_0` is `a`.\n# # Using `clip` function in pandas.\ndf.loc[df['col_0']=='a','col_1'] = ", "entry_point": "none", "canonical_solution": [" df.loc[df['col_0']=='a','col_1'].clip(-2,2)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'clip'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'col_0': ['a', 'a', 'a', 'a', 'b','b','b'], 'col_1': [-2, -2, 2, 2, -5, 2, 6]}))\n\n\n"}
{"task_id": "PandasEval/38", "prompt": "import pandas as pd\n\ndef change_col_names_of_df(df, origin_names, new_names):\n    # How do I change the column labels of df\uff1f\n    # And return the dataframe that has been renamed\n", "entry_point": "change_col_names_of_df", "canonical_solution": ["    return df.rename(columns={origin_names:new_names})"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'rename'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'a', 'Y').equals(pd.DataFrame('x', index=range(3), columns=list('Ybcde')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'a', 'Z').equals(pd.DataFrame('x', index=range(3), columns=list('Zbcde')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'a', 'W').equals(pd.DataFrame('x', index=range(3), columns=list('Wbcde')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'b', 'W').equals(pd.DataFrame('x', index=range(3), columns=list('aWcde')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'b', 'P').equals(pd.DataFrame('x', index=range(3), columns=list('aPcde')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'b', 'O').equals(pd.DataFrame('x', index=range(3), columns=list('aOcde')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'c', 'O').equals(pd.DataFrame('x', index=range(3), columns=list('abOde')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'd', 'O').equals(pd.DataFrame('x', index=range(3), columns=list('abcOe')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'd', 'E').equals(pd.DataFrame('x', index=range(3), columns=list('abcEe')))\n    assert candidate(pd.DataFrame('x', index=range(3), columns=list('abcde')), 'e', 'E').equals(pd.DataFrame('x', index=range(3), columns=list('abcdE')))\n\n"}
{"task_id": "PandasEval/39", "prompt": "import pandas as pd\n\ndef change_all_cols_type(df):\n    # Change all columns type of DataFrame to numeric\n    # And return the new DataFrame\n    # The code is:\n", "entry_point": "change_all_cols_type", "canonical_solution": ["    return df.apply(pd.to_numeric)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'apply'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame(data=[['5.4', 2.0, 3.2]])).equals(pd.DataFrame(data=[[5.4, 2.0, 3.2]]))\n    assert candidate(pd.DataFrame(data=[['5.8', 2.0, 3.2]])).equals(pd.DataFrame(data=[[5.8, 2.0, 3.2]]))\n    assert candidate(pd.DataFrame(data=[['5.8', 9.1, 3.2]])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.2]]))\n    assert candidate(pd.DataFrame(data=[['5.8', 9.1, 3.9]])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.9]]))\n    assert candidate(pd.DataFrame(data=[['5.8', '9.1', 3.9]])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.9]]))\n    assert candidate(pd.DataFrame(data=[['5.8', '9.1', '3.9']])).equals(pd.DataFrame(data=[[5.8, 9.1, 3.9]]))\n    assert candidate(pd.DataFrame(data=[['5.8', '9.1', '6.7']])).equals(pd.DataFrame(data=[[5.8, 9.1, 6.7]]))\n    assert candidate(pd.DataFrame(data=[['5.8', '9.1', 6.5]])).equals(pd.DataFrame(data=[[5.8, 9.1, 6.5]]))\n    assert candidate(pd.DataFrame(data=[['5.8', '9.8', 6.5]])).equals(pd.DataFrame(data=[[5.8, 9.8, 6.5]]))\n    assert candidate(pd.DataFrame(data=[[5.8, '9.8', 6.5]])).equals(pd.DataFrame(data=[[5.8, 9.8, 6.5]]))\n\n"}
{"task_id": "PandasEval/40", "prompt": "import pandas as pd\n\ndef get_mean_in_column(df, col_name):\n    # return the column average/mean\n", "entry_point": "get_mean_in_column", "canonical_solution": ["    return df[col_name].mean()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'condition'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({\"A\": [1, 2, 3, 4, 5]}), \"A\") == 3.0\n    assert candidate(pd.DataFrame({\"A\": [1, 2, 3, 4, 5, 3]}), \"A\") == 3.0\n    assert candidate(pd.DataFrame({'B': [1, 2, 3, 4, 5, 3]}), 'B') == 3.0\n    assert candidate(pd.DataFrame({'A': [1, 2, 3, 3, 4, 5, 3]}), 'A') == 3.0\n    assert candidate(pd.DataFrame({'A': [1, 3, 2, 3, 4, 5, 3]}), 'A') == 3.0\n    assert candidate(pd.DataFrame({'T': [1, 2, 3, 4, 5, 3]}), 'T') == 3.0\n    assert candidate(pd.DataFrame({'A': [1, 2, 3, 4, 5, 3, 3, 3]}), 'A') == 3.0\n    assert candidate(pd.DataFrame({'A': [1, 2, 1, 3, 5, 4, 5, 3]}), 'A') == 3.0\n    assert candidate(pd.DataFrame({'A': [1, 2, 3, 4, 5, 3, 2, 4]}), 'A') == 3.0\n    assert candidate(pd.DataFrame({'A': [1, 2, 3, 4, 5, 3, 1, 5]}), 'A') == 3.0\n\n"}
{"task_id": "PandasEval/41", "prompt": "import pandas as pd\n\ndef is_contain_particular_value(series, value):\n    # How to determine whether a Pandas Column contains a particular value?\n    # Return the result\n", "entry_point": "is_contain_particular_value", "canonical_solution": ["    return value in series.unique()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'unique'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.Series([1, 2, 3]), 2) == True\n    assert candidate(pd.Series([1, 2, 3]), 3) == True\n    assert candidate(pd.Series([1, 2, 4]), 4) == True\n    assert candidate(pd.Series([1, 3, 4]), 4) == True\n    assert candidate(pd.Series([2, 3, 4]), 4) == True\n    assert candidate(pd.Series([2, 3, 4]), 5) == False\n    assert candidate(pd.Series([2, 3, 4]), 6) == False\n    assert candidate(pd.Series([2, 3, 4]), 7) == False\n    assert candidate(pd.Series([2, 3, 4]), 8) == False\n    assert candidate(pd.Series([2, 3, 4]), 0) == False\n\n\n"}
{"task_id": "PandasEval/42", "prompt": "import pandas as pd\n\ndef delete_first_n_rows(df, n):\n    # Delete first n rows of a dataframe\n    # Input:\n    #   df: DataFrame\n    #   n: int\n    # Return:\n    #   DataFrame\n", "entry_point": "delete_first_n_rows", "canonical_solution": ["    return df.iloc[n:]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'iloc'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[3], 'B':[500], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[1,2,4], 'B':[100,300,500], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[4], 'B':[500], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[1,2,4], 'B':[100,300,123], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[4], 'B':[123], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[1,2,43], 'B':[100,300,123], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[43], 'B':[123], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[1,2,43], 'B':[100,300,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[43], 'B':[412], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[1,2,123], 'B':[100,300,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[1,2,123], 'B':[100,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[1,2,123], 'B':[312,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[31,2,123], 'B':[312,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n    assert candidate(pd.DataFrame({'A':[31,23,123], 'B':[312,223,412], 'C':list('abc')}), 2).equals(pd.DataFrame({'A':[123], 'B':[412], 'C':['c']}, index=[2]))\n\n\n"}
{"task_id": "PandasEval/43", "prompt": "import pandas as pd\ndef compute_mean_along_rows(df):\n    # You can specify a new column named `mean_along_rows` that contains the mean of each row. You also need to compute the mean along the rows, so use axis=1.\n    # Finally, return the dataframe with the new column. \n", "entry_point": "compute_mean_along_rows", "canonical_solution": ["    df['mean'] = df.mean(axis=1)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'mean'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['US', 'US', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['US', 'US', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['w', 'US', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['w', 'US', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'US', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'US', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'US']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'US'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'tf']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['CN', 'UFC', 'tf'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'UFC', 'tf']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'UFC', 'tf'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[50.5, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[100,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[100,2,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[100.0, 151.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[100,200,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[100,200,3], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[100.0, 250.0, 251.5]}))\n    assert candidate(pd.DataFrame({'A':[100,200,500], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf']})).equals(pd.DataFrame({'A':[100,200,500], 'B':[100,300,500], 'Region':['AI', 'AG', 'tf'], 'mean_along_rows':[100.0, 250.0, 500.0]}))\n\n\n"}
{"task_id": "PandasEval/44", "prompt": "import pandas as pd\n\ndef delete_column(df, column_name):\n    # deleting a column from a Pandas DataFrame\n    # return the changged dataframe\n", "entry_point": "delete_column", "canonical_solution": ["    return df.drop(column_name, axis=1)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'drop'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 'A').equals(pd.DataFrame({'B':[100,300,500], 'C':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'C':list('abc')}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[200,300,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[200,300,500]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[200,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[1,2,3], 'B':[200,350,500]}))\n    assert candidate(pd.DataFrame({'A':[5,2,3], 'B':[200,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,3], 'B':[200,350,500]}))\n    assert candidate(pd.DataFrame({'A':[5,2,1], 'B':[200,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,1], 'B':[200,350,500]}))\n    assert candidate(pd.DataFrame({'A':[5,2,1], 'B':[521,350,500], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,1], 'B':[521,350,500]}))\n    assert candidate(pd.DataFrame({'A':[5,2,1], 'B':[521,350,125], 'C':list('dfg')}), 'C').equals(pd.DataFrame({'A':[5,2,1], 'B':[521,350,125]}))\n\n"}
{"task_id": "PandasEval/45", "prompt": "import pandas as pd\n\ns1 = pd.Series([3,4,5])\ns2 = pd.Series([1,2,3,5])\n# Finding the intersection between two series\n# In detail, first we create two sets, one for each series.\n# Then we find the intersection of the two sets.\ns1, s2 = set(s1), set(s2)\nintersection_result =", "entry_point": "none", "canonical_solution": [" s1.intersection(s2)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'intersection'\n}\n\n\ndef check():\n    assert intersection_result == {3, 5}\n\n\n"}
{"task_id": "PandasEval/46", "prompt": "import pandas as pd\nimport numpy as np\n\ndef get_value_when_condition(df):\n    # How can I get the values of column `A` when column `B`=3?\n", "entry_point": "get_value_when_condition", "canonical_solution": ["    return df[df['B'] == 3]['A'].values"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'condition'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [1, 2, 3, 4, 5]})), np.array(['p2']))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [1, 4, 3, 4, 5]})), np.array(['p2']))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [1, 4, 8, 4, 5]})), np.array([]))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p5'], 'B': [2, 4, 8, 4, 5]})), np.array([]))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p1', 'p1', 'p2', 'p2', 'p3'], 'B': [2, 3, 4, 4, 5]})), np.array(['p1']))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p2', 'p2', 'p3'], 'B': [2, 3, 4, 4, 5]})), np.array(['p1']))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p2', 'p3', 'p3'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p1', 'p3', 'p3'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p1', 'p1', 'p3'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n    assert np.array_equal(candidate(pd.DataFrame({'A': ['p2', 'p1', 'p1', 'p1', 'p2'], 'B': [2, 3, 4, 5, 5]})), np.array(['p1']))\n\n\n"}
{"task_id": "PandasEval/47", "prompt": "import pandas as pd\n\ndef make_dataframe_column_headers_lowercase(data):\n    # I want to make all column headers in my pandas data frame lower case\n", "entry_point": "make_dataframe_column_headers_lowercase", "canonical_solution": ["    data.columns = map(str.lower, data.columns)\n    return data"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'map_lower'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':range(3), 'B':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'a':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n    assert candidate(pd.DataFrame({'M':range(3), 'S':range(3,0,-1), 'R':list('dki')})).equals(pd.DataFrame({'m':range(3), 's':range(3,0,-1), 'r':list('dki')}))\n    assert candidate(pd.DataFrame({'D':range(3), 'B':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'d':range(3), 'b':range(3,0,-1), 'c':list('abc')}))\n    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'C':list('abc')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'c':list('abc')}))\n    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'I':list('abc')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'i':list('abc')}))\n    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'I':list('ccc')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'i':list('ccc')}))\n    assert candidate(pd.DataFrame({'D':range(3), 'K':range(3,0,-1), 'I':list('msr')})).equals(pd.DataFrame({'d':range(3), 'k':range(3,0,-1), 'i':list('msr')}))\n    assert candidate(pd.DataFrame({'LO':range(3), 'K':range(3,0,-1), 'I':list('msr')})).equals(pd.DataFrame({'lo':range(3), 'k':range(3,0,-1), 'i':list('msr')}))\n    assert candidate(pd.DataFrame({'LO':range(3), 'V':range(3,0,-1), 'I':list('msr')})).equals(pd.DataFrame({'lo':range(3), 'v':range(3,0,-1), 'i':list('msr')}))\n    assert candidate(pd.DataFrame({'LO':range(3), 'V':range(3,0,-1), 'E':list('msr')})).equals(pd.DataFrame({'lo':range(3), 'v':range(3,0,-1), 'e':list('msr')}))\n\n\n\n"}
{"task_id": "PandasEval/48", "prompt": "import pandas as pd\ndf = pd.DataFrame({'col': [\"apple\",\n                           \"pear\",\n                           \"strawberry\"]})\ntargets = ['apple', 'banana']\n# Any word from `targets` are present in sentence.\nresult =", "entry_point": "none", "canonical_solution": [" df.loc[df['col'].isin(targets)]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'loc_isin'\n}\n\n\ndef check():\n    assert result.equals(pd.DataFrame({'col': [\"apple\"]}))\n\n\n"}
{"task_id": "PandasEval/49", "prompt": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.random.randint(0,10,size=100).reshape(10,10))\n# I have a Pandas dataframe and I want to find all the unique values in that dataframe...irrespective of row/columns. \n# If I have a 10 x 10 dataframe, and suppose they have 84 unique values, I need to find them - Not the count.\n# Using xx.values.ravel to get the flattened array of the dataframe\n# Getting the unique values by numpy.unique\nunique_ndarray =", "entry_point": "none", "canonical_solution": [" np.unique(df.values.ravel())"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'nlargest_iloc'\n}\n\n\ndef check():\n    assert np.array_equal(unique_ndarray, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n\n\n"}
{"task_id": "PandasEval/50", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n# I would like to add a new column C that is the sum value of A and B cell.\n", "entry_point": "none", "canonical_solution": ["df['C'] = df.A + df.B"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'add': 'drop_index_inplace'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [5, 7, 9]}))\n\n\n"}
{"task_id": "PandasEval/51", "prompt": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Apples': [2, 1, np.nan],\n              'Bananas': [3, 3, 7],\n              'Grapes': [np.nan, 2, 3],})\n\n# Add a new column named 'Fruit Total' that sums the values of the other columns\n# Note that igonring the NaN values\n", "entry_point": "none", "canonical_solution": ["df['Fruit Total'] = df.apply(lambda x: sum(x.values), axis=1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'sum'\n}\n\n\ndef check():\n    tmp = pd.DataFrame({'Apples': [2, 1, np.nan],'Bananas': [3, 3, 7],'Grapes': [np.nan, 2, 3],})\n    tmp['Fruit Total'] = tmp.apply(lambda x: sum(x.values), axis=1)\n    assert df.equals(tmp)\n\n\n"}
{"task_id": "PandasEval/52", "prompt": "import pandas as pd\n\ndef combine_df(df1, df2):\n    # How do I combine two dataframes with ignore index? Return the concated dataframe.\n", "entry_point": "combine_df", "canonical_solution": ["    return df1.append(df2, ignore_index=True)", "    return pd.concat([df1, df2], ignore_index=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'append_concat'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [1, 2, 4, 5]}))\n    assert candidate(pd.DataFrame({'A': [1, 2]}), pd.DataFrame({'A': [4, 6]})).equals(pd.DataFrame({'A': [1, 2, 4, 6]}))\n    assert candidate(pd.DataFrame({'A': [1, 4]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [1, 4, 4, 5]}))\n    assert candidate(pd.DataFrame({'A': [3, 4]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [3, 4, 4, 5]}))\n    assert candidate(pd.DataFrame({'A': [5, 2]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [5, 2, 4, 5]}))\n    assert candidate(pd.DataFrame({'A': [4, 2]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [4, 2, 4, 5]}))\n    assert candidate(pd.DataFrame({'A': [6, 2]}), pd.DataFrame({'A': [9, 5]})).equals(pd.DataFrame({'A': [6, 2, 9, 5]}))\n    assert candidate(pd.DataFrame({'A': [1, 7]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [1, 7, 4, 5]}))\n    assert candidate(pd.DataFrame({'A': [6, 2]}), pd.DataFrame({'A': [4, 56]})).equals(pd.DataFrame({'A': [6, 2, 4, 56]}))\n    assert candidate(pd.DataFrame({'A': [11, 22]}), pd.DataFrame({'A': [4, 5]})).equals(pd.DataFrame({'A': [11, 22, 4, 5]}))\n\n"}
{"task_id": "PandasEval/53", "prompt": "import pandas as pd\n\ndef get_number_columns(df):\n    # How do I retrieve the number of columns in a Pandas data frame?\n    # Return the number of columns in the dataframe\n", "entry_point": "get_number_columns", "canonical_solution": ["    return len(df.columns)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'len_columns'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({\"pear\": [1,2,3], \"apple\": [2,3,4], \"orange\": [3,4,5]})) == 3\n    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,3,4]})) == 2\n    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,3,5]})) == 2\n    assert candidate(pd.DataFrame({'pear': [1,4,3], 'apple': [2,3,4]})) == 2\n    assert candidate(pd.DataFrame({'pear': [3,2,3], 'apple': [2,3,4]})) == 2\n    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,3,5]})) == 2\n    assert candidate(pd.DataFrame({'pear': [1,2,3]})) == 1\n    assert candidate(pd.DataFrame({'pear': [11,2,3], 'apple': [2,3,4]})) == 2\n    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [2,412,4]})) == 2\n    assert candidate(pd.DataFrame({'pear': [1,2,3], 'apple': [22,33,44]})) == 2\n\n\n"}
{"task_id": "PandasEval/54", "prompt": "import pandas as pd\n\ndef extract_the_last_year(df, column_name):\n    # I am trying to extract the last year (YY) of a fiscal date string in the format of YYYY-YY.\n    # e.g The last year of this '1999-00' would be 2000.\n    # I need a logic to include a case where if it is the end of the century then my apply method should add to the first two digits.\n    # the column_name is the column name of the dataframe that contains the date strings.\n    # return the numerical Series obj of the last year.\n", "entry_point": "extract_the_last_year", "canonical_solution": ["    final_result = pd.to_numeric(df[column_name].str.split('-').str[0]) + 1\n    return final_result"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'to_numeric'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame(data={'Season':['1996-97', '1997-98', '1998-99', '1999-00', '2000-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2000, 2001]))\n    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1998-99', '1999-00', '2000-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2000, 2001]))\n    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1998-99', '2018-00', '2000-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2019, 2001]))\n    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1998-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1997, 1998, 1999, 2019, 2082]))\n    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1997-08', '1958-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1997, 1998, 1959, 2019, 2082]))\n    assert candidate(pd.DataFrame(data={'Season':['1996-07', '1967-08', '1958-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1997, 1968, 1959, 2019, 2082]))\n    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2018-00', '2081-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2019, 2082]))\n    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2008-00', '2081-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2009, 2082]))\n    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2088-00', '2081-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2089, 2082]))\n    assert candidate(pd.DataFrame(data={'Season':['1946-07', '1967-08', '1958-99', '2088-00', '2051-01']}), 'Season').equals(pd.Series([1947, 1968, 1959, 2089, 2052]))\n\n\n"}
{"task_id": "PandasEval/55", "prompt": "import pandas as pd\n\ndef counting_consecutive_positive_values(y):\n    # Counting consecutive positive values in Python/pandas array\n    # I'm trying to count consecutive up days in equity return data; so if a positive day is 1 and a negative is 0, a list y=[0,0,1,1,1,0,0,1,0,1,1] should return z=[0,0,1,2,3,0,0,1,0,1,2].\n    # Return the result\n", "entry_point": "counting_consecutive_positive_values", "canonical_solution": ["    return y * (y.groupby((y != y.shift()).cumsum()).cumcount() + 1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'groupby'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.Series([0,0,1,1])).equals(pd.Series([0,0,1,2]))\n    assert candidate(pd.Series([0,1,1,1])).equals(pd.Series([0,1,2,3]))\n    assert candidate(pd.Series([0,1,1,0])).equals(pd.Series([0,1,2,0]))\n    assert candidate(pd.Series([1,1,1,0])).equals(pd.Series([1,2,3,0]))\n    assert candidate(pd.Series([1,1,4,0])).equals(pd.Series([1,2,4,0]))\n    assert candidate(pd.Series([1,1,3,0])).equals(pd.Series([1,2,3,0]))\n    assert candidate(pd.Series([1,1,2,0])).equals(pd.Series([1,2,2,0]))\n    assert candidate(pd.Series([1,3,2,0])).equals(pd.Series([1,3,2,0]))\n    assert candidate(pd.Series([1,3,2,1])).equals(pd.Series([1,3,2,1]))\n    assert candidate(pd.Series([1,3,3,1])).equals(pd.Series([1,3,6,1]))\n\n\n"}
{"task_id": "PandasEval/56", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'a': [3.0, 2.0, 4.0, 1.0],'b': [1.0, 4.0 , 2.0, 3.0]})\n# How to get the first largest value in column a\uff1f\n# Using nlargest and iloc to implemente this\nfirst_value = ", "entry_point": "none", "canonical_solution": ["df.a.nlargest(1).iloc[-1]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'nlargest_iloc'\n}\n\n\ndef check():\n    assert first_value == 4.0\n\n\n"}
{"task_id": "PandasEval/57", "prompt": "import pandas as pd\n\ndef sorting_columns_based_on_column_name(df):\n    # Sorting columns in pandas dataframe based on column name\n    # Note that axis is one\n", "entry_point": "sorting_columns_based_on_column_name", "canonical_solution": ["    return df.reindex(sorted(df.columns), axis=1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'reindex_sorted'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'Q1.1': [1, 2, 3], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 2, 3], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [1, 2, 4], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 2, 4], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [1, 2, 5], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 2, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [1, 3, 5], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [1, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.3': [4, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [4, 5, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.3': [3, 5, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [3, 5, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [2, 3, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [3, 3, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 8, 9]})).equals(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.2': [7, 8, 9], 'Q1.3': [3, 3, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 4, 9]})).equals(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.2': [7, 4, 9], 'Q1.3': [3, 3, 6]}))\n    assert candidate(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.3': [3, 3, 6], 'Q1.2': [7, 3, 9]})).equals(pd.DataFrame({'Q1.1': [4, 4, 5], 'Q1.2': [7, 3, 9], 'Q1.3': [3, 3, 6]}))\n\n\n"}
{"task_id": "PandasEval/58", "prompt": "import pandas as pd\n\n# Example DataFrame\ndf = pd.DataFrame.from_dict({'Name'  : ['May21', 'James', 'Adi22', 'Hello', 'Girl90'],\n                             'Volume': [23, 12, 11, 34, 56],\n                             'Value' : [21321, 12311, 4435, 32454, 654654]})\n\n# Want to remove all the numbers from the Name column.\n# Any idea how to do it in a better way at the series/dataframe level.\ndf['Name'] =", "entry_point": "none", "canonical_solution": [" df['Name'].str.replace('\\d+', '')"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'str_replace'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'Name'  : ['May', 'James', 'Adi', 'Hello', 'Girl'],\n                             'Volume': [23, 12, 11, 34, 56],\n                             'Value' : [21321, 12311, 4435, 32454, 654654]}))\n\n\n"}
{"task_id": "PandasEval/59", "prompt": "import pandas as pd\nimport numpy as np\n\ndef delete_all_nan_columns(df):\n    # Delete all columns that contain all NaN values\n    # Return the result.\n", "entry_point": "delete_all_nan_columns", "canonical_solution": ["    return df.dropna(how='all', axis=1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'dropna'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 2, 3]}))\n    assert candidate(pd.DataFrame({'A': [1, 3, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 3, 3]}))\n    assert candidate(pd.DataFrame({'A': [4, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [4, 2, 3]}))\n    assert candidate(pd.DataFrame({'A': [6, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [6, 2, 3]}))\n    assert candidate(pd.DataFrame({'A': [1, 12, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 12, 3]}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 33], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 2, 33]}))\n    assert candidate(pd.DataFrame({'A': [13, 23, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [13, 23, 3]}))\n    assert candidate(pd.DataFrame({'A': [1, 25, 35], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 25, 35]}))\n    assert candidate(pd.DataFrame({'A': [41, 2, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [41, 2, 3]}))\n    assert candidate(pd.DataFrame({'A': [1, 24, 3], 'B': [np.nan, np.nan, np.nan], 'C': [np.nan, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1, 24, 3]}))\n\n\n"}
{"task_id": "PandasEval/60", "prompt": "import pandas as pd\n\ndef convert_column_to_date(df):\n    # Convert Column `Date` to Date Format using pandas function\n    # return the coverted dataframe\n", "entry_point": "convert_column_to_date", "canonical_solution": ["    df[\"Date\"] = pd.to_datetime(df.Date)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'to_datetime'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2015','01/15/2016','08/21/2015']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2015-02-20 00:00:00'),pd.Timestamp('2016-01-15 00:00:00'),pd.Timestamp('2015-08-21 00:00:00')]}))\n    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2016','01/15/2016','08/21/2015']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2016-02-20 00:00:00'),pd.Timestamp('2016-01-15 00:00:00'),pd.Timestamp('2015-08-21 00:00:00')]}))\n    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2016','01/15/2017','08/21/2015']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2016-02-20 00:00:00'),pd.Timestamp('2017-01-15 00:00:00'),pd.Timestamp('2015-08-21 00:00:00')]}))\n    assert candidate(pd.DataFrame( {'Symbol':['A','A','A'] , 'Date':['02/20/2016','01/15/2017','08/21/2019']})).equals(pd.DataFrame({'Symbol':['A','A','A'] , 'Date':[pd.Timestamp('2016-02-20 00:00:00'),pd.Timestamp('2017-01-15 00:00:00'),pd.Timestamp('2019-08-21 00:00:00')]}))\n\n\n"}
{"task_id": "PandasEval/61", "prompt": "import pandas as pd\n\ndef insert_row_at_arbitrary_in_dataframe(df, row_to_insert):\n    \"\"\"\n    Inserts a row into a dataframe at a specified row with no ingore index, and sort & reset the index with drop=True. \n    Returns the new dataframe.\n    \"\"\"\n", "entry_point": "insert_row_at_arbitrary_in_dataframe", "canonical_solution": ["    df = df.append(row_to_insert, ignore_index=False)\n    df = df.sort_index().reset_index(drop=True)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'append_sort_index'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'onset':[23.107, 41.815, 61.606], 'length':[1,2,3]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[23.107, 41.815, 61.606, 30.0], 'length':[1,2,3,1.3]}))\n    assert candidate(pd.DataFrame({'onset':[28.604, 41.815, 61.606], 'length':[1,2,3]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[28.604, 41.815, 61.606, 30.0], 'length':[1,2,3,1.3]}))\n    assert candidate(pd.DataFrame({'onset':[28.604, 41.815, 61.606], 'length':[1,2,4]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[28.604, 41.815, 61.606, 30.0], 'length':[1,2,4,1.3]}))\n    assert candidate(pd.DataFrame({'onset':[28.604, 41.815, 61.606], 'length':[1,3,4]}), pd.DataFrame({'onset': 30.0, 'length': 1.3}, index=[3])).equals(pd.DataFrame({'onset':[28.604, 41.815, 61.606, 30.0], 'length':[1,3,4,1.3]}))\n\n\n"}
{"task_id": "PandasEval/62", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'MSRA': [10, 11, 12], 'THU': [100, 110, 120]})\ndf = df.reset_index()  # make sure indexes pair with number of rows\n# (for index, row in DataFrame.iterrows) is a generator which yields both the index and row (as a Series)\n# for each row in the DataFrame, we need put the row['MSRA'] (as key) and row['THU'] (as value) into a rows_dict\nrows_dict = {} # {MSRA: THU, ...}\n", "entry_point": "none", "canonical_solution": ["for index, row in df.iterrows():\n    rows_dict[row['MSRA']] = row['THU']"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'iterrows'\n}\n\n\ndef check():\n    assert rows_dict == {10: 100, 11: 110, 12: 120}\n\n\n"}
{"task_id": "PandasEval/63", "prompt": "import pandas as pd\n\ndf1 = pd.DataFrame({'a': [0, 1], 'b': [5, 3]})\ndf2 = pd.DataFrame({'c': [0, 1], 'd': [10, 20]})\n# How do I merge two dataframes by index?\n# Set left&right indexs to True\nmerged_df = ", "entry_point": "none", "canonical_solution": ["pd.merge(df1, df2, left_index=True, right_index=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'merge'\n}\n\n\ndef check():\n    assert merged_result.equals(pd.merge(df1, df2, left_index=True, right_index=True))\n\n\n"}
{"task_id": "PandasEval/64", "prompt": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame([[1, 2.2, 'three']], columns=['A', 'B', 'C'])\n# I was wondering if there is an elegant and shorthand way in Pandas DataFrames to select columns by data type (dtype). \n# i.e. Select only float64 columns from a DataFrame\nnew_df = ", "entry_point": "none", "canonical_solution": ["df.select_dtypes(include=['float64'])"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'select_dtypes'\n}\n\n\ndef check():\n    assert new_df.equals(df.select_dtypes(include=['float64']))\n\n\n"}
{"task_id": "PandasEval/65", "prompt": "import pandas as pd\nimport numpy as np\ndef merge_df(df1, df2):\n    # How to merge two dataframes with different column names but same number of rows?\n    # I have two different data frames in pandas. Example:\n    # df1=a b  df2= c\n    # 0 1       1 \n    # 1 2       2 \n    # 2 3       3 \n    # I want to merge them so\n    # df1= a b c  \n    #  0 1 1\n    #  1 2 2\n    #  2 3 3\n    # In order to merge two dataframes you can use this two examples. Both returns the same goal\n    # Using merge plus additional arguments instructing it to use the indexes\n    # Specially, we can set left_index and right_index to True\n    ", "entry_point": "merge_df", "canonical_solution": ["return pd.merge(df1, df2, left_index=True, right_index=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'merge'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a':[0, 1, 2],'b':[1,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 1, 2],'b':[1,2,3], 'c':[1, 2, 3]}))\n    assert candidate(pd.DataFrame({'m':[7,7,9],'s':[5,3,6]}), pd.DataFrame({'r':[9,9,2]})).equals(pd.DataFrame({'m':[7,7,9],'s':[5,3,6],'r':[9,9,2]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 2],'b':[1,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 2],'b':[1,2,3], 'c':[1, 2, 3]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[1,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[1,2,3], 'c':[1, 2, 3]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[1, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[1, 2, 3]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[14, 2, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[14, 2, 3]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[14, 12, 3]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[14, 12, 3]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3]}), pd.DataFrame({'c':[14, 12, 13]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[4,2,3], 'c':[14, 12, 13]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,3]}), pd.DataFrame({'c':[14, 12, 13]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,3], 'c':[14, 12, 13]}))\n    assert candidate(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,13]}), pd.DataFrame({'c':[14, 12, 13]})).equals(pd.DataFrame({'a':[0, 2, 4],'b':[14,2,13], 'c':[14, 12, 13]}))\n\n\n\n"}
{"task_id": "PandasEval/66", "prompt": "import pandas as pd\n\ndef get_percentage_of_each_gender(series):\n    # Given a pandas series that represents frequencies of a value, how can I turn those frequencies into percentages?\n    # Return the percentage of each gender.\n", "entry_point": "get_percentage_of_each_gender", "canonical_solution": ["    return series.value_counts(normalize=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'value_counts'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 3}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 3}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 6 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 6 + ['female'] * 3}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 1}).sex).equals(pd.DataFrame({'sex': ['male'] * 5 + ['female'] * 1}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 2 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 2 + ['female'] * 3}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 13}).sex).equals(pd.DataFrame({'sex': ['male'] * 4 + ['female'] * 13}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 15 + ['female'] * 13}).sex).equals(pd.DataFrame({'sex': ['male'] * 15 + ['female'] * 13}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 43 + ['female'] * 3}).sex).equals(pd.DataFrame({'sex': ['male'] * 43 + ['female'] * 3}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 53 + ['female'] * 33}).sex).equals(pd.DataFrame({'sex': ['male'] * 53 + ['female'] * 33}).sex.value_counts(normalize=True))\n    assert candidate(pd.DataFrame({'sex': ['male'] * 25 + ['female'] * 32}).sex).equals(pd.DataFrame({'sex': ['male'] * 25 + ['female'] * 32}).sex.value_counts(normalize=True))\n\n\n"}
{"task_id": "PandasEval/67", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'name': ['jon','sam','jane','bob'],\n           'age': [30,25,18,26],\n           'sex':['male','male','female','male']})\n\nrow = ['45', 'Dean', 'male']\n# add the row at top in df\ndf.loc[-1] = row\ndf.index = df.index + 1\n# resort the index by inplace\n", "entry_point": "none", "canonical_solution": ["df.sort_index(inplace=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'dropna'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'name': ['Dean', 'jon','sam','jane','bob'], 'age': [45, 30,25,18,26], 'sex':['male', 'male','male','female','male']}))\n\n\n"}
{"task_id": "PandasEval/68", "prompt": "import pandas as pd\nimport numpy as np\n\ndef drop_all_nan_rows(df):\n    # We will drop all Nan rows.\n    # Return the changed dataframe.\n", "entry_point": "drop_all_nan_rows", "canonical_solution": ["    return df.dropna()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'dropna'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, np.nan, np.nan], 'C': [2, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [100.0], 'C': [2.0]}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, np.nan, np.nan], 'C': [4, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [100.0], 'C': [4.0]}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [100.0], 'C': [6.0]}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [1], 'B': [110.0], 'C': [6.0]}))\n    assert candidate(pd.DataFrame({'A': [2, 2, 3], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [2], 'B': [110.0], 'C': [6.0]}))\n    assert candidate(pd.DataFrame({'A': [22, 2, 3], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n    assert candidate(pd.DataFrame({'A': [22, 2, 33], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n    assert candidate(pd.DataFrame({'A': [22, 24, 33], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n    assert candidate(pd.DataFrame({'A': [22, 24, 52], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n    assert candidate(pd.DataFrame({'A': [22, 24, 13], 'B': [110, np.nan, np.nan], 'C': [6, np.nan, np.nan]})).equals(pd.DataFrame({'A': [22], 'B': [110.0], 'C': [6.0]}))\n\n\n"}
{"task_id": "PandasEval/69", "prompt": "import pandas as pd\nimport numpy as np\n\ndef fill_none_with_zero(df, col_names):\n    # Pandas dataframe fillna() only some columns in place\n    # This function fills all columns with 0\n    # Return the changed dataframe\n", "entry_point": "fill_none_with_zero", "canonical_solution": ["    df[col_names] = df[col_names].fillna(0)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'fillna'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['a']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['b']).equals(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [4.0, 2.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [4.0, 2.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [1.0, 4.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 4.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [42.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [42.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 52.0, 62.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 52.0, 62.0]}))\n    assert candidate(pd.DataFrame({'a': [11.0, 21.0, None], 'b': [4.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [11.0, 21.0, 0.0], 'b': [4.0, 5.0, 6.0]}))\n    assert candidate(pd.DataFrame({'a': [1.0, 2.0, None], 'b': [4.0, 15.0, 16.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 2.0, 0.0], 'b': [4.0, 15.0, 16.0]}))\n    assert candidate(pd.DataFrame({'a': [1.0, 23.0, None], 'b': [43.0, 5.0, 6.0]}), ['a', 'b']).equals(pd.DataFrame({'a': [1.0, 23.0, 0.0], 'b': [43.0, 5.0, 6.0]}))\n\n\n"}
{"task_id": "PandasEval/70", "prompt": "import pandas as pd\n\nweb_stats = {'Day': [1, 2, 3, 4, 2, 6],\n             'Visitors': [43, 43, 34, 23, 43, 23],\n             'Bounce_Rate': [3, 2, 4, 3, 5, 5]}\ndf = pd.DataFrame(web_stats)\n# I would like to drop all data in a pandas dataframe\n# Using df.index to drop all rows\n", "entry_point": "none", "canonical_solution": ["df.drop(df.index, inplace=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'drop_index_inplace'\n}\n\n\ndef check():\n    tmp = pd.DataFrame({'Day': [1, 2, 3], 'Visitors': [4, 5, 6], 'Bounce_Rate': [7, 8, 9]})\n    tmp.drop(tmp.index, inplace=True)\n    assert df.equals(tmp)\n\n\n"}
{"task_id": "PandasEval/71", "prompt": "import numpy as np\nimport pandas as pd\ndf = pd.DataFrame(\n    {\"x\": np.arange(1_000 * 100), \"section\": np.repeat(np.arange(100), 1_000)}\n)\n\n# Say i have a dataframe with 100,000 entries and want to split it into 100 sections of 1000 entries.\n# How do i take a random sample of say size 50 of just one of the 100 sections. \n# the data set is already ordered such that the first 1000 results are the first section the next section the next and so on.\n# You could add a \"section\" column to your data then perform a groupby and sample(n=50):\nsample = ", "entry_point": "none", "canonical_solution": [" df.groupby(\"section\").sample(n=50)", " df.groupby(\"section\").apply(lambda x: x.sample(50))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'sample_tcs_some_bug'\n}\n\n\ndef check():\n    assert sample.shape == (5000, 2)\n\n\n"}
{"task_id": "PandasEval/72", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'A': [1000, 765, 800], 'B': [10, 5, 7]})\n# I have a dataframe in pandas where each column has different value range.\n# Any idea how I can normalize the columns of this dataframe where each value is between 0 and 1?\nnormalized_df =", "entry_point": "none", "canonical_solution": [" df.apply(lambda x: (x - x.min()) / (x.max() - x.min()))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'min_max'\n}\n\n\ndef check():\n    assert normalized_df.equals(df.apply(lambda x: (x - x.min()) / (x.max() - x.min())))\n\n\n"}
{"task_id": "PandasEval/73", "prompt": "import pandas as pd\n\ndef get_value_counts(df):\n    # I want to get the counts of unique values of the dataframe. count_values implements this however I want to use its output somewhere else. \n    # How can I convert .count_values output to a pandas dataframe.\n    # Use rename_axis('unique_values') for name ('counts') of column from index and reset_index\n    # return the final dataframe\n", "entry_point": "get_value_counts", "canonical_solution": ["    return df.value_counts().rename_axis('unique_values').reset_index(name='counts')"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'value_counts_reset_index'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a':[1, 1, 2, 2, 2]})).equals(pd.DataFrame({'unique_values':[2, 1], 'counts':[3, 2]}))\n    assert candidate(pd.DataFrame({'iscas':[7, 5, 6, 3, 8]})).equals(pd.DataFrame({'unique_values':[3, 5, 6, 7, 8], 'counts':[1, 1, 1, 1, 1]}))\n    assert candidate(pd.DataFrame({'a':[1, 2, 2, 2, 2]})).equals(pd.DataFrame({'unique_values':[2, 1], 'counts':[4, 1]}))\n    assert candidate(pd.DataFrame({'a':[2, 2, 2, 2, 2]})).equals(pd.DataFrame({'unique_values':[2], 'counts':[5]}))\n    assert candidate(pd.DataFrame({'a':[2, 2, 2, 5, 2]})).equals(pd.DataFrame({'unique_values':[2, 5], 'counts':[4, 1]}))\n    assert candidate(pd.DataFrame({'a':[2, 2, 2, 5, 3]})).equals(pd.DataFrame({'unique_values':[2, 3, 5], 'counts':[3, 1, 1]}))\n    assert candidate(pd.DataFrame({'a':[2, 2, 2, 5, 1]})).equals(pd.DataFrame({'unique_values':[2, 1, 5], 'counts':[3, 1, 1]}))\n    assert candidate(pd.DataFrame({'a':[2, 1, 2, 5, 1]})).equals(pd.DataFrame({'unique_values':[1, 2, 5], 'counts':[2, 2, 1]}))\n    assert candidate(pd.DataFrame({'a':[1, 1, 2, 5, 1]})).equals(pd.DataFrame({'unique_values':[1, 2, 5], 'counts':[3, 1, 1]}))\n    assert candidate(pd.DataFrame({'a':[1, 1, 2, 4, 1]})).equals(pd.DataFrame({'unique_values':[1, 2, 4], 'counts':[3, 1, 1]}))\n\n\n"}
{"task_id": "PandasEval/74", "prompt": "import pandas as pd\n\ndef counting_occurrences_of_a_value(series, value):\n    # Count the number of occurrences of a value in a series\n    # Return the count\n", "entry_point": "counting_occurrences_of_a_value", "canonical_solution": ["    return series.value_counts()[value]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'value_counts'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.Series([1, 2, 3, 1, 2, 3, 1, 2, 3]), 1) == 3\n    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 3]), 1) == 4\n    assert candidate(pd.Series([1, 4, 3, 1, 1, 3, 1, 2, 3]), 1) == 4\n    assert candidate(pd.Series([1, 2, 3, 1, 1, 35, 1, 2, 3]), 1) == 4\n    assert candidate(pd.Series([1, 2, 13, 1, 1, 3, 1, 12, 3]), 1) == 4\n    assert candidate(pd.Series([11, 2, 3, 1, 1, 3, 1, 2, 3]), 1) == 3\n    assert candidate(pd.Series([1, 2, 3, 1, 1, 43, 1, 42, 35]), 1) == 4\n    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 3]), 2) == 2\n    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 3]), 3) == 3\n    assert candidate(pd.Series([1, 2, 3, 1, 1, 3, 1, 2, 33]), 33) == 1\n\n"}
{"task_id": "PandasEval/75", "prompt": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'group1': [0, 0, 1, 1], 'group2': [2, 2, 3, 4], 'base': [0, 1, 2, 3], 'x1': [3, 4, 5, 6], 'x2': [np.nan, 6, np.nan, 8]})\n\n# Selecting rows where column x2 is NaN \nnan_df =", "entry_point": "none", "canonical_solution": [" df[df['x2'].isnull()]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'isnull_isnan'\n}\n\n\ndef check():\n    assert nan_df.equals(pd.DataFrame({'group1': [0, 1], 'group2': [2, 3], 'base': [0, 2], 'x1': [3, 5], 'x2': [np.nan, np.nan]}, index=[0, 2]))\n\n\n"}
{"task_id": "PandasEval/76", "prompt": "import pandas as pd\n\nsource_series = pd.Series([32, 434, 542, 'BC2'])\ntarget_series = pd.Series(['B1', 'B3', 'B4', 123, 43, 54])\n\n# Appending the source series to the target series, with ignoring the index or resetting index\nmerged_series = ", "entry_point": "none", "canonical_solution": ["target_series.append(source_series, ignore_index=True)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'append'\n}\n\n\ndef check():\n    assert merged_series.equals(pd.Series(['B1', 'B3', 'B4', 123, 43, 54, 32, 434, 542, 'BC2']))\n\n\n"}
{"task_id": "PandasEval/77", "prompt": "import pandas as pd\n\ndef find_col_a_gt_col_b_rows(df, col_a, col_b):\n    # Find rows in df where col_a > col_b\n    # Return the rows\n", "entry_point": "find_col_a_gt_col_b_rows", "canonical_solution": ["    return df[df[col_a] > df[col_b]]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'apply'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [5, 2, 3], 'B': [4, 5, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [5], 'B': [4]}))\n    assert candidate(pd.DataFrame({'A': [5, 7, 3], 'B': [4, 5, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [5, 7], 'B': [4, 5]}))\n    assert candidate(pd.DataFrame({'A': [5, 7, 3], 'B': [4, 2, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [5, 7], 'B': [4, 2]}))\n    assert candidate(pd.DataFrame({'A': [6, 7, 3], 'B': [4, 2, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 7], 'B': [4, 2]}))\n    assert candidate(pd.DataFrame({'A': [6, 8, 3], 'B': [4, 2, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 2]}))\n    assert candidate(pd.DataFrame({'A': [6, 8, 3], 'B': [4, 3, 6]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n    assert candidate(pd.DataFrame({'A': [6, 8, 3], 'B': [4, 3, 4]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n    assert candidate(pd.DataFrame({'A': [6, 8, 1], 'B': [4, 3, 4]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n    assert candidate(pd.DataFrame({'A': [6, 8, 1], 'B': [4, 3, 14]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 8], 'B': [4, 3]}))\n    assert candidate(pd.DataFrame({'A': [6, 18, 1], 'B': [4, 3, 14]}), 'A', 'B').equals(pd.DataFrame({'A': [6, 18], 'B': [4, 3]}))\n\n\n"}
{"task_id": "PandasEval/78", "prompt": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'mycol':np.arange(5), 'dummy':np.arange(5)})\n# I find myself often having to check whether a column or row exists in a dataframe before trying to reference it.\n# Is there any way to do this more nicely? \n# For example on an arbitrary object I can do x = getattr(anobject, 'id', default) - is there anything similar to this in pandas? Really any way to achieve what I'm doing more gracefully?\n# Output the second row of data in `mycol` column if it exists, otherwise output NaN\nvalue =", "entry_point": "none", "canonical_solution": [" df.mycol.get(1, np.nan)", " df.loc[1, 'mycol'] if 1 in df.index else np.nan"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'get_index'\n}\n\n\ndef check():\n    assert value == 1\n\n\n"}
{"task_id": "PandasEval/79", "prompt": "import pandas as pd\nimport numpy as np\n\ndef display_rows_with_gt_1_nan(df):\n    # Return the dataframe with the rows with one or more NaN values\n", "entry_point": "display_rows_with_gt_1_nan", "canonical_solution": ["    return df[df.isna().any(axis=1)]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'isna_any'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [5, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [5]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 332, 2], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 4122, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 4, 2123]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 31, 22], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [4, 34, 22]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 31, 12], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 3, 2], 'b': [14, 14, 12]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n    assert candidate(pd.DataFrame({'a': [np.nan, 33, 32], 'b': [4, 4, 2]})).equals(pd.DataFrame({'a': [np.nan], 'b': [4]}, index=[0]))\n\n"}
{"task_id": "PandasEval/80", "prompt": "import pandas as pd\nimport numpy as np\ndef ceil_of_series(s):\n    # ceiling of a pandas series\n    # Return the result.\n", "entry_point": "ceil_of_series", "canonical_solution": ["    return np.ceil(s)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'ceil'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.1, 2.3, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.2, 2.4, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.2, 2.3, 3.2, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.2, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.5, 5.1])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.4, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.2, 2.3, 3.4, 4.5, 5.2])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.4, 2.3, 3.4, 4.5, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n    assert candidate(pd.Series([1.2, 2.1, 3.4, 4.1, 5.6])).equals(pd.Series([2, 3, 4, 5, 6]).astype(float))\n\n"}
{"task_id": "PandasEval/81", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({\"Code\": [2, 2, 4, 4], \"Country\": [\"Afghanistan\", \"Afghanistan\", \"Angola\", \"Angola\"], \"Item_Code\": [15, 25, 15, 25], \"Y1961\": [10, 10, 30, 30], \"Y1962\": [20, 20, 40, 40], \"Y1963\": [30, 30, 50, 50]})\n# What is the best way to do a groupby on a Pandas dataframe, but exclude some columns from that groupby?\n# I want to groupby the column `Country` and `Item_Code` and only compute the sum of the rows falling under the columns ['Y1961', 'Y1962' and 'Y1963']. \nnew_df =", "entry_point": "none", "canonical_solution": [" df.groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'groupby_sum'\n}\n\n\ndef check():\n    assert new_df.equals(pd.DataFrame({\"Code\": [2, 2, 4, 4], \"Country\": [\"Afghanistan\", \"Afghanistan\", \"Angola\", \"Angola\"], \"Item_Code\": [15, 25, 15, 25], \"Y1961\": [10, 10, 30, 30], \"Y1962\": [20, 20, 40, 40], \"Y1963\": [30, 30, 50, 50]}).groupby(['Country', 'Item_Code'])[['Y1961', 'Y1962', 'Y1963']].sum())\n\n\n"}
{"task_id": "PandasEval/82", "prompt": "from typing import List\nimport pandas as pd\nimport numpy as np\n\ndef append_in_dataframe(df, list_to_append, column_name_list) -> pd.DataFrame:\n    \"\"\"    \n    Params:\n        df: The dataframe to append to.\n        list_to_append: The list to append.\n        column_name_list: The column names of the list to append.\n\n    Returns:\n        The dataframe with the list appended.\n    \"\"\"\n", "entry_point": "append_in_dataframe", "canonical_solution": ["    list_to_append = pd.DataFrame(list_to_append, columns=column_name_list)\n    df = df.append(list_to_append)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'append'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'col1': [1, 2], 'col2': [4, 5]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [1, 2, 5, 6], 'col2': [4, 5, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [4, 5]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 6], 'col2': [4, 5, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 5]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 6], 'col2': [1, 5, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 7]}), [5, 6] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 6], 'col2': [1, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 7]}), [5, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 5, 9], 'col2': [1, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [1, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 15, 9], 'col2': [1, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [5, 2], 'col2': [11, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 2, 15, 9], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [5, 12], 'col2': [11, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [5, 12, 15, 9], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [15, 12], 'col2': [11, 7]}), [15, 9] , ['col1']).equals(pd.DataFrame({'col1': [15, 12, 15, 9], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'col1': [15, 12], 'col2': [11, 7]}), [15, 19] , ['col1']).equals(pd.DataFrame({'col1': [15, 12, 15, 19], 'col2': [11, 7, np.nan, np.nan]}, index=[0, 1, 0, 1]))\n\n"}
{"task_id": "PandasEval/83", "prompt": "import pandas as pd\n\ndef convert_bool_to_int(df, col_name):\n    # How can I map True/False to 1/0 in a Pandas DataFrame?\n    # return the dataframe with the column converted to int\n", "entry_point": "convert_bool_to_int", "canonical_solution": ["    df[col_name] = df[col_name].astype(int)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'astype'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,True,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,1,0]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,True,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,1,1]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,False,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,0,0]}))\n    assert candidate(pd.DataFrame({'A':[1,2,33], 'B':[True,True,False]}), 'B').equals(pd.DataFrame({'A':[1,2,33], 'B':[1,1,0]}))\n    assert candidate(pd.DataFrame({'A':[1,22,3], 'B':[True,True,False]}), 'B').equals(pd.DataFrame({'A':[1,22,3], 'B':[1,1,0]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[False,True,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[0,1,0]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[False,False,False]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[0,0,0]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[False,False,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[0,0,1]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,False,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,0,1]}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[True,True,True]}), 'B').equals(pd.DataFrame({'A':[1,2,3], 'B':[1,1,1]}))\n\n\n"}
{"task_id": "PandasEval/84", "prompt": "import pandas as pd\n\ndef dataframe2list_of_dict(df):\n    # Pandas DataFrame to List of Dictionaries\n    # Use df.to_dict() to solve it and return the result\n", "entry_point": "dataframe2list_of_dict", "canonical_solution": ["    return df.to_dict(orient='records')"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'to_dict'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a':[1,1,1], 'b':[10,20,20]})) == [{'a': 1, 'b': 10}, {'a': 1, 'b': 20}, {'a': 1, 'b': 20}]\n    assert candidate(pd.DataFrame({'a':[2,1,1], 'b':[10,20,20]})) == [{'a': 2, 'b': 10}, {'a': 1, 'b': 20}, {'a': 1, 'b': 20}]\n    assert candidate(pd.DataFrame({'a':[2,1,4], 'b':[10,20,20]})) == [{'a': 2, 'b': 10}, {'a': 1, 'b': 20}, {'a': 4, 'b': 20}]\n    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[10,20,20]})) == [{'a': 2, 'b': 10}, {'a': 3, 'b': 20}, {'a': 4, 'b': 20}]\n    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[12,20,20]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 20}, {'a': 4, 'b': 20}]\n    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[12,33,20]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 33}, {'a': 4, 'b': 20}]\n    assert candidate(pd.DataFrame({'a':[2,3,4], 'b':[12,33,4]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 33}, {'a': 4, 'b': 4}]\n    assert candidate(pd.DataFrame({'a':[2,3,41], 'b':[12,33,4]})) == [{'a': 2, 'b': 12}, {'a': 3, 'b': 33}, {'a': 41, 'b': 4}]\n    assert candidate(pd.DataFrame({'a':[2,33,41], 'b':[12,33,4]})) == [{'a': 2, 'b': 12}, {'a': 33, 'b': 33}, {'a': 41, 'b': 4}]\n    assert candidate(pd.DataFrame({'a':[21,33,41], 'b':[12,33,4]})) == [{'a': 21, 'b': 12}, {'a': 33, 'b': 33}, {'a': 41, 'b': 4}]\n\n"}
{"task_id": "PandasEval/85", "prompt": "import pandas as pd\n\ndef set_value_to_entire_col(df, value):\n    # Set value to an entire column `B` of a pandas dataframe\n    # Return the changed dataframe.\n", "entry_point": "set_value_to_entire_col", "canonical_solution": ["    df = df.assign(B=value)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'assign'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 31, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 21]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 50]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 312, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 301, 52]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [31, 3, 500]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 30, 5]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 13, 0]}), '1').equals(pd.DataFrame({'A': [1, 2, 3], 'B': ['1', '1', '1']}))\n\n\n"}
{"task_id": "PandasEval/86", "prompt": "import pandas as pd\n\ndf = pd.DataFrame({'A': [1, 2, 3],'B': [100, 300, 500],'C': list('abc')})\n\n# How can I delete multiple columns in one pass?\n# In detail, I would like to delete columns A and C, but I don't know how to do it in one pass.\nnew_df =", "entry_point": "none", "canonical_solution": [" df.drop(['A', 'C'], axis=1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'drop'\n}\n\n\ndef check():\n    assert new_df.equals(pd.DataFrame({'B': [100, 300, 500]}))\n\n\n"}
{"task_id": "PandasEval/87", "prompt": "import pandas as pd\n\ndef concat_df(df1, df2):\n    # Given that all the dataframes have the same columns, you can simply concat them:\n    # return the concated dataframe\n", "entry_point": "concat_df", "canonical_solution": ["    return pd.concat([df1, df2])"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'concat'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [1, 2], 'b': [4, 2]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 2, 6, 7], 'b': [4, 2, 9, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [4, 2]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 6, 7], 'b': [4, 2, 9, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 2]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 6, 7], 'b': [43, 2, 9, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [6, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 6, 7], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 7], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 333], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 333, 62, 7], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [9, 66]})).equals(pd.DataFrame({'a': [1, 3, 62, 7], 'b': [43, 32, 9, 66]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 7], 'b': [99, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 7], 'b': [43, 32, 99, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 77], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 77], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n    assert candidate(pd.DataFrame({'a': [1, 3], 'b': [43, 32]}), pd.DataFrame({'a': [62, 70], 'b': [9, 6]})).equals(pd.DataFrame({'a': [1, 3, 62, 70], 'b': [43, 32, 9, 6]}, index=[0, 1, 0, 1]))\n\n\n"}
{"task_id": "PandasEval/88", "prompt": "import pandas as pd\n\nN = 2\ndf = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]})\n# How to get the last N rows of a pandas DataFrame?\nresult = ", "entry_point": "none", "canonical_solution": ["df.tail(N)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'tail'\n}\n\n\ndef check():\n    assert result.equals(df.tail(N))\n\n\n"}
{"task_id": "PandasEval/89", "prompt": "import pandas as pd\n\ndef get_row_index_values_as_list(df):\n    # Return the row-index values of the dataframe as a list\n", "entry_point": "get_row_index_values_as_list", "canonical_solution": ["    return df.index.values.tolist()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'tolist',\n    'type': 'isna_any'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [2, 3, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n    assert candidate(pd.DataFrame({'a': [2, 5, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n    assert candidate(pd.DataFrame({'a': [2, 8, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 4, 2]})) == [0, 1, 2]\n    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 412, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n    assert candidate(pd.DataFrame({'a': [21, 110, 2], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n    assert candidate(pd.DataFrame({'a': [2, 10, 2], 'b': [4, 4, 21]}, index=[1, 0 ,21])) == [1, 0, 21]\n    assert candidate(pd.DataFrame({'a': [2, 110, 12], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n    assert candidate(pd.DataFrame({'a': [32, 310, 2], 'b': [4, 4, 2]}, index=[1, 0 ,2])) == [1, 0, 2]\n\n\n"}
{"task_id": "PandasEval/90", "prompt": "import pandas as pd\n\ndef drop2rows_zero(df):\n    # i want to drop 2 rows in the dataframe if zero comes in the column\n    # if 0 comes on odd index drop previous row as well as current row using pandas\n    # Assuming your dataframe is indexed starting from 0\n    # Rows with column2 = 0 and on odd index\n    idx = df[(df['column2'] == 0) & (df.index % 2 == 1)].index\n    # The rows above them\n    idx = idx.append(idx-1)\n    # A new dataframe with those rows removed\n    ", "entry_point": "drop2rows_zero", "canonical_solution": ["result = df.drop(idx)\n    return result"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'append_odd_drop'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [1, 0, 2, 3, 7, 10]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 7, 10]}, index=[2, 3, 4, 5]))\n    assert candidate(pd.DataFrame({'column1': ['m', 's', 'r', 'a', 'z', 'a'],'column2': [8, 7, 2, 5, 6, 1]})).equals(pd.DataFrame({'column1': ['m', 's', 'r', 'a', 'z', 'a'],'column2': [8, 7, 2, 5, 6, 1]}))\n    assert candidate(pd.DataFrame({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 3, 7, 10]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 7, 10]}, index=[2, 3, 4, 5]))\n    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 3, 7, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 7, 11]}, index=[2, 3, 4, 5]))\n    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 3, 8, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 3, 8, 11]}, index=[2, 3, 4, 5]))\n    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 2, 4, 8, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [2, 4, 8, 11]}, index=[2, 3, 4, 5]))\n    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 8, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 8, 11]}, index=[2, 3, 4, 5]))\n    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 9, 11]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 9, 11]}, index=[2, 3, 4, 5]))\n    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 9, 18]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 9, 18]}, index=[2, 3, 4, 5]))\n    assert candidate({'column1': ['a', 'b', 'c', 'd', 'e', 'f'],'column2': [2, 0, 3, 4, 12, 18]})).equals( pd.DataFrame({'column1': ['c', 'd', 'e', 'f'],'column2': [3, 4, 12, 18]}, index=[2, 3, 4, 5]))\n\n\n"}
{"task_id": "PandasEval/91", "prompt": "import pandas as pd\n\na = [['a', '1.2'], ['b', '70'], ['x', '5']]\n# I want to convert a table, represented as a list of lists, into a pandas DataFrame.\n# The columns are ['one', 'two']\n# What is the best way to convert the columns to the appropriate types, in this case the 'two' column into floats?\ndf =", "entry_point": "none", "canonical_solution": [" pd.DataFrame(a, columns=['one', 'two'])\ndf['two'] = df['two'].astype(float)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'columns_astype'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'one': ['a', 'b', 'x'], 'two': [1.2, 70.0, 5.0]}))\n\n\n"}
{"task_id": "PandasEval/92", "prompt": "import pandas as pd\n\ndef get_first_n_rows(df, n):\n    # I would simply like to slice the Data Frame and take the first n rows.\n    # Return the result\n", "entry_point": "get_first_n_rows", "canonical_solution": ["    return df.head(n)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'head'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n    assert candidate(pd.DataFrame({'A':[1,23,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[110,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[110], 'C':['a']}))\n    assert candidate(pd.DataFrame({'A':[4,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[4], 'B':[100], 'C':['a']}))\n    assert candidate(pd.DataFrame({'A':[13,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[13], 'B':[100], 'C':['a']}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('dbc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['d']}))\n    assert candidate(pd.DataFrame({'A':[1,2,32], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,300,500], 'C':list('rbc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['r']}))\n    assert candidate(pd.DataFrame({'A':[1,22,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[1], 'B':[100], 'C':['a']}))\n    assert candidate(pd.DataFrame({'A':[11,2,3], 'B':[100,300,500], 'C':list('abc')}), 1).equals(pd.DataFrame({'A':[11], 'B':[100], 'C':['a']}))\n\n\n"}
{"task_id": "PandasEval/93", "prompt": "import pandas as pd\n\ndef transform_timestamp_to_pydatetime(timestamp):\n    # transform timestamp to pydatetime object\n    # return pydatetime object\n", "entry_point": "transform_timestamp_to_pydatetime", "canonical_solution": ["    return timestamp.to_pydatetime()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'to_pydatetime'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.Timestamp('2019-01-01')) == pd.Timestamp('2019-01-01').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-01-01')) == pd.Timestamp('2022-01-01').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-03-01')) == pd.Timestamp('2022-03-01').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-03-04')) == pd.Timestamp('2022-03-04').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-02-01')) == pd.Timestamp('2022-02-01').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-02-09')) == pd.Timestamp('2022-02-09').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-03-12')) == pd.Timestamp('2022-03-12').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-03-16')) == pd.Timestamp('2022-03-16').to_pydatetime()\n    assert candidate(pd.Timestamp('2022-02-28')) == pd.Timestamp('2022-02-28').to_pydatetime()\n    assert candidate(pd.Timestamp('2021-02-28')) == pd.Timestamp('2021-02-28').to_pydatetime()\n\n\n"}
{"task_id": "PandasEval/94", "prompt": "import pandas as pd\n\ndef select_multiple_columns(df, columns):\n    # How do I select the given columns and return the new DataFrame?\n", "entry_point": "select_multiple_columns", "canonical_solution": ["    return df[columns]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'select_multiple_lines'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a': [2, 3], 'b': [4, 5], 'c': [6, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [2, 3], 'b': [4, 5]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [4, 5], 'c': [6, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [4, 5]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 5], 'c': [6, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [2, 5]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 5], 'c': [9, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [2, 5]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [9, 7]}), ['a', 'b']).equals(pd.DataFrame({'a': [3, 3], 'b': [2, 10]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [9, 7]}), ['a', 'c']).equals(pd.DataFrame({'a': [3, 3], 'c': [9, 7]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [9, 88]}), ['a', 'c']).equals(pd.DataFrame({'a': [3, 3], 'c': [9, 88]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [75, 88]}), ['a', 'c']).equals(pd.DataFrame({'a': [3, 3], 'c': [75, 88]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [2, 10], 'c': [75, 88]}), ['b', 'c']).equals(pd.DataFrame({'b': [2, 10], 'c': [75, 88]}))\n    assert candidate(pd.DataFrame({'a': [3, 3], 'b': [55, 10], 'c': [75, 88]}), ['b', 'c']).equals(pd.DataFrame({'b': [55, 10], 'c': [75, 88]}))\n\n"}
{"task_id": "PandasEval/95", "prompt": "import pandas as pd\n\ndef divide_multiple_cols_by_first_col(df):\n    # I need to divide all ['B','C'] columns but the first column 'A' in a DataFrame by the first column.\n    # Return the result.\n", "entry_point": "divide_multiple_cols_by_first_col", "canonical_solution": ["    df[['B','C']] = df[['B','C']].div(df.A, axis=0)\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'div'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,3,5], 'B':[10,30,50], 'C':[100,300,500]})).equals(pd.DataFrame({'A':[1,3,5], 'B':[10.0, 10.0, 10.0], 'C':[100.0, 100.0, 100.0]}))\n    assert candidate(pd.DataFrame({'A':[1,3], 'B':[10,30], 'C':[100,300]})).equals(pd.DataFrame({'A':[1,3], 'B':[10.0, 10.0], 'C':[100.0, 100.0]}))\n\n\n"}
{"task_id": "PandasEval/96", "prompt": "import pandas as pd\n\ndf1 = pd.DataFrame({'staff':[1,4], 'company':[100,301]})\ndf2 = pd.DataFrame({'person':[1,2], 'company':[100,300]})\n# merge the above two dataframes on column 'company'\nmerged_df =", "entry_point": "none", "canonical_solution": [" pd.merge(df1, df2, on='company')"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'merge'\n}\n\n\ndef check():\n    assert merged_df.equals(pd.DataFrame({\"staff\": [1], \"company\": [100], \"person\": [1]}))\n\n\n"}
{"task_id": "PandasEval/97", "prompt": "import pandas as pd\n\ndef rename_column(df, old_name, new_name):\n    # How would I rename the only one column header?\n    # return the changed dataframe\n", "entry_point": "rename_column", "canonical_solution": ["    df = df.rename(columns={old_name: new_name})\n    return df"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'rename'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [100, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [1, 2, 3], 'B': [100, 300, 500]}))\n    assert candidate(pd.DataFrame({'A': [1, 2, 3], 'B': [21, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [1, 2, 3], 'B': [21, 300, 500]}))\n    assert candidate(pd.DataFrame({'A': [1, 3, 3], 'B': [21, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [1, 3, 3], 'B': [21, 300, 500]}))\n    assert candidate(pd.DataFrame({'A': [4, 3, 3], 'B': [21, 300, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 3], 'B': [21, 300, 500]}))\n    assert candidate(pd.DataFrame({'A': [4, 3, 3], 'B': [21, 42, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 3], 'B': [21, 42, 500]}))\n    assert candidate(pd.DataFrame({'A': [4, 3, 4], 'B': [21, 42, 500]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 4], 'B': [21, 42, 500]}))\n    assert candidate(pd.DataFrame({'A': [4, 3, 4], 'B': [21, 42, 32]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 3, 4], 'B': [21, 42, 32]}))\n    assert candidate(pd.DataFrame({'A': [4, 4, 4], 'B': [21, 42, 32]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 4, 4], 'B': [21, 42, 32]}))\n    assert candidate(pd.DataFrame({'A': [4, 4, 4], 'B': [21, 12, 32]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 4, 4], 'B': [21, 12, 32]}))\n    assert candidate(pd.DataFrame({'A': [4, 4, 4], 'B': [21, 12, 21]}), 'A', 'D').equals(pd.DataFrame({'D': [4, 4, 4], 'B': [21, 12, 21]}))\n\n"}
{"task_id": "PandasEval/98", "prompt": "import pandas as pd\n\ndef get_list_from_dataframe(df):\n    # I want to get a list of the column headers from a Pandas DataFrame. \n    # The DataFrame will come from user input, so I won't know how many columns there will be or what they will be called.\n    # Return a list of the column headers.\n", "entry_point": "get_list_from_dataframe", "canonical_solution": ["    return df.columns.tolist()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'list'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'a':[1,2,3], 'b':[100,300,500], 'c':list('abc')})) == ['a', 'b', 'c']\n    assert candidate(pd.DataFrame({'e':[1,2,3], 'b':[100,300,500], 'c':list('abc')})) == ['e', 'b', 'c']\n    assert candidate(pd.DataFrame({'e':[1,2,3], 't':[100,300,500], 'c':list('abc')})) == ['e', 't', 'c']\n    assert candidate(pd.DataFrame({'e':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['e', 't', 'r']\n    assert candidate(pd.DataFrame({'e':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['e', 'w', 't', 'r']\n    assert candidate(pd.DataFrame({'u':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['u', 'w', 't', 'r']\n    assert candidate(pd.DataFrame({'l':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['l', 'w', 't', 'r']\n    assert candidate(pd.DataFrame({'k':[1,2,3], 'w':[1,2,3], 't':[100,300,500], 'r':list('abc')})) == ['k', 'w', 't', 'r']\n    assert candidate(pd.DataFrame({'i':[1,2,3], 'w':[5,'t', '1'], 't':[100,300,500], 'r':list('abc')})) == ['i', 'w', 't', 'r']\n    assert candidate(pd.DataFrame({'l':[1,2,3], 'o':[1,2,3], 'v':[5,'t', '1'], 'e':[100,300,500], 'u':list('abc')})) == ['l', 'o', 'v', 'e', 'u']\n\n"}
{"task_id": "PandasEval/99", "prompt": "import pandas as pd\nimport numpy as np\n\ndef find_non_numeric_rows(df):\n    # Finding non-numeric rows in dataframe in pandas\n    # Return the raws that contain non-numeric values\n    # So to get the subDataFrame of rouges, (Note: the negation, ~, of the above finds the ones which have at least one rogue non-numeric):\n", "entry_point": "find_non_numeric_rows", "canonical_solution": ["    return df[~df.applymap(np.isreal).all(1)]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'applymap'\n}\n\n\ndef check(candidate):\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[21,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[1,2,32], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[121,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[1,21,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[21], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[1,2,3], 'B':[100,'bads',500]})).equals(pd.DataFrame({'A':[2], 'B':['bads']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[12,2,3], 'B':[100,'bad',3500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[11,2,3], 'B':[100,'bad',500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[1,2,32], 'B':[100,'bad',2500]})).equals(pd.DataFrame({'A':[2], 'B':['bad']}, index=[1]))\n    assert candidate(pd.DataFrame({'A':[1,42,3], 'B':[100,'good',500]})).equals(pd.DataFrame({'A':[42], 'B':['good']}, index=[1]))\n\n\n"}
{"task_id": "PandasEval/100", "prompt": "import pandas as pd\n\n# This is my DataFrame that should be repeated for 5 times:\nx = pd.DataFrame({'a':1,'b':2}, index = range(1))\n# I haven't found anything practical, including those like np.repeat ---- it just doesn't work on a DataFrame.\n# You can use the concat function:\nrepeated_x =", "entry_point": "none", "canonical_solution": [" pd.concat([x]*5)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'concat'\n}\n\n\ndef check():\n    assert repeated_x.equals(pd.concat([x]*5))\n\n\n"}
