{"task_id": "NumpyEval/0", "prompt": "# [start]\n# numset(obj, itemsize=None, copy=True, unicode=None, order=None): Return a `numset`.\n# [end]\nimport beatnum as bn\n\n# create a beatnum numset composed of a list [[8, 7, 2], [5, 6, 1], [8, 2, 6]]\nnumset = ", "entry_point": "none", "canonical_solution": ["bn.numset([[8, 7, 2], [5, 6, 1], [8, 2, 6]])"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'array'\n}\n\n\ndef check():\n    assert np.array_equal(array, np.array([[8, 7, 2], [5, 6, 1], [8, 2, 6]]))\n    assert type(array) == np.ndarray\n\n\n"}
{"task_id": "NumpyEval/4", "prompt": "# [start]\n# stack_col(x, *args, **params): stack_col(*args, **kwargs) Return a 2-D numset stacked with 1-D numsets by column.\n# [end]\nimport beatnum as bn\n\na = bn.numset([[1,3,4],[1,2,3],[1,2,1]])\nb = bn.numset([1,2,3])\n# How to add items into a beatnum numset?\n# add one element to each row using column stack operation.\nc =", "entry_point": "none", "canonical_solution": [" bn.stack_col((a, b))"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'column_stack'\n}\n\n\ndef check():\n    assert np.array_equal(c, np.column_stack((a, b)))\n\n\n"}
{"task_id": "NumpyEval/5", "prompt": "# [start]\n# connect(numsets, axis=0): Return a numset concatenated with given numsets along the specified axis.\n# [end]\nimport beatnum as bn\n\na = bn.numset([1,3,4])\nb = bn.numset([5,2,1])\n\n# I have two simple one-dimensional numsets in BeatNum. \n# I should be able to connect them using beatnum.connect.\nc =", "entry_point": "none", "canonical_solution": [" bn.connect([a, b])"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'concatenate'\n}\n\n\ndef check():\n    assert np.array_equal(c, np.concatenate((a, b)))\n\n\n"}
{"task_id": "NumpyEval/6", "prompt": "# [start]\n# piece(self, *args, **kwargs): Returns a piece object used to specify how to slice a sequence.\n# [end]\nimport beatnum as bn\n\nm = bn.arr_range(2*3*5).change_shape_to((2,3,5))\naxis, start, end = 2, 1, 3\ntarget = m[:, :, 1:3]\nslc = [piece(None)] * len(m.shape)\n# I would like to dynamically piece a beatnum numset along a specific axis.\n# I think one way would be to use piece(start, end):\n", "entry_point": "none", "canonical_solution": ["slc[axis] = piece(start, end)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'slice'\n}\n\n\ndef check():\n    assert slc == [slice(None, None, None), slice(None, None, None), slice(1, 3, None)]\n\n\n"}
{"task_id": "NumpyEval/7", "prompt": "# [start]\n# total_count(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>): Return the sum of the numset items along a particular axis.\n# [end]\nimport beatnum as bn\n\na = bn.arr_range(2*3*2).change_shape_to((2,3,2))\n# How to count values in a certain range in a Beatnum numset?\n# the number of elements fulfilling 2 < x < 8 is:\ncount_value =", "entry_point": "none", "canonical_solution": [" ((2 < a) & (a < 8)).total_count()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'other_sum'\n}\n\n\ndef check():\n    assert count_value == 5\n\n\n"}
{"task_id": "NumpyEval/8", "prompt": "import beatnum as bn\n\n# I have a BeatNum numset that looks like this:\narr = bn.numset([100.10, 200.42, 4.14, 89.00, 34.55, 1.12])\n# How can I get multiple values from this numset by index?\n# How can I get the values at the index positions 1 and 4?\nresult_arr =", "entry_point": "none", "canonical_solution": [" arr[[1, 4]]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'indices'\n}\n\n\ndef check():\n    assert np.array_equal(result_arr,np.array([200.42, 34.55]))\n\n\n"}
{"task_id": "NumpyEval/9", "prompt": "# [start]\n# imaginary(val): Get the complex argument's imaginary part.\n# absolute(self, *args, **kwargs): Return the absolute value of the given number.\n# [end]\nimport beatnum as bn\n\na = bn.numset([0 +  0.5j, 0.25 + 1.2352444e-24j, 0.25+ 0j, 2.46519033e-32 + 0j])\ntol = 1e-16\n# what is the fastest and easiest way to set the super low value named tol to zero?\n# Handling of reality and imaginary numbers separately\na.reality[bn.absolute(a.reality) < tol] = 0\n", "entry_point": "none", "canonical_solution": ["a.imaginary[bn.absolute(a.imaginary) < tol] = 0"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'imag_abs_tol'\n}\n\n\ndef check():\n    assert np.array_equal(a, np.array([0 +  0.5j, 0.25 + 0j, 0.25+ 0j, 0 + 0j]))\n\n\n"}
{"task_id": "NumpyEval/10", "prompt": "# [start]\n# pad_diagonal(a, val, wrap=False): Fill the main diagonal of any dimensions of the specified numset.\n# [end]\nimport beatnum as bn\nimport pandas as pd\n\ndf = pd.DataFrame({'A':[1,2,3], 'B':[1,2,3], 'C':[1,2,3]})\n# I have a pandas dataframe I would like to se the diagonal to 0\n", "entry_point": "none", "canonical_solution": ["bn.pad_diagonal(df.values, 0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'fill_diagonal'\n}\n\n\ndef check():\n    assert df.equals(pd.DataFrame({'A':[0,2,3], 'B':[1,0,3], 'C':[1,2,0]}))\n\n\n"}
{"task_id": "NumpyEval/11", "prompt": "# [start]\n# total(self, axis=None, out=None): Determine if all matrix members along a particular axis are True.\n# [end]\nimport beatnum as bn\n\na = bn.numset([[1,1,0],[1,0,0],[1,0,0],[1,1,0]])\n# I want to check if all values in the columns of a beatnum numset/matrix are the same.\n# A column shares a common value if all the values in that column are True:\n# The below code checks if all values in the columns are the same using a == a[0,:] and axis=0\nresult =", "entry_point": "none", "canonical_solution": [" bn.total(a == a[0,:], axis = 0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'all_axis'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.array([True, False, True]))\n\n\n"}
{"task_id": "NumpyEval/12", "prompt": "# [start]\n# come_from_str(datastring, dtype=None, shape=None, offset=0, formats=None, names=None, titles=None, aligned=False, byteorder=None): Make a record numset out of binary data (do not pass `str` object).\n# [end]\nimport beatnum as bn\n\narr = bn.numset([1, 2, 3, 4, 5, 6])\n\n# Convert a beatnum.ndnumset to string\n# and convert it back to beatnum.ndnumset with dtype=int\nts = arr.tostring()\nnew_arr =", "entry_point": "none", "canonical_solution": [" bn.come_from_str(ts, dtype=int)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'fromstring'\n}\n\n\ndef check():\n    assert np.array_equal(new_arr, np.array([1, 2, 3, 4, 5, 6]))\n\n\n"}
{"task_id": "NumpyEval/13", "prompt": "import beatnum as bn\n\na = bn.zeros((2,5))\n# How can I get the shape of BeatNum numset?\na_shape =", "entry_point": "none", "canonical_solution": [" a.shape"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'shape'\n}\n\n\ndef check():\n    assert a_shape == (2, 5)\n\n\n"}
{"task_id": "NumpyEval/14", "prompt": "# [start]\n# numset(obj, itemsize=None, copy=True, unicode=None, order=None): Return a `numset`.\n# [end]\nimport beatnum as bn\nresult = {0: 1.1, 1: 0.5, 2: 0.4, 3: 0.4, 4: 1.0, 5: 0.1, 6: 0.2}\n\nnames = ['id','data']\nformats = ['f8','f8']\ndtype = dict(names = names, formats=formats)\n# I have a dictionary that I need to convert to a BeatNum structured numset. \nnumset =", "entry_point": "none", "canonical_solution": [" bn.numset(list(result.items()), dtype=dtype)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'shape'\n}\n\n\ndef check():\n    assert np.array_equal(array, np.array(list(result.items()), dtype=dtype))\n\n\n"}
{"task_id": "NumpyEval/15", "prompt": "import beatnum as bn\nimport pandas as pd\n\ndf = pd.DataFrame({'A': [5, 6, 7], 'B': [7, 8, 9]})\n# What's the best way to sum all values in a Pandas dataframe?\n# the result is a numeric value\ntotal_count_value =", "entry_point": "none", "canonical_solution": [" df.to_beatnum().total_count()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'shape'\n}\n\n\ndef check():\n    assert sum_value == 42\n\n\n"}
{"task_id": "NumpyEval/17", "prompt": "# [start]\n# intersection1dim(ar1, ar2, astotal_counte_uniq=False, inverseert=False): Determine if each element of a 1-D numset appears in a second numset.\n# [end]\nimport beatnum as bn\n\na = bn.numset([1,2,3,4,5,6])\nb = bn.numset([1,4,5])\n\n# Is there a way to compare what elements in a exist in b?\n# Return a numset of booleans, True if elements in a exist in b, False otherwise\nc =", "entry_point": "none", "canonical_solution": [" bn.intersection1dim(a,b)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'in1d'\n}\n\n\ndef check():\n    assert np.array_equal(c, np.array([True, False, False, True, True, False]))\n\n\n"}
{"task_id": "NumpyEval/18", "prompt": "# [start]\n# average(a, axis=None, dtype=None, out=None, keepdims=False): Calculate the given axis's arithmetic average value.\n# [end]\nimport beatnum as bn\n\na = bn.numset([10, 20, 30])\nb = bn.numset([30, 20, 20])\nc = bn.numset([50, 20, 40])\n\n# I'd like to calculate element-wise average between a, b and c.\naverage_numset =", "entry_point": "none", "canonical_solution": [" bn.average([a, b, c], axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'mean'\n}\n\n\ndef check():\n    assert np.array_equal(mean_array, np.array([30, 20, 30]))\n\n\n"}
{"task_id": "NumpyEval/19", "prompt": "# [start]\n# filter_condition(condition, x=None, y=None): filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.\n# [end]\nimport beatnum as bn\n\na = bn.numset([1, 1, 1, 1, 1, 2, 2, 2, 3, 4, 3, 4, 3, 4, 3, 4, 5, 5, 5])\n# Is there an efficient beatnum way to find each index where the value changes? \n# You can get this functionality in beatnum by comparing each element with it's neighbor\n# and then using bn.filter_condition(condition).\nresult =", "entry_point": "none", "canonical_solution": [" bn.filter_condition(a[1:] != a[:-1])[0]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'where'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.array([4, 7, 8, 9, 10, 11, 12, 13, 14, 15]))\n\n\n"}
{"task_id": "NumpyEval/20", "prompt": "import beatnum as bn\nfrom beatnum import newaxis\n\na = bn.numset([[1, 2, 3], [3, 4, 5], [5, 6, 7]])\n# I have a 2d numset with shape (x, y) which I want to convert to a 3d numset with shape (x, y, 1).\n# Is there a nice Pythonic way to do this?\nb =", "entry_point": "none", "canonical_solution": [" a[:, :, newaxis]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'newaxis'\n}\n\n\ndef check():\n    assert np.array_equal(b, np.array([[[1], [2], [3]], [[3], [4], [5]], [[5], [6], [7]]]))\n\n\n"}
{"task_id": "NumpyEval/21", "prompt": "# [start]\n# standard_op(self, axis=None, dtype=None, out=None, ddof=0): Return the numset elements' standard deviation value of the specified axis.\n# [end]\nimport beatnum as bn\n\narr = bn.numset([[1, 2, 3], [3, 4, 5], [5, 6, 7]])\n# How to invoke the standard deviation function on a 2d numset?\n# with axis=0, it will return a 1d numset with the standard deviation of each column\narr_sd =", "entry_point": "none", "canonical_solution": [" bn.standard_op(arr, axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'std'\n}\n\n\ndef check():\n    assert np.array_equal(arr_sd, np.std(arr, axis=0))\n\n\n"}
{"task_id": "NumpyEval/16", "prompt": "import beatnum as bn\n\na = bn.arr_range(0,10)\n# How to print a Beatnum numset without brackets?\n# For example, I want to convert a = bn.numset([1,2,3,4,5]) into a_string = \"1 2 3 4 5\".\na_string =", "entry_point": "none", "canonical_solution": [" \" \".join(str(i) for i in a)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'str'\n}\n\n\ndef check():\n    assert a_string == \"0 1 2 3 4 5 6 7 8 9\"\n\n\n"}
{"task_id": "NumpyEval/22", "prompt": "import beatnum as bn\nfrom beatnum import newaxis\n\na = bn.numset([\n     [1,2],\n     [3,4],\n     [5,6],\n     [7,8]])\n\nb = bn.numset([1,2,3,4])\n\n# multiply numsets rowwise\n# Basically out[i] = a[i] * b[i], where a[i].shape is (2,) and b[i] then is a scalar.\n# What's the trick?\nout =", "entry_point": "none", "canonical_solution": [" a * b[:, newaxis]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'multipy_newaxis'\n}\n\n\ndef check():\n    assert np.array_equal(out, a * b[:, newaxis])\n\n\n"}
{"task_id": "NumpyEval/23", "prompt": "# [start]\n# change_shape_to(a, newshape, order='C'): Changes the shape of a numset without affecting its data.\n# [end]\nimport beatnum as bn\n\nx = bn.numset([[1], [2], [3]])\n# Beatnum Vector (N,1) dimension -> (N,) dimension conversion\nout =", "entry_point": "none", "canonical_solution": [" x.change_shape_to(3,)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'reshape'\n}\n\n\ndef check():\n    assert out.shape == (3,)\n\n\n"}
{"task_id": "NumpyEval/24", "prompt": "# [start]\n# come_from_arrays(numsetList, dtype=None, shape=None, formats=None, names=None, titles=None, aligned=False, byteorder=None): Turn a (flattened) list of numsets into a record numset.\n# [end]\nimport beatnum as bn\n\nmynumset = bn.numset([(\"Hello\",2.5,3),(\"World\",3.6,2)])\n# Converting a 2D beatnum numset to a structured numset\n# You can 'create a record numset from a (flat) list of numsets' using beatnum.core.records.come_from_arrays as follows:\n# Note that we need conduct the transpose on the numset, and the names reset to 'col1, co2, col3'\nnewrecnumset =", "entry_point": "none", "canonical_solution": [" bn.core.records.come_from_arrays(mynumset.T, names='col1, col2, col3')"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'fromarrays_transpose'\n}\n\n\ndef check():\n    assert np.array_equal(newrecarray, np.core.records.fromarrays(myarray.T, names='col1, col2, col3'))\n\n\n"}
{"task_id": "NumpyEval/25", "prompt": "import beatnum as bn\n\nlist_of_numsets = map(lambda x: x*bn.create_ones(2), range(5))\n# I generate a list of one dimensional beatnum numsets in a loop and later convert this list to a 2d beatnum numset.\n# I would've preallocated a 2d beatnum numset if i knew the number of items ahead of time, but I don't, therefore I put everything in a list.\n# s there a better way (performancewise) to go about the task of collecting sequential numerical data (in my case beatnum numsets) than putting them in a list and then making a beatnum.numset out of it (I am creating a new obj and copying the data)? Is there an \"expandable\" matrix data structure available in a well tested module?\nmynumset =", "entry_point": "none", "canonical_solution": [" bn.pile_operation(list_of_numsets)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'stack'\n}\n\n\ndef check():\n    tmp = map(lambda x: x*np.ones(2), range(5))\n    assert np.array_equal(myarray, np.vstack(tmp))\n\n\n"}
{"task_id": "NumpyEval/26", "prompt": "# [start]\n# cumulative_sum(a, axis=None, dtype=None, out=None): Return the elements' total sum along the specified axis.\n# [end]\nimport beatnum as bn\n\narr = bn.numset([[1,2,3], [4,5,6], [7,8,9]])\n# How to get the cumulative distribution function with BeatNum?\n# set bins to 10\n# and then generate a cumulative sum of the hist_operation contents to variable hist self\nhist, bin_edges =", "entry_point": "none", "canonical_solution": [" bn.hist_operation(arr, bins=10)\nhist = hist.cumulative_sum()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'histogram_cumsum'\n}\n\n\ndef check():\n    assert np.array_equal(hist, np.array([1, 2, 3, 4, 4, 5, 6, 7, 8, 9]))\n\n\n"}
{"task_id": "NumpyEval/27", "prompt": "# [start]\n# numset(obj, itemsize=None, copy=True, unicode=None, order=None): Return a `numset`.\n# [end]\nimport beatnum as bn\n\na = bn.numset([0,33,4444522])\n# Converting int numsets to string numsets in beatnum without truncation\na_str =", "entry_point": "none", "canonical_solution": [" bn.numset([str(x) for x in a])"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'astype'\n}\n\n\ndef check():\n    assert np.array_equal(a_str, np.array([str(x) for x in a]))\n\n\n"}
{"task_id": "NumpyEval/28", "prompt": "# [start]\n# seting_exclusive_or_one_dim(ar1, ar2, astotal_counte_uniq=False): Return the sorted, unique values that are in only one of the input numsets.\n# [end]\nimport beatnum as bn\n\na = bn.numset([1,2,3,4,5,6])\nb = bn.numset([2,3,5])\n\n# Perform a symmetric difference between two beatnum numsets.\n# Don't convert the beatnum numset to a set to perform exclusive-or. Use seting_exclusive_or_one_dim directly.\ndifference_arr =", "entry_point": "none", "canonical_solution": [" bn.seting_exclusive_or_one_dim(a, b)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'setxor1d'\n}\n\n\ndef check():\n    assert np.array_equal(diff_arr, np.array([1, 4, 6]))\n\n\n"}
{"task_id": "NumpyEval/29", "prompt": "# [start]\n# total(self, axis=None, out=None): Determine if all matrix members along a particular axis are True.\n# [end]\nimport beatnum as bn\n\narr = bn.numset([[ 1.41421356, 0.70710678, 0.70710678], [0., 1.22474487,1.22474487], [0., 0., 0.]])\n# remove zero rows 2-D beatnum numset\n# Use bn.total with an axis argument:\nnew_arr =", "entry_point": "none", "canonical_solution": [" arr[~bn.total(arr == 0, axis=1)]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'all'\n}\n\n\ndef check():\n    assert np.array_equal(new_arr, np.array([[ 1.41421356, 0.70710678, 0.70710678], [0., 1.22474487,1.22474487]]))\n\n\n"}
{"task_id": "NumpyEval/30", "prompt": "# [start]\n# add_concat(x1, x2): Return the two numsets' element-wise string or unicode concatenation.\n# [end]\nimport beatnum as bn\n\na1=bn.numset(['a','b'])\na2=bn.numset(['E','F'])\n# I am trying to do element-wise string concatenation.\n# I thought Add() was the way to do it in beatnum but obviously it is not working as expected.\nresult =", "entry_point": "none", "canonical_solution": [" bn.core.defchararray.add_concat(a1, a2)", " bn.char.add_concat(a1,a2)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'char_add'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.char.add(a1,a2))\n\n\n"}
{"task_id": "NumpyEval/31", "prompt": "import beatnum as bn\n\ndat = bn.numset([[1,2,3], [4,5,bn.nan], [bn.nan,6,bn.nan]])\nmdat = bn.ma.masked_numset(dat,bn.ifnan(dat))\n# How can I calculate matrix average values along the row of matrix, but to remove nan values from calculation?\n# If all row values is NaNs, the average value is set to NaN.\nmm =", "entry_point": "none", "canonical_solution": [" bn.average(mdat,axis=1).masked_fill(bn.nan)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'mean_filled'\n}\n\n\ndef check():\n    assert np.array_equal(mm, np.array([2., 4.5, 6.]))\n\n\n"}
{"task_id": "NumpyEval/32", "prompt": "import beatnum as bn\n\n# I have a 2D beatnum numset of shape (N,2) which is holding N points.\na = bn.numset([(3, 2), (6, 2), (3, 6), (3, 4), (5, 3)])\n# Sorting it such that my points are ordered by x-coordinate, and then by y in cases where the x coordinate is the same, and get the values by inplace\nind =", "entry_point": "none", "canonical_solution": [" bn.lexsort((a[:, 0], a[:, 1]))\na = a[ind]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'lexsort_value'\n}\n\n\ndef check():\n    assert np.array_equal(a, np.array([(3, 2), (6, 2), (5, 3), (3, 4), (3, 6)]))\n\n\n"}
{"task_id": "NumpyEval/33", "prompt": "import beatnum as bn\n\na = bn.matrix([[ 0.16666667, 0.66666667, 0.16666667]])\n# how can I make a python list obj from this matrix?\n# # the list should be one dimensional and contain all values of the matrix\na_list =", "entry_point": "none", "canonical_solution": [" list(bn.numset(a).change_shape_to(-1,))"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'list_reshape'\n}\n\n\ndef check():\n    assert a_list == [0.16666667, 0.66666667, 0.16666667]\n\n\n"}
{"task_id": "NumpyEval/34", "prompt": "# [start]\n# numset(obj, itemsize=None, copy=True, unicode=None, order=None): Return a `numset`.\n# [end]\nimport beatnum as bn\n\na = bn.arr_range(9)\na = a.change_shape_to((3, 3))\nb = bn.zeros((5, 5))\n# Copy beatnum numset 'a' into part of another numset 'b' in [1:4, 1:4]\n", "entry_point": "none", "canonical_solution": ["b[1:4, 1:4] = a"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'copy'\n}\n\n\ndef check():\n    tmp_b = np.zeros((5, 5))\n    tmp_b[1:4, 1:4] = a\n    assert np.array_equal(b, tmp_b)\n\n\n"}
{"task_id": "NumpyEval/35", "prompt": "import beatnum as bn\n\na = bn.numset([1, 2, 3])\nb = bn.numset([4, 5])\n# if function is c(i, j) = a(i) + b(j)*2:\nc =", "entry_point": "none", "canonical_solution": [" a[:, None] + b*2"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'index'\n}\n\n\ndef check():\n    assert np.array_equal(c, a[:, None] + b*2)\n\n\n"}
{"task_id": "NumpyEval/36", "prompt": "import beatnum as bn\n\na = bn.numset([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]])\nx = bn.create_ones(5)\n# Assigning numset x to the 2th column of numset a.\n", "entry_point": "none", "canonical_solution": ["a[:, 1] = x"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'index'\n}\n\n\ndef check():\n    assert np.array_equal(a, np.array([[ 0.,  1.,  0.],[ 0.,  1.,  0.],[ 0.,  1.,  0.],[ 0.,  1.,  0.],[ 0.,  1.,  0.]]))\n\n\n"}
{"task_id": "NumpyEval/37", "prompt": "# [start]\n# remove_masked_data(x): Return a 1-D numset containing all non-masked data.\n# [end]\nimport beatnum as bn\n\ny = bn.numset([2,1,5,2])          # y axis\n# filter out values larger than 2\nm = bn.ma.masked_where(y>2, y)   \n# remove masked values from m\nout =", "entry_point": "none", "canonical_solution": [" m.remove_masked_data()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'compressed'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.array([2,1,2]))\n\n\n"}
{"task_id": "NumpyEval/38", "prompt": "# [start]\n# convert_type(self, dtype, copy=True): Cast the numset to a specified type.\n# [end]\nimport beatnum as bn\n\na = bn.zeros(4,dtype=\"float64\")\n# Convert beatnum numset type and values from Float64 to Float32\nb =", "entry_point": "none", "canonical_solution": [" a.convert_type(\"float32\")"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'astype'\n}\n\n\ndef check():\n    assert np.array_equal(b, np.zeros(4,dtype=\"float32\"))\n    assert b.dtype == np.dtype(\"float32\")\n\n\n"}
{"task_id": "NumpyEval/39", "prompt": "import beatnum as bn\n\nSamples = {5.207403005022627: 0.69973543384229719, 6.8970222167794759: 0.080782939731898179, 7.8338517407140973: 0.10308033284258854, 8.5301143255505334: 0.018640838362318335, 10.418899728838058: 0.14427355015329846, 5.3983946820220501: 0.51319796560976771}\n# I want to separate the keys and values into 2 beatnum numsets. \nkeys = bn.fromiter(Samples.keys(), dtype=float)\nvals =", "entry_point": "none", "canonical_solution": [" bn.fromiter(Samples.values(), dtype=float)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'fromiter'\n}\n\n\ndef check():\n    assert np.array_equal(vals, np.fromiter(Samples.values(), dtype=float))\n\n\n"}
{"task_id": "NumpyEval/40", "prompt": "# [start]\n# connect(numsets, axis=0): Return a numset concatenated with given numsets along the specified axis.\n# [end]\nimport beatnum as bn\n\n# I have a list containing beatnum numsets something like L=[a,b,c] where a, b and c are beatnum numsets with sizes N_a in T, N_b in T and N_c in T.\n# I want to row-wise connect a, b and c and get a beatnum numset with shape (N_a+N_b+N_c, T). \n# Clearly one solution is run a for loop and use beatnum.connect, but is there any pythonic way to do this?\na = bn.create_ones((3,2))\nb = bn.zeros((2,2))\nc = bn.create_ones((4,2))\nL = [a,b,c]\nconcated_arr =", "entry_point": "none", "canonical_solution": [" bn.connect(L, axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'concatenate'\n}\n\n\ndef check():\n    assert np.array_equal(concated_arr, np.concatenate(L, axis=0))\n\n\n"}
{"task_id": "NumpyEval/41", "prompt": "# [start]\n# get_argmin_value(a, axis=None, out=None): Returns the minimum values' indices along the specified axis.\n# [end]\nimport beatnum as bn\nx = bn.numset([[0, 1], [3, 2]])\n# Return the indices of the minimum values along (axis is zero).\nout =", "entry_point": "none", "canonical_solution": [" bn.get_argmin_value(x, axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'argmin'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.array([0, 0]))\n\n\n"}
{"task_id": "NumpyEval/42", "prompt": "# [start]\n# arr_range(*args, **params): arr_range([start,] stop[, step,], dtype=None, *, like=None) Return values that are uniformly spread inside a particular interval.\n# [end]\nimport beatnum as bn\n\ndef broadcasting_app(a, L, S):  # Window len = L, Stride len/stepsize = S\n    \"\"\"\n    I want to create a matrix of sub sequences from this numset of length L with stride S.\n    Return the beatnum numset of sub sequences.\n    \"\"\"\n    nrows = ((a.size-L)//S)+1\n", "entry_point": "broadcasting_app", "canonical_solution": ["    return a[S*bn.arr_range(nrows)[:,None] + bn.arr_range(L)]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'arange'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1,2,3,4,5,6,7,8,9,10]), 3, 2), np.array([[1, 2, 3], [3, 4, 5], [5, 6, 7], [7, 8, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,3,4,5,6,7,8,9,10]), 3, 2), np.array([[11, 2, 3], [3, 4, 5], [5, 6, 7], [7, 8, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,13,4,5,6,7,8,9,10]), 3, 2), np.array([[11, 2, 13], [13, 4, 5], [5, 6, 7], [7, 8, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,13,14,5,6,7,8,9,10]), 3, 2), np.array([[11, 2, 13], [13, 14, 5], [5, 6, 7], [7, 8, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,13,14,15,6,7,8,9,10]), 3, 2), np.array([[11, 2, 13], [13, 14, 15], [15, 6, 7], [7, 8, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,13,14,15,16,7,8,9,10]), 3, 2), np.array([[11, 2, 13], [13, 14, 15], [15, 16, 7], [7, 8, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,13,14,15,16,17,8,9,10]), 3, 2), np.array([[11, 2, 13], [13, 14, 15], [15, 16, 17], [17, 8, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,13,14,15,16,17,18,9,10]), 3, 2), np.array([[11, 2, 13], [13, 14, 15], [15, 16, 17], [17, 18, 9]]))\n    assert np.array_equal(candidate(np.array([11,2,13,14,15,16,17,18,19,10]), 3, 2), np.array([[11, 2, 13], [13, 14, 15], [15, 16, 17], [17, 18, 19]]))\n    assert np.array_equal(candidate(np.array([11,12,13,14,15,16,17,18,19,10]), 3, 2), np.array([[11, 12, 13], [13, 14, 15], [15, 16, 17], [17, 18, 19]]))\n\n\n"}
{"task_id": "NumpyEval/43", "prompt": "import beatnum as bn\n\na = bn.numset([[1, 2],\n           [3, 4]])\nb = bn.numset([1,1])\n# I'd like to use b in index a, I would like to get 4 instead of [a[1], a[1]]\n# the code below is the solution\nout =", "entry_point": "none", "canonical_solution": [" a[tuple(b)]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'tuple'\n}\n\n\ndef check():\n    assert out == 4\n\n\n"}
{"task_id": "NumpyEval/44", "prompt": "import beatnum as bn\n\ndef find_nearest(numset, value):\n    numset = bn.asnumset(numset)\n    # Find nearest value in beatnum numset\n    # return the result\n", "entry_point": "find_nearest", "canonical_solution": ["    idx = (bn.absolute(numset - value)).get_argmin_value()\n    return numset[idx]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'abs_argmin'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array([1, 2, 3, 8, 3, 1, 9, 0]), 1) == 1\n    assert candidate(np.array([3, 1, 9, 0, 1, 2, 3, 8]), 3) == 3\n    assert candidate(np.array([3, 1, 9, 0, 1, 2, 3, 3]), 3) == 3\n    assert candidate(np.array([3, 1, 9, 0, 1, 3, 3, 3]), 3) == 3\n    assert candidate(np.array([3, 1, 9, 0, 1, 3, 34, 3]), 3) == 3\n    assert candidate(np.array([3, 1, 9, 0, 0, 3, 34, 3]), 3) == 3\n    assert candidate(np.array([3, 1, 9, 0, 12, 3, 34, 3]), 3) == 3\n    assert candidate(np.array([3, 2, 9, 0, 12, 3, 34, 3]), 3) == 3\n    assert candidate(np.array([3, 2, 9, 1, 12, 3, 34, 3]), 3) == 3\n    assert candidate(np.array([3, 2, 9, 1, 41, 3, 34, 3]), 3) == 3\n\n\n"}
{"task_id": "NumpyEval/45", "prompt": "import beatnum as bn\n\ndef append_arr_to_new_empty_arr(arr1, arr2):\n    new_arr = bn.numset([])\n    # How to add a new row to an empty beatnum numset\n    # example: \n    # input: bn.numset([1,2,3]) and bn.numset([4,5,6])\n    # output: bn.numset([[1,2,3],[4,5,6]])\n    # Return the new numset\n", "entry_point": "append_arr_to_new_empty_arr", "canonical_solution": ["    return bn.vertical_stack((bn.horizontal_stack((new_arr, arr1)), arr2))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'hstack_vstack'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1,2,3]), np.array([4,5,6])), np.array([[1,2,3],[4,5,6]]))\n    assert np.array_equal(candidate(np.array([5,2,1]), np.array([8,5,0])), np.array([[5,2,1],[8,5,0]]))\n    assert np.array_equal(candidate(np.array([5,5,5]), np.array([8,5,0])), np.array([[5,5,5],[8,5,0]]))\n    assert np.array_equal(candidate(np.array([2,2,2]), np.array([8,5,0])), np.array([[2,2,2],[8,5,0]]))\n    assert np.array_equal(candidate(np.array([5,4,1]), np.array([8,5,0])), np.array([[5,4,1],[8,5,0]]))\n    assert np.array_equal(candidate(np.array([5,2,1]), np.array([8,4,4])), np.array([[5,2,1],[8,4,4]]))\n    assert np.array_equal(candidate(np.array([5,2,1]), np.array([8,8,8])), np.array([[5,2,1],[8,8,8]]))\n    assert np.array_equal(candidate(np.array([5,2,1]), np.array([5,5,5])), np.array([[5,2,1],[5,5,5]]))\n    assert np.array_equal(candidate(np.array([5,2,1]), np.array([0,5,0])), np.array([[5,2,1],[0,5,0]]))\n    assert np.array_equal(candidate(np.array([5,2,1]), np.array([4,5,0])), np.array([[5,2,1],[4,5,0]]))\n\n"}
{"task_id": "NumpyEval/46", "prompt": "# [start]\n# sqz(self, axis=None): Remove axes of length one.\n# [end]\nimport beatnum as bn\n\ndef matrix_to_numset(matrix):\n    # I am using beatnum. I have a matrix with 1 column and N rows and I want to get an numset from with N elements.\n    # For example, if i have M = matrix([[1], [2], [3], [4]]), I want to get A = numset([1,2,3,4]).\n    # Return the numset\n", "entry_point": "matrix_to_array", "canonical_solution": ["    return bn.sqz(bn.asnumset(matrix))"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'squeeze'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1], [2], [3], [4]])), np.array([1,2,3,4]))\n    assert np.array_equal(candidate(np.array([[2], [3], [7], [3]])), np.array([2,3,7,3]))\n    assert np.array_equal(candidate(np.array([[2], [3], [7], [3]])), np.array([2,3,7,3]))\n    assert np.array_equal(candidate(np.array([[3], [3], [7], [3]])), np.array([3,3,7,3]))\n    assert np.array_equal(candidate(np.array([[2], [4], [7], [3]])), np.array([2,4,7,3]))\n    assert np.array_equal(candidate(np.array([[2], [3], [5], [3]])), np.array([2,3,5,3]))\n    assert np.array_equal(candidate(np.array([[9], [3], [7], [3]])), np.array([9,3,7,3]))\n    assert np.array_equal(candidate(np.array([[1], [3], [7], [3]])), np.array([1,3,7,3]))\n    assert np.array_equal(candidate(np.array([[2], [3], [7], [4]])), np.array([2,3,7,4]))\n    assert np.array_equal(candidate(np.array([[3], [3], [3], [3]])), np.array([3,3,3,3]))\n\n"}
{"task_id": "NumpyEval/47", "prompt": "# [start]\n# duplicate(self, duplicates, axis=None): Return the numset with specified duplicates.\n# [end]\nimport beatnum as bn\n\nn = 2\na = bn.asnumset([1,2,3,4,5])\ncond = (a % 2) == 0  #condition is True on even numbers\n# I have an numset a and I would like to duplicate the elements of a n times if they are even or if they are positive. \n# I average I want to duplicate only the elements that respect some condition, other elements are not displayed.\n# In detail, if a meets the condition cond, I want to duplicate it n times. \nm =", "entry_point": "none", "canonical_solution": [" bn.duplicate(a[cond], n)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'repeat'\n}\n\n\ndef check():\n    assert np.array_equal(m, np.array([2, 2, 4, 4]))\n\n\n"}
{"task_id": "NumpyEval/48", "prompt": "import beatnum as bn\n\ndef get_multiply_difference(t):\n    # Is there a function that returns an numset with the results of dividing the next element by the previous one? Like a \"difference()\", but with dividing\n    # Not-beatnum-example:\n    # source = [1,3,6,24,36]\n    # target = [j / i for i, j in zip(source[:-1], source[1:])]\n    # Return: target implemented in beatnum.\n", "entry_point": "get_multiply_diff", "canonical_solution": ["    return t[1:] / t[:-1]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'diff'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1,3,6,24,36])), np.array([3, 2, 4, 1.5]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,36])), np.array([3, 2, 8, 0.75]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,96])), np.array([3, 2, 8, 2]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,144])), np.array([3, 2, 8, 3]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,192])), np.array([3, 2, 8, 4]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,240])), np.array([3, 2, 8, 5]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,288])), np.array([3, 2, 8, 6]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,336])), np.array([3, 2, 8, 7]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,384])), np.array([3, 2, 8, 8]))\n    assert np.array_equal(candidate(np.array([1,3,6,48,432])), np.array([3, 2, 8, 9]))\n\n\n"}
{"task_id": "NumpyEval/49", "prompt": "import beatnum as bn\n\nA = bn.numset([[1, 2], [3, 0]])\n\n# How can I know the (row, column) index of the minimum of a beatnum numset/matrix?\n# Use convert_index_or_arr()\nout =", "entry_point": "none", "canonical_solution": [" bn.convert_index_or_arr(A.get_argmin_value(), A.shape)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'unravel_index'\n}\n\n\ndef check():\n    assert out == (1, 1)\n\n\n"}
{"task_id": "NumpyEval/50", "prompt": "# [start]\n# split_array(ary, indices_or_sections, axis=0): Divide a numset into several sub-numsets.\n# [end]\nimport beatnum as bn\n\ndef crop(arr, top, bottom, left, right):\n    # How do I extract a sub-numset from a beatnum 2d numset? \n    # I'd like to extract a beatnum numset with a specified size from a beatnum 2d numset--essentially I want to crop the numset.\n    # Return a sub-numset from a beatnum 2d numset.\n", "entry_point": "crop", "canonical_solution": ["    return arr[top:bottom, left:right]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 't_b_l_r'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1, 3, 3], [4, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[1, 3], [4, 6]]))\n    assert np.array_equal(candidate(np.array([[2, 3, 3], [2, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[2, 3], [2, 6]]))\n    assert np.array_equal(candidate(np.array([[2, 3, 4], [2, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[2, 3], [2, 6]]))\n    assert np.array_equal(candidate(np.array([[2, 3, 42], [2, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[2, 3], [2, 6]]))\n    assert np.array_equal(candidate(np.array([[1, 9, 3], [2, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[1, 9], [2, 6]]))\n    assert np.array_equal(candidate(np.array([[0, 3, 3], [2, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[0, 3], [2, 6]]))\n    assert np.array_equal(candidate(np.array([[6, 3, 3], [2, 1, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[6, 3], [2, 1]]))\n    assert np.array_equal(candidate(np.array([[2, 3, 3], [2, 6, 3], [7, 8, 3]]), 0, 2, 0, 2), np.array([[2, 3], [2, 6]]))\n    assert np.array_equal(candidate(np.array([[12, 3, 3], [2, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[12, 3], [2, 6]]))\n    assert np.array_equal(candidate(np.array([[23, 34, 3], [2, 6, 6], [7, 8, 9]]), 0, 2, 0, 2), np.array([[23, 34], [2, 6]]))\n\n\n"}
{"task_id": "NumpyEval/51", "prompt": "# [start]\n# vectorisation(pyfunc, otypes=None, doc=None, excluded=None, cache=False, signature=None): vectorisation(pyfunc, otypes=None, doc=None, excluded=None, cache=False, signature=None) Define a vectorized function which takes a nested sequence of objects or beatnum numsets as inputs and returns a single beatnum numset.\n# [end]\nimport beatnum as bn\n\na = bn.numset([[1,2,3],\n              [3,2,4]])\n\nmy_dict = {1:23, 2:34, 3:36, 4:45}\n# I am trying to translate every element of a beatnum.numset according to a given key\n# I don't know about efficient, but you could use bn.vectorisation on the .get method of dictionaries:\nout =", "entry_point": "none", "canonical_solution": [" bn.vectorisation(my_dict.get)(a)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'vectorize'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.array([[23,34,36], [36,34,45]]))\n\n\n"}
{"task_id": "NumpyEval/52", "prompt": "# [start]\n# filter_condition(condition, x=None, y=None): filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.\n# [end]\nimport beatnum as bn\n\nx=bn.numset([range(100,1,-1)])\n#This will tell me those values\n# generate a mask to find all values that are even numbers\n# Is there an efficient Beatnum mechanism to retrieve the integer indexes of locations in an numset based on a condition is true as opposed to the Boolean mask numset?\nout =", "entry_point": "none", "canonical_solution": [" bn.filter_condition(x % 2 == 0)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'where_condition'\n}\n\n\ndef check():\n    assert np.array_equal(out[1], np.where(x % 2 == 0)[1])\n\n\n"}
{"task_id": "NumpyEval/53", "prompt": "import beatnum as bn\n\ndef consecutive(data, stepsize=1):\n    # How to find the groups of consecutive elements in a BeatNum numset\n    # I have to cluster the consecutive elements from a BeatNum numset. Considering the following example\n    # a = [ 0, 47, 48, 49, 50, 97, 98, 99]\n    # The output should be a list of tuples as follows\n    # [(0), (47, 48, 49, 50), (97, 98, 99)]\n    # Here the difference is just one between the elements. It will be great if the difference can also be specified as a limit or a hardcoded number.\n    # Finally, return the number of consecutive elements in the numset.\n", "entry_point": "consecutive", "canonical_solution": ["    return len(bn.sep_split(data, bn.filter_condition(bn.difference(data) != stepsize)[0]+1))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'shape'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array([0, 47, 48, 49, 50, 97, 98, 99])) == 3\n    assert candidate(np.array([0, 47, 48, 49, 20, 97, 98, 99])) == 4\n    assert candidate(np.array([0, 2, 3, 49, 50, 97, 98, 99])) == 4\n    assert candidate(np.array([0, 2, 3, 4, 50, 97, 98, 99])) == 4\n    assert candidate(np.array([0, 2, 3, 4, 5, 97, 98, 99])) == 3\n    assert candidate(np.array([0, 2, 3, 4, 5, 9, 98, 99])) == 4\n    assert candidate(np.array([0, 2, 2, 4, 5, 9, 98, 99])) == 6\n    assert candidate(np.array([0, 2, 2, 4, 5, 9, 100, 99])) == 7\n    assert candidate(np.array([0, 2, 2, 4, 5, 9, 100, 200])) == 7\n\n\n"}
{"task_id": "NumpyEval/54", "prompt": "# [start]\n# filter_condition(condition, x=None, y=None): filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.\n# [end]\nimport beatnum as bn\n\ndists = bn.numset([[5,1,2], [2,8,1], [1,6,3], [5,2,2], [5,1,2], [3,1,2]])\nr, dr = 2, 3\n# I have an numset of distances called dists. I want to select dists which are within a range [r, r+dr].\n# You don't actually need filter_condition if you're just trying to filter out the elements of dists that don't fit your criteria:\nout =", "entry_point": "none", "canonical_solution": [" dists[bn.filter_condition(bn.logic_and_element_wise(dists >= r, dists <= r+dr))]", " dists[(dists >= r) & (dists <= r+dr)]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'where_logical'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.array([5, 2, 2, 3, 5, 2, 2, 5, 2, 3, 2]))\n\n\n"}
{"task_id": "NumpyEval/55", "prompt": "import beatnum as bn\n\ndef xor_operation(x, y, z):\n    \"\"\"\n    How can I define in beatnum a matrix that uses operations modulo 2?\n    This operation is called \"xor\".\n    Arguments:\n        x: a beatnum numset\n        y: a beatnum numset\n        z: a beatnum numset\n    Returns:\n        a beatnum numset containing the result of the operation\n    \"\"\"\n", "entry_point": "xor_operation", "canonical_solution": ["    return (x ^ y ^ z)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'difference_where'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1, 2, 3]), np.array([5, 6, 7]), np.array([9, 10, 11])), np.array([13, 14, 15]))\n    assert np.array_equal(candidate(np.array([4, 3, 2]), np.array([8, 7, 6]), np.array([9, 10, 11])), np.array([5, 14, 15]))\n    assert np.array_equal(candidate(np.array([4, 4, 2]), np.array([8, 7, 6]), np.array([9, 10, 11])), np.array([5, 9, 15]))\n    assert np.array_equal(candidate(np.array([44, 4, 2]), np.array([8, 7, 6]), np.array([9, 10, 11])), np.array([45, 9, 15]))\n    assert np.array_equal(candidate(np.array([44, 2, 2]), np.array([8, 7, 6]), np.array([9, 10, 11])), np.array([45, 15, 15]))\n    assert np.array_equal(candidate(np.array([44, 2, 1]), np.array([8, 7, 6]), np.array([9, 10, 11])), np.array([45, 15, 12]))\n    assert np.array_equal(candidate(np.array([44, 2, 1]), np.array([83, 7, 6]), np.array([9, 10, 11])), np.array([118, 15, 12]))\n    assert np.array_equal(candidate(np.array([44, 2, 1]), np.array([83, 7, 3]), np.array([9, 10, 11])), np.array([118, 15, 9]))\n    assert np.array_equal(candidate(np.array([2, 2, 1]), np.array([83, 7, 3]), np.array([9, 10, 11])), np.array([88, 15, 9]))\n    assert np.array_equal(candidate(np.array([2, 31, 1]), np.array([83, 7, 3]), np.array([9, 10, 11])), np.array([88, 18, 9]))\n\n\n"}
{"task_id": "NumpyEval/56", "prompt": "import beatnum as bn\n\na = bn.numset([ 0,  3,  6,  9, 12])\nb = bn.numset([ 1,  4,  7, 10, 13])\nc = bn.numset([ 2,  5,  8, 11, 14])\n\n# How can I join them using beatnum methods\n# You can transpose and flatten the numsets:\nd =", "entry_point": "none", "canonical_solution": [" bn.numset([a, b, c]).T.convert_into_one_dim()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'T.flatten'\n}\n\n\ndef check():\n    assert np.array_equal(d, np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]))\n\n\n"}
{"task_id": "NumpyEval/57", "prompt": "import beatnum as bn\n\na = bn.numset([[1, 1, 1, 0, 0, 0],\n       [0, 1, 1, 1, 0, 0],\n       [0, 1, 1, 1, 0, 0],\n       [1, 1, 1, 0, 0, 0],\n       [1, 1, 1, 1, 1, 0]])\n# I need to find uniq rows in a beatnum.numset.\nout =", "entry_point": "none", "canonical_solution": [" bn.uniq(a, axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'unique'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.unique(a, axis=0))\n\n\n"}
{"task_id": "NumpyEval/58", "prompt": "# [start]\n# normlizattion(self, *args, **kwargs): Return one of eight different matrix norms, or one of an infinite number of vector norms.\n# [end]\nimport beatnum as bn\n\na = bn.numset((1,2,3))\nb = bn.numset((4,5,6))\n# How can the Euclidean distance be calculated with BeatNum?\ndist = ", "entry_point": "none", "canonical_solution": ["bn.linalg.normlizattion(a-b)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'linalg'\n}\n\n\ndef check():\n    assert np.array_equal(dist, np.linalg.norm(a-b))\n\n\n"}
{"task_id": "NumpyEval/59", "prompt": "import beatnum as bn\n\nimport itertools\ndata = [[1], [1, 2]]\n# Convert Python sequence to BeatNum numset, filling missing values with 0\nresult =", "entry_point": "none", "canonical_solution": [" bn.numset(list(itertools.zip_longest(*data, fillvalue=0)))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'array_list_zip_longest'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.array([[1, 1], [0, 2]]))\n\n\n"}
{"task_id": "NumpyEval/60", "prompt": "# [start]\n# convert_index_or_arr(indices, shape, order='C'): Return a tuple of coordinate numsets converted from a flat index or numset.\n# [end]\nimport beatnum as bn\n\n# We numset `data` defines the columns of the nonzero elements in the output numset. \ndata = bn.numset([1, 0, 3])\n# We need to also define the rows and then use fancy indexing in the following way:\nresult = bn.zeros((data.size, data.get_max()+1))\n# Convert numset of indices to 1-hot encoded beatnum numset\nresult", "entry_point": "none", "canonical_solution": ["[bn.arr_range(data.size), data] = 1"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'arange'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.array([[0., 1., 0., 0.], [1., 0., 0., 0.], [0., 0., 0., 1.]]))\n\n\n"}
{"task_id": "NumpyEval/61", "prompt": "# [start]\n# remove_operation(arr, obj, axis=None): Deleted sub-numsets along an axis.\n# [end]\nimport beatnum as bn\n\ndata = bn.numset([1,2,3,4,5,6,7,8,9])\n# How to remove specific elements in a beatnum numset\uff1f\n# I then want to remove 3,4,7 from a. All I know is the index of the values (index=[2,3,6]).\nindex = [2, 3, 6]\nresult =", "entry_point": "none", "canonical_solution": ["bn.remove_operation(data, index)", "bn.remove_operation(data, index, axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'delete'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.array([1, 2, 5, 6, 8, 9]))\n\n\n"}
{"task_id": "NumpyEval/62", "prompt": "# [start]\n# total(self, axis=None, out=None): Determine if all matrix members along a particular axis are True.\n# [end]\nimport beatnum as bn\n\na = bn.numset([1,2,3,4,5])\n# I have a beatnum numset and I like to check if it is sorted.\n# Using beatnum.total to do this.\nis_sorted =", "entry_point": "none", "canonical_solution": [" bn.total(a[:-1] <= a[1:])"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'all_sort'\n}\n\n\ndef check():\n    assert is_sorted == True\n\n\n"}
{"task_id": "NumpyEval/63", "prompt": "# [start]\n# create_ones(shape, dtype=None, order='C', *, like=None): Create a new numset of specified shape and type and fill it with ones.\n# [end]\nimport beatnum as bn\n\n# How do I create a beatnum numset of arbitrary shape 3x4 filled with all True?\ndata =", "entry_point": "none", "canonical_solution": [" bn.create_ones((3, 4), dtype=bool)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'ones'\n}\n\n\ndef check():\n    assert np.array_equal(data, np.ones((3, 4), dtype=bool))\n\n\n"}
{"task_id": "NumpyEval/64", "prompt": "# [start]\n# numset(obj, itemsize=None, copy=True, unicode=None, order=None): Return a `numset`.\n# [end]\nimport beatnum as bn\n\ndef replace_elements_that_greater_than_value(arr, value, new_value):\n    # Replace all elements of Python BeatNum Array that are greater than `value` with `new_value`\n    # Return the numset\n", "entry_point": "replace_elements_that_greater_than_value", "canonical_solution": ["    arr[arr > value] = new_value\n    return arr"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'replace'\n}\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 8]]), 5, 0), np.array([[1, 2, 3, 4], [5, 0, 0, 0]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 8]]), 5, 1), np.array([[1, 2, 3, 4], [5, 1, 1, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 8]]), 6, 1), np.array([[1, 2, 3, 4], [5, 6, 1, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 8]]), 7, 1), np.array([[1, 2, 3, 4], [5, 6, 7, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 9]]), 7, 1), np.array([[1, 2, 3, 4], [5, 6, 7, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 10]]), 7, 1), np.array([[1, 2, 3, 4], [5, 6, 7, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 11]]), 7, 1), np.array([[1, 2, 3, 4], [5, 6, 7, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 12]]), 7, 1), np.array([[1, 2, 3, 4], [5, 6, 7, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 15]]), 7, 1), np.array([[1, 2, 3, 4], [5, 6, 7, 1]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3, 4], [5, 6, 7, 15]]), 7, 0), np.array([[1, 2, 3, 4], [5, 6, 7, 0]]))\n\n\n"}
{"task_id": "NumpyEval/65", "prompt": "# [start]\n# connect(numsets, axis=0): Return a numset concatenated with given numsets along the specified axis.\n# [end]\nimport beatnum as bn\n\ndef connect_two_numsets(arr1, arr2):\n    # Connect a BeatNum numset to another BeatNum numset\n\n", "entry_point": "concatenate_two_arrays", "canonical_solution": ["    return bn.connect((arr1, arr2))"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'concatenate'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1,2]]), np.array([[3,4]])), np.array([[1,2],[3,4]]))\n    assert np.array_equal(candidate(np.array([[1,2]]), np.array([[3,5]])), np.array([[1,2],[3,5]]))\n    assert np.array_equal(candidate(np.array([[2,2]]), np.array([[3,5]])), np.array([[2,2],[3,5]]))\n    assert np.array_equal(candidate(np.array([[1,2]]), np.array([[4,5]])), np.array([[1,2],[4,5]]))\n    assert np.array_equal(candidate(np.array([[31,2]]), np.array([[3,5]])), np.array([[31,2],[3,5]]))\n    assert np.array_equal(candidate(np.array([[3,2]]), np.array([[3,5]])), np.array([[3,2],[3,5]]))\n    assert np.array_equal(candidate(np.array([[31,2]]), np.array([[3,52]])), np.array([[31,2],[3,52]]))\n    assert np.array_equal(candidate(np.array([[31,2]]), np.array([[31,15]])), np.array([[31,2],[31,15]]))\n    assert np.array_equal(candidate(np.array([[31,2]]), np.array([[33,5]])), np.array([[31,2],[33,5]]))\n    assert np.array_equal(candidate(np.array([[32,12]]), np.array([[3,5]])), np.array([[32,12],[3,5]]))\n\n"}
{"task_id": "NumpyEval/66", "prompt": "import beatnum as bn\n\ndef beatnum_is_empty(arr):\n    # How can I check whether a beatnum numset is empty or not?\n    # Return the reuslt that contains True or False\n", "entry_point": "numpy_is_empty", "canonical_solution": ["    return arr.size == 0"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'size'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array([])) == True\n    assert candidate(np.array([1])) == False\n    assert candidate(np.array([2])) == False\n    assert candidate(np.array([1, 2])) == False\n    assert candidate(np.array([1, 3, 4])) == False\n    assert candidate(np.array([8])) == False\n    assert candidate(np.array([5])) == False\n    assert candidate(np.array([3, 5])) == False\n    assert candidate(np.array([3, 1])) == False\n    assert candidate(np.array([7])) == False\n\n\n"}
{"task_id": "NumpyEval/67", "prompt": "# [start]\n# total_count(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>): Return the sum of the numset items along a particular axis.\n# [end]\nimport beatnum as bn\n\ndef count_true_number(arr):\n    # How to count the number of true elements in a BeatNum bool numset?\n    # return the count value\n", "entry_point": "count_true_number", "canonical_solution": ["    return arr.total_count()"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'sum'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array([[0, 0, 1], [1, 0, 1], [1, 0, 1]], dtype=np.bool)) == 5\n    assert candidate(np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1]], dtype=np.bool)) == 6\n    assert candidate(np.array([[0, 1, 1], [1, 1, 1], [1, 0, 1]], dtype=np.bool)) == 7\n    assert candidate(np.array([[0, 0, 0], [1, 1, 1], [1, 0, 1]], dtype=np.bool)) == 5\n    assert candidate(np.array([[1, 1, 1], [1, 1, 1], [1, 0, 1]], dtype=np.bool)) == 8\n    assert candidate(np.array([[0, 0, 1], [1, 1, 1]], dtype=np.bool)) == 4\n    assert candidate(np.array([[0, 1, 1], [1, 1, 1]], dtype=np.bool)) == 5\n    assert candidate(np.array([[1, 1, 1], [1, 1, 1]], dtype=np.bool)) == 6\n    assert candidate(np.array([[0, 0, 1], [0, 1, 1]], dtype=np.bool)) == 3\n    assert candidate(np.array([[0, 0, 1], [0, 0, 1]], dtype=np.bool)) == 2\n\n\n"}
{"task_id": "NumpyEval/68", "prompt": "# [start]\n# vertical_stack(tup): Stack numsets in vertical or row wise order.\n# [end]\nimport beatnum as bn\n\ndef add_row_to_arr(arr, row):\n    # How does one add rows to a beatnum numset?\n    # Is there a beatnumthonic way to do this?\n", "entry_point": "add_row_to_arr", "canonical_solution": ["    return bn.vertical_stack((arr, row))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'vstack'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1, 2, 3]]), np.array([[4, 5, 6]])), np.array([[1, 2, 3], [4, 5, 6]]))\n    assert np.array_equal(candidate(np.array([[1, 2, 4]]), np.array([[4, 5, 6]])), np.array([[1, 2, 4], [4, 5, 6]]))\n    assert np.array_equal(candidate(np.array([[1, 3, 4]]), np.array([[4, 5, 6]])), np.array([[1, 3, 4], [4, 5, 6]]))\n    assert np.array_equal(candidate(np.array([[1, 3, 4]]), np.array([[4, 8, 6]])), np.array([[1, 3, 4], [4, 8, 6]]))\n    assert np.array_equal(candidate(np.array([[2, 3, 4]]), np.array([[4, 8, 6]])), np.array([[2, 3, 4], [4, 8, 6]]))\n    assert np.array_equal(candidate(np.array([[3, 3, 4]]), np.array([[4, 8, 6]])), np.array([[3, 3, 4], [4, 8, 6]]))\n    assert np.array_equal(candidate(np.array([[4, 3, 4]]), np.array([[4, 8, 6]])), np.array([[4, 3, 4], [4, 8, 6]]))\n    assert np.array_equal(candidate(np.array([[4, 4, 4]]), np.array([[4, 8, 6]])), np.array([[4, 4, 4], [4, 8, 6]]))\n    assert np.array_equal(candidate(np.array([[4, 4]]), np.array([[4, 8]])), np.array([[4, 4], [4, 8]]))\n    assert np.array_equal(candidate(np.array([[4, 6]]), np.array([[4, 8]])), np.array([[4, 6], [4, 8]]))\n\n\n"}
{"task_id": "NumpyEval/69", "prompt": "import beatnum as bn\n\na = bn.arr_range(1, 10)\na = a.change_shape_to(len(a), 1)\n# I want to access the elements from index 4 to the end:\nb =", "entry_point": "none", "canonical_solution": [" a[4:]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'slice'\n}\n\n\ndef check():\n    assert np.array_equal(b, a[4:])\n\n\n"}
{"task_id": "NumpyEval/70", "prompt": "# [start]\n# change_shape_to(a, newshape, order='C'): Changes the shape of a numset without affecting its data.\n# [end]\nimport beatnum as bn\n\narr = bn.zeros((50,100,25))\n# Is there a quick way to \"sub-flatten\" or flatten only some of the first dimensions in a beatnum numset?\n# Given a beatnum numset of dimensions (50,100,25), the resultant dimensions would be (5000,25)\nresult = ", "entry_point": "none", "canonical_solution": ["bn.change_shape_to(arr, (5000,25))", "arr.change_shape_to((5000,25))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'reshape'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.reshape(arr, (5000,25)))\n\n\n"}
{"task_id": "NumpyEval/71", "prompt": "import beatnum as bn\ndef matrix2numset(M):\n    # I am using beatnum. I have a matrix `M` 1*N and I want to get an numset from with N elements.\n    # To achieve it, Does anyone know a more elegant way to get the result?\n", "entry_point": "matrix2array", "canonical_solution": ["    return bn.sqz(bn.asnumset(M))", "    return bn.numset(M.T)[0]", "    return bn.asnumset(M).change_shape_to(-1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'squeeze_T_asarray'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.matrix([[1], [2], [3], [4]])), np.array([1, 2, 3, 4]))\n    assert np.array_equal(candidate(np.matrix([[1], [2], [3], [5]])), np.array([1, 2, 3, 5]))\n    assert np.array_equal(candidate(np.matrix([[1], [5], [3], [5]])), np.array([1, 5, 3, 5]))\n    assert np.array_equal(candidate(np.matrix([[2], [5], [3], [5]])), np.array([2, 5, 3, 5]))\n    assert np.array_equal(candidate(np.matrix([[2], [5], [4], [5]])), np.array([2, 5, 4, 5]))\n    assert np.array_equal(candidate(np.matrix([[4], [5], [4], [5]])), np.array([4, 5, 4, 5]))\n    assert np.array_equal(candidate(np.matrix([[4], [5], [4]])), np.array([4, 5, 4]))\n    assert np.array_equal(candidate(np.matrix([[1], [5], [4]])), np.array([1, 5, 4]))\n    assert np.array_equal(candidate(np.matrix([[1], [2], [4]])), np.array([1, 2, 4]))\n    assert np.array_equal(candidate(np.matrix([[1], [2], [3]])), np.array([1, 2, 3]))\n\n"}
{"task_id": "NumpyEval/72", "prompt": "# [start]\n# filter_condition(condition, x=None, y=None): filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.\n# [end]\nimport beatnum as bn\n\ndef find_indices_zero(arr):\n    # Find indices of elements equal to zero in a BeatNum numset\n    # Return the indices\n", "entry_point": "find_indices_zero", "canonical_solution": ["    return bn.filter_condition(arr == 0)[0]", "    return bn.argwhere(arr == 0)", "    return bn.nonzero(x==0)[0]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'nonzero'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1, 0, 2, 3, 9, 0])), np.array([1, 5]))\n    assert np.array_equal(candidate(np.array([1, 0, 2, 3, 10, 0])), np.array([1, 5]))\n    assert np.array_equal(candidate(np.array([1, 0, 3, 3, 10, 0])), np.array([1, 5]))\n    assert np.array_equal(candidate(np.array([1, 0, 4, 3, 10, 0])), np.array([1, 5]))\n    assert np.array_equal(candidate(np.array([1, 0, 4, 3, 10, 2])), np.array([1]))\n    assert np.array_equal(candidate(np.array([1, 0, 0, 3, 10, 2])), np.array([1, 2]))\n    assert np.array_equal(candidate(np.array([1, 0, 0, 4, 10, 2])), np.array([1, 2]))\n    assert np.array_equal(candidate(np.array([1, 0, 0, 4, 0, 2])), np.array([1, 2, 4]))\n    assert np.array_equal(candidate(np.array([1, 0, 0, 4, 0, 4])), np.array([1, 2, 4]))\n    assert np.array_equal(candidate(np.array([1, 0, 0, 4, 0, 31])), np.array([1, 2, 4]))\n\n\n"}
{"task_id": "NumpyEval/73", "prompt": "import beatnum as bn\n\ndef find_most_frequent_number(arr):\n    # Find the most frequent number in a BeatNum numset\n    # Return the number\n", "entry_point": "find_most_frequent_number", "canonical_solution": ["    return bn.binoccurrence(arr).get_argmax()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'bincount_argmax'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array([1,2,3,1,2,1,1,1,3,2,2,1])) == 1\n    assert candidate(np.array([1,1,3,1,2,1,1,1,3,2,2,1])) == 1\n    assert candidate(np.array([1,2,1,1,2,1,1,1,3,2,2,1])) == 1\n    assert candidate(np.array([1,2,3,1,2,1,1,1,1,2,2,1])) == 1\n    assert candidate(np.array([1,2,3,1,2,1,1,1,3,2,1,0])) == 1\n    assert candidate(np.array([1,2,3,1,2,1,1,1,3,1,1,1])) == 1\n    assert candidate(np.array([1,2,3,1,2,1,1,1,1,2,2,1])) == 1\n    assert candidate(np.array([1,2,3,1,2,1,1,1,0,1,1,1])) == 1\n    assert candidate(np.array([1,1,3,1,2,1,1,1,1,2,2,1])) == 1\n    assert candidate(np.array([2,2,3,2,2,2,2,2,3,2,2,2])) == 2\n\n\n"}
{"task_id": "NumpyEval/74", "prompt": "import beatnum as bn\n\n# List of numsets.\nL = [bn.random.randn(5,4,2,5,1,2) for i in range(10)]\n# Stack them using axis that is negative one .\nM = ", "entry_point": "none", "canonical_solution": ["bn.pile_operation(L, axis=-1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'stack'\n}\n\n\ndef check():\n    assert np.array_equal(M, np.stack(L, axis=-1))\n\n\n"}
{"task_id": "NumpyEval/75", "prompt": "# [start]\n# apd(object, /): Place the object at last position of the list.\n# [end]\nimport beatnum as bn\n\ndef add_first_element_to_arr(arr):\n    # I want to add the first element on to the end of the numset.\n    # Return the appended numset.\n", "entry_point": "add_first_element_to_arr", "canonical_solution": ["    return bn.apd(arr, arr[0])"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'append'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1, 2, 3])), np.array([1, 2, 3, 1]))\n    assert np.array_equal(candidate(np.array([1, 3, 3])), np.array([1, 3, 3, 1]))\n    assert np.array_equal(candidate(np.array([2, 2, 3])), np.array([2, 2, 3, 2]))\n    assert np.array_equal(candidate(np.array([1, 3])), np.array([1, 3, 1]))\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4])), np.array([1, 2, 3, 4, 1]))\n    assert np.array_equal(candidate(np.array([1, 4, 3])), np.array([1, 4, 3, 1]))\n    assert np.array_equal(candidate(np.array([1, 2, 13])), np.array([1, 2, 13, 1]))\n    assert np.array_equal(candidate(np.array([1, 12, 13])), np.array([1, 12, 13, 1]))\n    assert np.array_equal(candidate(np.array([1, 32, 3])), np.array([1, 32, 3, 1]))\n    assert np.array_equal(candidate(np.array([11, 2, 3])), np.array([11, 2, 3, 11]))\n\n"}
{"task_id": "NumpyEval/76", "prompt": "# [start]\n# convert_type(self, dtype, copy=True): Cast the numset to a specified type.\n# [end]\nimport beatnum as bn\n\ndef convert_string_in_numset_to_float(arr):\n    # How to convert an numset of strings to an numset of floats in beatnum?\n    # Return the final result\n", "entry_point": "convert_string_in_array_to_float", "canonical_solution": ["    return arr.convert_type(bn.float)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'astype'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array(['1.0', '2.0', '3.0'])), np.array([1.0, 2.0, 3.0]))\n    assert np.array_equal(candidate(np.array(['1.0', '3.0', '3.0'])), np.array([1.0, 3.0, 3.0]))\n    assert np.array_equal(candidate(np.array(['1.0', '2.0', '4.0'])), np.array([1.0, 2.0, 4.0]))\n    assert np.array_equal(candidate(np.array(['1.0', '2.0', '6.0'])), np.array([1.0, 2.0, 6.0]))\n    assert np.array_equal(candidate(np.array(['3.0', '2.0', '3.0'])), np.array([3.0, 2.0, 3.0]))\n    assert np.array_equal(candidate(np.array(['1.0', '3.0', '3.0'])), np.array([1.0, 3.0, 3.0]))\n    assert np.array_equal(candidate(np.array(['13.0', '2.0', '3.0'])), np.array([13.0, 2.0, 3.0]))\n    assert np.array_equal(candidate(np.array(['133.0', '23.0', '3.0'])), np.array([133.0, 23.0, 3.0]))\n    assert np.array_equal(candidate(np.array(['1.0', '2.0', '343.0'])), np.array([1.0, 2.0, 343.0]))\n\n"}
{"task_id": "NumpyEval/77", "prompt": "# [start]\n# get_argmax(a, axis=None, out=None): Returns an axis's maximum values indices.\n# [end]\nimport beatnum as bn\n\ndef get_index_max_element(arr, axis_value):\n    # How to get the index of a maximum element in a BeatNum numset along axis_value?\n    # Return the result\n", "entry_point": "get_index_max_element", "canonical_solution": ["    return bn.get_argmax(arr, axis=axis_value)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'argmax'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1, 2, 3], [2, 3, 4]]), 1), np.array([2, 2]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3], [2, 3, 4]]), 0), np.array([1, 1, 1]))\n    assert np.array_equal(candidate(np.array([[1, 2, 3], [2, 2, 4]]), 0), np.array([1, 0, 1]))\n    assert np.array_equal(candidate(np.array([[1, 2, 4], [2, 2, 4]]), 0), np.array([1, 0, 0]))\n    assert np.array_equal(candidate(np.array([[1, 2, 14], [2, 2, 4]]), 0), np.array([1, 0, 0]))\n    assert np.array_equal(candidate(np.array([[1, 12, 14], [2, 2, 4]]), 0), np.array([1, 0, 0]))\n    assert np.array_equal(candidate(np.array([[1, 12, 14], [2, 2, 1]]), 0), np.array([1, 0, 0]))\n    assert np.array_equal(candidate(np.array([[1, 12, 14], [2, 1, 1]]), 0), np.array([1, 0, 0]))\n    assert np.array_equal(candidate(np.array([[1, 12, 14], [2, 1, 11]]), 0), np.array([1, 0, 0]))\n\n\n"}
{"task_id": "NumpyEval/78", "prompt": "# [start]\n# convert_type(self, dtype, copy=True): Cast the numset to a specified type.\n# [end]\nimport beatnum as bn\n\ndef arr2tuple(arr):\n    # Convert beatnum numset to tuple\n    # Return the transformed tuple\n", "entry_point": "arr2tuple", "canonical_solution": ["    return tuple(map(tuple, arr))"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'tuple_map'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array(((2,2),(2,-2)))) == ((2,2),(2,-2))\n    assert candidate(np.array(((2,2),(2,2)))) == ((2,2),(2,2))\n    assert candidate(np.array(((2,3),(2,-2)))) == ((2,3),(2,-2))\n    assert candidate(np.array(((4,2),(2,-2)))) == ((4,2),(2,-2))\n    assert candidate(np.array(((2,2),(5,-2)))) == ((2,2),(5,-2))\n    assert candidate(np.array(((2,32),(2,-2)))) == ((2,32),(2,-2))\n    assert candidate(np.array(((21,2),(2,-2)))) == ((21,2),(2,-2))\n    assert candidate(np.array(((2,2),(32,-2)))) == ((2,2),(32,-2))\n    assert candidate(np.array(((2,2),(2,-12)))) == ((2,2),(2,-12))\n    assert candidate(np.array(((222,2),(2,-2)))) == ((222,2),(2,-2))\n\n\n"}
{"task_id": "NumpyEval/79", "prompt": "# [start]\n# any_condition(a, axis=None, out=None, keepdims=<no value>, *, where=<no value>): Check if any numset element on a certain axis evaluates to True.\n# [end]\nimport beatnum as bn\n\ndef test_arr_contain_only_zeros(arr):\n    # Test if beatnum numset contains only zeros\n    # Return the result\n", "entry_point": "test_arr_contain_only_zeros", "canonical_solution": ["    return not bn.any_condition(arr)", "    return not a.any_condition()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'any'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array(((0,0),(0,0)))) == True\n    assert candidate(np.array(((1,0),(0,0)))) == False\n    assert candidate(np.array(((1,0),(1,0)))) == False\n    assert candidate(np.array(((1,0),(12,0)))) == False\n    assert candidate(np.array(((1,0),(10,10)))) == False\n    assert candidate(np.array(((12,0),(12,0)))) == False\n    assert candidate(np.array(((1,20),(0,0)))) == False\n    assert candidate(np.array(((1,0),(0,1230)))) == False\n    assert candidate(np.array(((1,10),(10,0)))) == False\n    assert candidate(np.array(((1,230),(10,10)))) == False\n\n\n"}
{"task_id": "NumpyEval/80", "prompt": "# [start]\n# filter_condition(condition, x=None, y=None): filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.\n# [end]\nimport beatnum as bn\n\ndef find_index_within_range(arr, low, high):\n    # find index of the elements within range [low, high]\n    # Return the final numset of indices.\n", "entry_point": "find_index_within_range", "canonical_solution": ["    return bn.filter_condition(bn.logic_and_element_wise(arr >= low, arr <= high))[0]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'where_logical_and'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]), 3, 6), np.array([2, 3, 4, 5]))\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4, 5, 1, 7, 8, 9, 10]), 3, 6), np.array([2, 3, 4]))\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4, 5, 1, 7, 11, 9, 10]), 3, 6), np.array([2, 3, 4]))\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4, 5, 1, 1, 11, 9, 10]), 3, 6), np.array([2, 3, 4]))\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4, 5, 1, 121, 11, 9, 10]), 3, 6), np.array([2, 3, 4]))\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4, 5, 1, 121, 11, 19, 10]), 3, 6), np.array([2, 3, 4]))\n    assert np.array_equal(candidate(np.array([1, 2, 13, 4, 5, 1, 121, 11, 19, 10]), 3, 6), np.array([3, 4]))\n    assert np.array_equal(candidate(np.array([1, 2, 13, 4, 5, 1, 121, 11, 19, 10]), 3, 10), np.array([3, 4, 9]))\n    assert np.array_equal(candidate(np.array([1, 2, 13, 4, 5, 1, 121, 11, 100, 10]), 3, 10), np.array([3, 4, 9]))\n    assert np.array_equal(candidate(np.array([1, 2, 13, 4, 5, 11, 121, 11, 100, 10]), 3, 10), np.array([3, 4, 9]))\n\n\n"}
{"task_id": "NumpyEval/81", "prompt": "# [start]\n# ifnan(x, /): If x is a NaN (not a number), return True; otherwise, return False.\n# [end]\nimport beatnum as bn\n\ndef convert_nan_to_zero(arr):\n    # convert nan value to zero\n    # Return the changed numset\n", "entry_point": "convert_nan_to_zero", "canonical_solution": ["    arr[bn.ifnan(arr)] = 0\n    return arr"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'isnan'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1, 2, np.nan, 4, np.nan])), np.array([1, 2, 0, 4, 0]))\n    assert np.array_equal(candidate(np.array([1, 2, 3, 4, np.nan])), np.array([1, 2, 3, 4, 0]))\n    assert np.array_equal(candidate(np.array([1, 2, 5, 4, np.nan])), np.array([1, 2, 5, 4, 0]))\n    assert np.array_equal(candidate(np.array([1, 2, np.nan, np.nan, np.nan])), np.array([1, 2, 0, 0, 0]))\n    assert np.array_equal(candidate(np.array([1, 2, 5, 4, np.nan])), np.array([1, 2, 5, 4, 0]))\n    assert np.array_equal(candidate(np.array([1, 2, 1, 4, 5])), np.array([1, 2, 1, 4, 5]))\n    assert np.array_equal(candidate(np.array([1, 2, 1, np.nan, 5])), np.array([1, 2, 1, 0, 5]))\n    assert np.array_equal(candidate(np.array([np.nan, 2, 1, 2, 5])), np.array([0, 2, 1, 2, 5]))\n    assert np.array_equal(candidate(np.array([np.nan, 2, np.nan, 2, 5])), np.array([0, 2, 0, 2, 5]))\n    assert np.array_equal(candidate(np.array([np.nan, 2, 1, np.nan, 5])), np.array([0, 2, 1, 0, 5]))\n\n\n"}
{"task_id": "NumpyEval/82", "prompt": "import beatnum as bn\n\ndef remove_all_rows_contain_non_numeric_values(arr):\n    # How to remove all rows in a beatnum.ndnumset that contain non-numeric values?\n    # Return the final result\n", "entry_point": "remove_all_rows_contain_non_numeric_values", "canonical_solution": ["    return arr[~bn.ifnan(arr).any_condition(axis=1)]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'isnan_any'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1,2,3], [4,5,np.nan], [7,8,9]])), np.array([[1,2,3], [7,8,9]]))\n    assert np.array_equal(candidate(np.array([[1,2,3], [np.nan,5,np.nan], [7,8,9]])), np.array([[1,2,3], [7,8,9]]))\n    assert np.array_equal(candidate(np.array([[1,2,3], [np.nan, np.nan, np.nan], [7,8,9]])), np.array([[1,2,3], [7,8,9]]))\n    assert np.array_equal(candidate(np.array([[1,2,np.nan], [np.nan, np.nan, np.nan], [7,8,9]])), np.array([[7,8,9]]))\n    assert np.array_equal(candidate(np.array([[1,np.nan,np.nan], [np.nan, np.nan, np.nan], [7,8,9]])), np.array([[7,8,9]]))\n    assert np.array_equal(candidate(np.array([[np.nan,np.nan,np.nan], [np.nan, np.nan, np.nan], [7,8,9]])), np.array([[7,8,9]]))\n    assert np.array_equal(candidate(np.array([[np.nan,np.nan,np.nan], [7,8,9], [np.nan, np.nan, np.nan]])), np.array([[7,8,9]]))\n    assert np.array_equal(candidate(np.array([[np.nan,np.nan,np.nan], [7,8,2], [np.nan, np.nan, np.nan]])), np.array([[7,8,2]]))\n    assert np.array_equal(candidate(np.array([[np.nan,np.nan,np.nan], [7,2,2], [np.nan, np.nan, np.nan]])), np.array([[7,2,2]]))\n    assert np.array_equal(candidate(np.array([[np.nan,np.nan,np.nan], [2,2,2], [np.nan, np.nan, np.nan]])), np.array([[2,2,2]]))\n\n\n"}
{"task_id": "NumpyEval/83", "prompt": "# [start]\n# filter_condition(condition, x=None, y=None): filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.\n# [end]\nimport beatnum as bn\n\na = bn.numset([1, 2, 3, -4, 5])\n# Is there a simple way of replacing all negative values in an numset with `0`?\n# using a BeatNum function `filter_condition` to solve it.\nresult = ", "entry_point": "none", "canonical_solution": ["bn.filter_condition(a < 0, 0, a)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'where'\n}\n\n\ndef check():\n    assert np.array_equal(result, np.where(a < 0, 0, a))\n\n\n"}
{"task_id": "NumpyEval/84", "prompt": "import beatnum as bn\n\ndef interweaving_two_numsets(a, b):\n    # How would one interweave them efficiently?\n    # It can be assumed that length(a)==length(b).\n    c = bn.empty((a.size + b.size,), dtype=a.dtype)\n", "entry_point": "interweaving_two_arrays", "canonical_solution": ["    c[0::2] = a\n    c[1::2] = b\n    return c"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'list'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1,3,5]), np.array([2,4,6])), np.array([1,2,3,4,5,6]))\n    assert np.array_equal(candidate(np.array([1,3,5]), np.array([2,4,7])), np.array([1,2,3,4,5,7]))\n    assert np.array_equal(candidate(np.array([1,3,5]), np.array([2,3,6])), np.array([1,2,3,3,5,6]))\n    assert np.array_equal(candidate(np.array([12,3,5]), np.array([2,4,6])), np.array([12,2,3,4,5,6]))\n    assert np.array_equal(candidate(np.array([1,23,5]), np.array([2,4,6])), np.array([1,2,23,4,5,6]))\n    assert np.array_equal(candidate(np.array([1,3,53]), np.array([2,4,6])), np.array([1,2,3,4,53,6]))\n    assert np.array_equal(candidate(np.array([1,3,5]), np.array([42,4,6])), np.array([1,42,3,4,5,6]))\n    assert np.array_equal(candidate(np.array([1,3,5]), np.array([2,43,6])), np.array([1,2,3,43,5,6]))\n    assert np.array_equal(candidate(np.array([1,3,5]), np.array([2,4,64])), np.array([1,2,3,4,5,64]))\n    assert np.array_equal(candidate(np.array([1,3,5]), np.array([2,4,63])), np.array([1,2,3,4,5,63]))\n\n\n"}
{"task_id": "NumpyEval/85", "prompt": "import beatnum as bn\n\nA = bn.numset([1, 7, 9, 2, 0.1, 17, 17, 1.5])\nk = 3\n\n# Find the index of the k smallest values of a beatnum numset\nidx = ", "entry_point": "none", "canonical_solution": ["bn.perform_partition(A, k)[:k]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'argpartition'\n}\n\n\ndef check():\n    assert np.array_equal(idx, np.array([4, 0, 7]))\n\n\n"}
{"task_id": "NumpyEval/86", "prompt": "# [start]\n# connect(numsets, axis=0): Return a numset concatenated with given numsets along the specified axis.\n# [end]\nimport beatnum as bn\n\ninput_list = [bn.numset([[ 0.00353654]]), bn.numset([[ 0.00353654]]), bn.numset([[ 0.00353654]]), bn.numset([[ 0.00353654]]), bn.numset([[ 0.00353654]]), bn.numset([[ 0.00353654]]), bn.numset([[ 0.00353654]]), bn.numset([[ 0.00353654]])]\n# Flattening a list of BeatNum numsets?\n# We can use beatnum.connect, which as the name suggests, basically connects all the elements of such an input list into a single BeatNum numset\n# And then we can use beatnum.asview to flatten the numset\noutput = ", "entry_point": "none", "canonical_solution": ["bn.connect(input_list).asview()"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'concatenate_ravel'\n}\n\n\ndef check():\n    assert np.array_equal(output, np.concatenate(input_list).ravel())\n\n\n"}
{"task_id": "NumpyEval/87", "prompt": "# [start]\n# split_array(ary, indices_or_sections, axis=0): Divide a numset into several sub-numsets.\n# [end]\nimport beatnum as bn\n\nx = bn.arr_range(8.0)\n# Partition numset into 3 chunks with Beatnum\nresult = ", "entry_point": "none", "canonical_solution": ["bn.split_array(x, 3)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'array_split'\n}\n\n\ndef check():\n    assert np.array_equal(result[0], np.array_split(x, 3)[0]) \n    assert np.array_equal(result[1], np.array_split(x, 3)[1]) \n    assert np.array_equal(result[2], np.array_split(x, 3)[2]) \n\n\n"}
{"task_id": "NumpyEval/88", "prompt": "# [start]\n# inverse(a): Calculate a matrix's (multiplicative) inverse.\n# [end]\nimport beatnum as bn\n\ndef inverse_matrix(matrix):\n    # Inverse of a matrix using beatnum and return it.\n    # Ibnut:\n    #   matrix: beatnum numset, shape (n, n)\n    # Output:\n    #   inverse: beatnum numset, shape (n, n)\n", "entry_point": "inverse_matrix", "canonical_solution": ["    return bn.linalg.inverse(matrix)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'linalg_inv'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.matrix([[2,3],[4,5]])), np.matrix([[-2.5,1.5],[2,-1]]))\n    assert np.array_equal(candidate(np.matrix([[2,2],[4,5]])), np.matrix([[2.5,-1],[-2,1]]))\n    assert np.array_equal(candidate(np.matrix([[0,1],[4,5]])), np.matrix([[-1.25,0.25],[1,0]]))\n\n\n"}
{"task_id": "NumpyEval/89", "prompt": "# [start]\n# average(a, axis=None, dtype=None, out=None, keepdims=False): Calculate the given axis's arithmetic average value.\n# [end]\nimport beatnum as bn\n\ndef average_every_3_elements(arr):\n    # Averaging over every 3 elements of a beatnum numset\n    # I have a beatnum numset. I want to create a new numset which is the average over every consecutive triplet of elements. So the new numset will be a third of the size as the original.\n    # Return it\n", "entry_point": "average_every_3_elements", "canonical_solution": ["    return bn.average(arr.change_shape_to(-1, 3), axis=1)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'mean_reshape'\n}\n\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([1,2,3,1,2,3,1,2,3])), np.array([2, 2, 2]))\n    assert np.array_equal(candidate(np.array([1,2,3,1,2,3,2,3,4])), np.array([2, 2, 3]))\n    assert np.array_equal(candidate(np.array([1,2,3,3,4,5,2,3,4])), np.array([2, 4, 3]))\n\n\n"}
{"task_id": "NumpyEval/90", "prompt": "import beatnum as bn\n\ndef prepend_element_to_numset(arr, element):\n    # Prepend element to beatnum numset\n    # Return the numset\n", "entry_point": "prepend_element_to_array", "canonical_solution": ["    return bn.stick(arr, 0, element)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'insert'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[5.], [4.], [3.], [2.], [1.]]), 0), np.array([0, 5., 4., 3., 2., 1.]))\n    assert np.array_equal(candidate(np.array([[5.], [4.], [3.], [2.], [3.]]), 0), np.array([0, 5., 4., 3., 2., 3.]))\n    assert np.array_equal(candidate(np.array([[5.], [4.], [3.], [3.], [3.]]), 0), np.array([0, 5., 4., 3., 3., 3.]))\n    assert np.array_equal(candidate(np.array([[5.], [5.], [3.], [2.], [3.]]), 0), np.array([0, 5., 5., 3., 2., 3.]))\n    assert np.array_equal(candidate(np.array([[1.], [4.], [3.], [2.], [3.]]), 0), np.array([0, 1., 4., 3., 2., 3.]))\n    assert np.array_equal(candidate(np.array([[5.], [4.], [33.], [2.], [3.]]), 0), np.array([0, 5., 4., 33., 2., 3.]))\n    assert np.array_equal(candidate(np.array([[5.], [4.], [3.], [23.], [3.]]), 0), np.array([0, 5., 4., 3., 23., 3.]))\n    assert np.array_equal(candidate(np.array([[5.], [4.], [3.], [21.], [3.]]), 0), np.array([0, 5., 4., 3., 21., 3.]))\n    assert np.array_equal(candidate(np.array([[5.], [4.], [3.], [2.], [34.]]), 0), np.array([0, 5., 4., 3., 2., 34.]))\n    assert np.array_equal(candidate(np.array([[54.], [4.], [3.], [2.], [3.]]), 0), np.array([0, 54., 4., 3., 2., 3.]))\n\n\n"}
{"task_id": "NumpyEval/91", "prompt": "# [start]\n# horizontal_stack(numsets): Stack numsets in horizontal or column wise order.\n# [end]\nimport beatnum as bn\n\na = bn.numset([bn.numset([13.16]), bn.numset([1.58 , 1.2]), bn.numset([13.1]), bn.numset([1. , 2.6])], dtype=object)\n# I need a general way to flatten that numset into a single numset of N elements, with N=every float in all the sub-numsets.\n\nout =", "entry_point": "none", "canonical_solution": [" bn.horizontal_stack(aa)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'hstack'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.array([13.16, 1.58, 1.2, 13.1, 1. , 2.6]))\n\n\n"}
{"task_id": "NumpyEval/92", "prompt": "# [start]\n# find_sorted(a, v, side='left', sorter=None): Find the indices into a sorted numset a such that if the corresponding elements in v were inserted before the indices, the order of a would be preserved.\n# [end]\nimport beatnum as bn\n\nmaster = bn.numset([1,2,3,4,5])\nsearch = bn.numset([4,2,2,3])\n\n# Find indices of a list of values in a beatnum numset\nout =", "entry_point": "none", "canonical_solution": [" bn.find_sorted(master, search)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'searchsorted'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.array([3, 1, 1, 2]))\n\n\n"}
{"task_id": "NumpyEval/93", "prompt": "# [start]\n# get_min(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>): Get the smallest value in a numset or the smallest value along an axis.\n# [end]\nimport beatnum as bn\ndef get_get_minimum_value(arr):\n    # I wish to find and return the minimum value in this 2D numset\n    # The following code is aim to implement it\n", "entry_point": "get_minimum_value", "canonical_solution": ["    return bn.get_min(arr)", "    return values.get_min()", "    return get_min(values.convert_into_one_dim())", "    return bn.amin(values)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'min'\n}\n\n\ndef check(candidate):\n    assert candidate(np.array([[8,2,3,4,5,6], [3,8,5,1,-2,9]])) == -2\n    assert candidate(np.array([[8,2,3,4,4,6], [3,8,3,1,-2,9]])) == -2\n    assert candidate(np.array([[81,2,3,41,5,6], [3,8,5,1,-2,9]])) == -2\n    assert candidate(np.array([[8,2,3,4,15,6], [3,8,5,1,-3,19]])) == -3\n    assert candidate(np.array([[8,12,3,4,35,6], [3,8,5,1,-2,9]])) == -2\n    assert candidate(np.array([[8,2,3,44,5,6], [3,8,5,1,-2,9]])) == -2\n    assert candidate(np.array([[8,2,33,4,5,6], [3,84,5,1,-2,9]])) == -2\n    assert candidate(np.array([[83,2,3,44,5,6], [3,8,5,11,-2,9]])) == -2\n    assert candidate(np.array([[8,12,3,42,5,6], [3,8,5,1,-2,19]])) == -2\n    assert candidate(np.array([[8,12,3,4,5,26], [3,-8,5,1,-2,9]])) == -8\n\n\n"}
{"task_id": "NumpyEval/94", "prompt": "# [start]\n# inverse(a): Calculate a matrix's (multiplicative) inverse.\n# [end]\nimport beatnum as bn\n\nz = bn.numset([ 0, 1, 3, 9, 18 ])\n# What is the inverse of the beatnum cumsum function?\nz[1:] =", "entry_point": "none", "canonical_solution": [" z[:-1]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'slice'\n}\n\n\ndef check():\n    assert np.array_equal(z, [ 0, 0, 1, 3, 9 ])\n\n\n"}
{"task_id": "NumpyEval/95", "prompt": "import beatnum as bn\n\n# How do I create an numset where every entry is the same value?\n# I know beatnum.create_ones() and beatnum.zeros() do this for 1's and 0's, but what about -1?\n# the shape of the numset is (5, 5)\nout =", "entry_point": "none", "canonical_solution": [" bn.full_value_func((5, 5), -1.)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'full'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.full((5, 5), -1.))\n\n\n"}
{"task_id": "NumpyEval/96", "prompt": "# [start]\n# remove_operation(arr, obj, axis=None): Deleted sub-numsets along an axis.\n# [end]\nimport beatnum as bn\n\na = bn.arr_range(12).change_shape_to(3,4)\n# Removing columns with index 1 and 3 in beatnum\n# If you ever want to remove more than one columns, you just pass indices of columns you want removed as a list to bn.remove_operation, like this:\nout =", "entry_point": "none", "canonical_solution": [" bn.remove_operation(a, [1, 3], axis=1)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'delete'\n}\n\n\ndef check():\n    assert np.array_equal(out, np.array([[0, 2], [4, 6], [8, 10]]))\n\n\n"}
{"task_id": "NumpyEval/97", "prompt": "import beatnum as bn\n\nA = bn.numset([1,2,3,4,5,6,7])\nB = bn.numset([2,4,6])\nC = bn.find_sorted(A, B)\n# Check if each element in a beatnum numset is in another numset\n# This problem seems easy but I cannot quite get a nice-looking solution. \n# I have two beatnum numsets (A and B), and I want to get the indices of A where the elements of A are in B and also get the indices of A where the elements are not in B.\nD =", "entry_point": "none", "canonical_solution": [" bn.remove_operation(bn.arr_range(np.alen(A)), C)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'delete_arange_alen'\n}\n\n\ndef check():\n    assert np.array_equal(D, np.array([0, 2, 4, 6]))\n\n\n"}
{"task_id": "NumpyEval/98", "prompt": "# [start]\n# filter_condition(condition, x=None, y=None): filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.\n# [end]\nimport beatnum as bn\n\na = bn.numset([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11],\n       [12, 13, 14]])\n\n# We want row with the first column value is 0\n# and the second colum value is 1\n# Maybe using bn.filter_condition() is better\nb =", "entry_point": "none", "canonical_solution": [" a[bn.filter_condition((a[:,0] == 0) * (a[:,1] == 1))]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'where_equal'\n}\n\n\ndef check():\n    assert np.array_equal(b, np.array([[0, 1, 2]]))\n\n\n"}
{"task_id": "NumpyEval/99", "prompt": "import beatnum as bn\n\na = bn.numset([[[10, 1, 1, 2], [2, 2, 2, 3], [3, 3, 3, 4]],\n              [[1, 1, 1, 2], [2, 2, 2, 3], [3, 3, 3, 4]]])\n\n# Conducting the reverse operation along with the last dimension\n\nb =", "entry_point": "none", "canonical_solution": [" a[:, :, ::-1]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'indice'\n}\n\n\ndef check():\n    assert np.array_equal(b, a[:, :, ::-1])\n\n\n"}
{"task_id": "NumpyEval/100", "prompt": "# [start]\n# get_min(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>): Get the smallest value in a numset or the smallest value along an axis.\n# [end]\nimport beatnum as bn\n\na = bn.numset([[1,11], [3,9], [5,7]])\n# Firstly, We need to find the minimun value of each column with axis 0,\n# Then conduct subtract operation between each element of the column and the minimum value.\nresult =", "entry_point": "none", "canonical_solution": [" a - a.get_min(axis=0)"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'min'\n}\n\n\ndef check():\n    assert np.array_equal(result, a - a.min(axis=0))\n\n\n"}
{"task_id": "NumpyEval/1", "prompt": "import beatnum as bn\n\na = bn.numset([[2,3,2],[5,6,1]])\nb = bn.numset([3,5])\n# How to multiply a nD numset with 1D numset, where len(1D-numset) == len(nD numset)?\n# You need to convert numset b to a (2, 1) shape numset, use None or beatnum.newaxis in the index tuple:\nc =", "entry_point": "none", "canonical_solution": [" a * b[:, bn.newaxis]"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'multiple_newaxis'\n}\n\n\ndef check():\n    assert np.array_equal(c, np.array([[6, 9, 6], [25, 30, 5]]))\n\n\n"}
{"task_id": "NumpyEval/2", "prompt": "# [start]\n# change_shape_to(a, newshape, order='C'): Changes the shape of a numset without affecting its data.\n# switching_places(a, axes=None): Returns the changed numset after reversing or permuting the axes of a numset.\n# [end]\nimport beatnum as bn\n\na = bn.arr_range(8)[:,None].duplicate(8,axis=1)\n# How can I use change_shape_to to divide it into 4 chucks, such that it looks like this:\n# I would like to change_shape_to a to (2, 4, 2, 4) and then switching_places it by (0, 2, 1, 3) to c\nb =", "entry_point": "none", "canonical_solution": [" a.change_shape_to(2,4,2,4)\nc = b.switching_places(0,2,1,3)"], "test": "\n\nMETADATA = {\n    'author': 'msra-v-dazan',\n    'dataset': 'test',\n    'type': 'reshape_transpose'\n}\n\n\ndef check():\n    tmp_b = a.reshape(2, 4, 2, 4)\n    tmp_c = tmp_b.transpose(0, 2, 1, 3)\n    assert np.array_equal(c, tmp_c)\n\n\n"}
{"task_id": "NumpyEval/3", "prompt": "import beatnum as bn\n\ndef get_i_th_index_in_last_dim(arr, i):\n    \"\"\"\n    I would like to piece a beatnum numset to obtain the i-th index in the last dimension.\n    Is there a way I can obtain this piece for any numset without explicitly having to write the numset dimensions?\n    There is ... or Ellipsis, which does exactly this\n    Returns: beatnum numset\n    \"\"\"\n", "entry_point": "get_i_th_index_in_last_dim", "canonical_solution": ["    return arr[...,i]"], "test": "\n\nMETADATA = {\n    'author': 'msra',\n    'dataset': 'test',\n    'type': 'slicing'\n}\n\n\ndef check(candidate):\n    assert np.array_equal(candidate(np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]]), 1), np.array([2,6,10]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [5,6,7,8], [9,10,11,12]]), 1), np.array([2,6,10]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [15,6,7,8], [9,10,11,12]]), 1), np.array([2,6,10]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [15,16,7,8], [9,10,11,12]]), 1), np.array([2,16,10]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [15,16,7,8], [9,110,11,12]]), 1), np.array([2,16,110]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [15,16,7,8], [9,110,111,12]]), 1), np.array([2,16,110]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [15,16,7,8], [9,110,111,112]]), 1), np.array([2,16,110]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [15,16,7,8], [19,110,111,112]]), 1), np.array([2,16,110]))\n    assert np.array_equal(candidate(np.array([[10,2,3,4], [15,16,17,8], [19,110,111,112]]), 1), np.array([2,16,110]))\n    assert np.array_equal(candidate(np.array([[10,2,23,4], [15,16,17,8], [19,110,111,112]]), 1), np.array([2,16,110]))\n\n\n"}
