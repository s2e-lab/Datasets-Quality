{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "pk = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_path = '../Datasets/pandasNumpyEval/offical_numpy.jsonl'\n",
    "result_data_path = '../results/pandasNumpyEval_numpy_heuristic_results.json'\n",
    "combined_data_path = '../Combined_Datasets/pandasNumpyEval_numpy_combined.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = []\n",
    "with open(original_data_path) as f:\n",
    "    for line in f:\n",
    "        original_data.append(json.loads(line))\n",
    "\n",
    "len(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = []\n",
    "with open(result_data_path) as f:\n",
    "    data = json.load(f)\n",
    "    extra = 0\n",
    "    for i in range(len(data)):\n",
    "        if extra > 0:\n",
    "            extra -= 1\n",
    "            continue\n",
    "        new_data = data[i]\n",
    "        new_comment= data[i]['nl']['comment']\n",
    "        new_heuristics = data[i]['Heuristic']\n",
    "        for j in range(i+1, len(data)):\n",
    "            if data[i]['nl']['id'] == data[j]['nl']['id'] :\n",
    "                new_comment = new_comment+\"\\n\"+ data[i]['nl']['comment']\n",
    "                new_heuristics = new_heuristics + data[j]['Heuristic']\n",
    "                extra += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        new_heuristics = list(set(new_heuristics))\n",
    "        new_data['nl']['comment'] = new_comment\n",
    "        new_data['Heuristic'] = new_heuristics\n",
    "        result_data.append(new_data)\n",
    "\n",
    "len(result_data)\n",
    "assert len(result_data) == len(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistical_significance_samples_ids(population_size, confidence_interval, error_margin):\n",
    "    \"\"\"\n",
    "    Get the sample ids for the statistical significance test.\n",
    "    \"\"\"\n",
    "    z_score = 0\n",
    "    if confidence_interval == 0.95:\n",
    "        z_score = 1.96\n",
    "    elif confidence_interval == 0.99:\n",
    "        z_score = 2.58\n",
    "    no_top = (z_score ** 2) * 0.25\n",
    "    no_bottom = error_margin ** 2\n",
    "    no = no_top / no_bottom\n",
    "    sample_size = math.ceil(no / (1 + no / population_size))\n",
    "\n",
    "    # Generate random sample IDs\n",
    "    sample_ids = random.sample(range(0, population_size), int(sample_size))\n",
    "    \n",
    "    return sample_ids\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "print(len(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_heuristic_list(heuristic_list):\n",
    "    result = []\n",
    "    for heuristic in heuristic_list:\n",
    "        result.append(int(heuristic.replace('H', '')))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = []\n",
    "for i in range(len(original_data)):\n",
    "    if i not in sample_ids:\n",
    "        continue\n",
    "    original = original_data[i]\n",
    "    result = result_data[i]\n",
    "    original['nl'] = result['nl']['comment'] \n",
    "    combined_data.append({\n",
    "        \"model\": \"datasets_study.problem\",\n",
    "        \"pk\": pk,\n",
    "        \"fields\": {\n",
    "            \"source_dataset\": \"CoderEval4Python\",\n",
    "            \"prompt_id\": result['nl']['id'],\n",
    "            \"content\": original,\n",
    "            \"language\": \"py\",\n",
    "            \"problems\": fix_heuristic_list(result['Heuristic']),\n",
    "        }\n",
    "\n",
    "    })\n",
    "    pk += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(combined_data_path, 'w') as f:\n",
    "    json.dump(combined_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
