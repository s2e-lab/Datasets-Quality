{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "pk = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistical_significance_samples_ids(population_size, confidence_interval, error_margin):\n",
    "    \"\"\"\n",
    "    Get the sample ids for the statistical significance test.\n",
    "    \"\"\"\n",
    "    z_score = 0\n",
    "    if confidence_interval == 0.95:\n",
    "        z_score = 1.96\n",
    "    elif confidence_interval == 0.99:\n",
    "        z_score = 2.58\n",
    "    no_top = (z_score ** 2) * 0.25\n",
    "    no_bottom = error_margin ** 2\n",
    "    no = no_top / no_bottom\n",
    "    sample_size = math.ceil(no / (1 + no / population_size))\n",
    "\n",
    "    # Generate random sample IDs\n",
    "    sample_ids = random.sample(range(0, population_size), int(sample_size))\n",
    "    \n",
    "    return sample_ids\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_heuristic_list(heuristic_list):\n",
    "    result = []\n",
    "    for heuristic in heuristic_list:\n",
    "        result.append(int(heuristic.replace('H', '')))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_data_path = '../Combined_Datasets/datasets_study_prompts.json'\n",
    "combined_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATASET = [\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/HumanEval/human-eval-v2-20210705.jsonl\",\n",
    "    \"Output_Path\": \"../results/HumanEval_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/mbxp/mbpp_release_v1.jsonl\",\n",
    "    \"Output_Path\": \"../results/mbxp_python_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/mbxp/mbjp_release_v1.jsonl\",\n",
    "    \"Output_Path\": \"../results/mbxp_java_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/mbxp_humaneval/HumanEval.jsonl\",\n",
    "    \"Output_Path\": \"../results/mbxp_humaneval_python_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/mbxp_humaneval/HumanEval_java_v1.1.jsonl\",\n",
    "    \"Output_Path\": \"../results/mbxp_humaneval_java_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/mbxp_mathqa/mathqa-test-python_v1.jsonl\",\n",
    "    \"Output_Path\": \"../results/mbxp_mathqa_python_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/mbxp_mathqa/mathqa-test-java_v1.jsonl\",\n",
    "    \"Output_Path\": \"../results/mbxp_mathqa_java_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/ODEX/en_test.jsonl\",\n",
    "    # \"Output_Path\": \"../results/odex_en_heuristic_results.json\",\n",
    "    # \"jsonl\": True,\n",
    "    # },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/pandasNumpyEval/offical_numpy.jsonl\",\n",
    "    \"Output_Path\": \"../results/pandasNumpyEval_numpy_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/pandasNumpyEval/offical_pandas.jsonl\",\n",
    "    \"Output_Path\": \"../results/pandasNumpyEval_pandas_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/CoderEval/CoderEval4Python.json\",\n",
    "    # \"Output_Path\": \"../results/CoderEval4Python__heuristic.json\",\n",
    "    # \"jsonl\": False,\n",
    "    # },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/MCoNaLa/test/flores101/es_test_to_en.json\",\n",
    "    # \"Output_Path\": \"../results/MCoNaLa_es_test_to_en__heuristic.json\",\n",
    "    # \"jsonl\": False,\n",
    "    # },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/MCoNaLa/test/flores101/ja_test_to_en.json\",\n",
    "    # \"Output_Path\": \"../results/MCoNaLa_ja_test_to_en__heuristic.json\",\n",
    "    # \"jsonl\": False,\n",
    "    # },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/MCoNaLa/test/flores101/ru_test_to_en.json\",\n",
    "    # \"Output_Path\": \"../results/MCoNaLa_ru_test_to_en__heuristic.json\",\n",
    "    # \"jsonl\": False,\n",
    "    # },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/TorchDataEval/real_beatnum_eval_v3_human_labelled.jsonl\",\n",
    "    \"Output_Path\": \"../results/real_beatnum_eval_v3_human_labelled_heuristic.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/TorchDataEval/real_monkey_eval_v3_human_labelled.jsonl\",\n",
    "    \"Output_Path\": \"../results/real_monkey_eval_v3_human_labelled_heuristic.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/TorchDataEval/real_torchdata_eval_v3_human_labelled.jsonl\",\n",
    "    \"Output_Path\": \"../results/real_torchdata_eval_v3_human_labelled_heuristic.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/TorchDataEval/real_torchdata_eval_v3_human_labelled_make_sense.jsonl\",\n",
    "    \"Output_Path\": \"../results/real_torchdata_eval_v3_human_labelled_make_sense_heuristic.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/CodeComplex/extend_data.jsonl\",\n",
    "    # \"Output_Path\": \"../results/CodeComplex_extend_data_heuristic.json\",\n",
    "    # \"jsonl\": True,\n",
    "    # },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/CodeComplex/new_data.jsonl\",\n",
    "    # \"Output_Path\": \"../results/CodeComplex_new_data_heuristic.json\",\n",
    "    # \"jsonl\": True,\n",
    "    # },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/HumanEval-Infilling/HumanEval-MultiLineInfilling.jsonl\",\n",
    "    \"Output_Path\": \"../results/HumanEval-MultiLineInfilling_heuristic.json\",\n",
    "    \"jsonl\": True,\n",
    "    },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/JigsawDataset/PandasEval1.json\",\n",
    "    # \"Output_Path\": \"../results/JigsawDataset_pandas_eval1_heuristic.json\",\n",
    "    # \"jsonl\": False,\n",
    "    # },\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/JigsawDataset/PandasEval2.json\",\n",
    "    # \"Output_Path\": \"../results/JigsawDataset_pandas_eval2_heuristic.json\",\n",
    "    # \"jsonl\": False,\n",
    "    # },\n",
    "    {\n",
    "    \"Source_Path\": \"../datasets/MBPP/sanitized-mbpp.json\",\n",
    "    \"Output_Path\": \"../results/sanitized-mbpp_heuristic.json\",\n",
    "    \"jsonl\": False,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanEval/human-eval-v2-20210705\n",
      "164\n",
      "164\n",
      "132\n",
      "py\n",
      "mbxp/mbpp_release_v1\n",
      "974\n",
      "974\n",
      "396\n",
      "py\n",
      "mbxp/mbjp_release_v1\n",
      "966\n",
      "966\n",
      "395\n",
      "py\n",
      "mbxp_humaneval/HumanEval\n",
      "164\n",
      "164\n",
      "132\n",
      "py\n",
      "mbxp_humaneval/HumanEval_java_v1\n",
      "161\n",
      "161\n",
      "130\n",
      "java\n",
      "mbxp_mathqa/mathqa-test-python_v1\n",
      "1883\n",
      "1883\n",
      "492\n",
      "py\n",
      "mbxp_mathqa/mathqa-test-java_v1\n",
      "1883\n",
      "1883\n",
      "492\n",
      "java\n",
      "pandasNumpyEval/offical_numpy\n",
      "101\n",
      "101\n",
      "88\n",
      "py\n",
      "pandasNumpyEval/offical_pandas\n",
      "101\n",
      "101\n",
      "88\n",
      "py\n",
      "TorchDataEval/real_beatnum_eval_v3_human_labelled\n",
      "101\n",
      "101\n",
      "88\n",
      "py\n",
      "TorchDataEval/real_monkey_eval_v3_human_labelled\n",
      "101\n",
      "101\n",
      "88\n",
      "py\n",
      "TorchDataEval/real_torchdata_eval_v3_human_labelled\n",
      "50\n",
      "50\n",
      "47\n",
      "py\n",
      "TorchDataEval/real_torchdata_eval_v3_human_labelled_make_sense\n",
      "50\n",
      "50\n",
      "47\n",
      "py\n",
      "HumanEval-Infilling/HumanEval-MultiLineInfilling\n",
      "5815\n",
      "5815\n",
      "598\n",
      "py\n",
      "MBPP/sanitized-mbpp\n",
      "427\n",
      "427\n",
      "261\n",
      "py\n"
     ]
    }
   ],
   "source": [
    "for datasets in TARGET_DATASET:\n",
    "    original_data_path = datasets['Source_Path']\n",
    "    result_data_path = datasets['Output_Path']\n",
    "    dataset_name = \"/\".join(datasets['Source_Path'].split('/')[2:]).split('.')[0]\n",
    "    print(dataset_name)\n",
    "\n",
    "    original_data = []\n",
    "    if datasets['jsonl']:\n",
    "        with open(original_data_path) as f:\n",
    "            for line in f:\n",
    "                original_data.append(json.loads(line))\n",
    "    else:\n",
    "        with open(original_data_path) as f:\n",
    "            original_data = json.load(f)\n",
    "\n",
    "    print(len(original_data))\n",
    "\n",
    "    result_data = []\n",
    "    with open(result_data_path) as f:\n",
    "        data = json.load(f)\n",
    "        extra = 0\n",
    "        for i in range(len(data)):\n",
    "            if extra > 0:\n",
    "                extra -= 1\n",
    "                continue\n",
    "            new_data = data[i]\n",
    "            new_comment= data[i]['nl']['comment']\n",
    "            new_heuristics = data[i]['Heuristic']\n",
    "            for j in range(i+1, len(data)):\n",
    "                if data[i]['nl']['id'] == data[j]['nl']['id'] :\n",
    "                    new_comment = new_comment+\"\\n\"+ data[j]['nl']['comment']\n",
    "                    new_heuristics = new_heuristics + data[j]['Heuristic']\n",
    "                    extra += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            new_heuristics = list(set(new_heuristics))\n",
    "            new_data['nl']['comment'] = new_comment\n",
    "            new_data['Heuristic'] = new_heuristics\n",
    "            result_data.append(new_data)\n",
    "\n",
    "    print(len(result_data))\n",
    "    assert len(result_data) == len(original_data)\n",
    "    sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "    print(len(sample_ids))\n",
    "\n",
    "    language = \"py\"\n",
    "    if \"java\" in dataset_name.lower():\n",
    "        language = \"java\"\n",
    "    print(language)\n",
    "    for i in range(len(original_data)):\n",
    "        if i not in sample_ids:\n",
    "            continue\n",
    "        original = original_data[i]\n",
    "        result = result_data[i]\n",
    "        original['nl'] = result['nl']['comment'] \n",
    "        combined_data.append({\n",
    "            \"model\": \"datasets_study.prompt\",\n",
    "            \"pk\": pk,\n",
    "            \"fields\": {\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"prompt_id\": result['nl']['id'],\n",
    "                \"content\": original,\n",
    "                \"language\": language,\n",
    "                \"problems\": fix_heuristic_list(result['Heuristic']),\n",
    "            }\n",
    "\n",
    "        })\n",
    "        pk += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODEX/en_test\n",
      "439\n",
      "439\n",
      "265\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"Source_Path\": \"../datasets/ODEX/en_test.jsonl\",\n",
    "    \"Output_Path\": \"../results/odex_en_heuristic_results.json\",\n",
    "    \"jsonl\": True,\n",
    "    }\n",
    "\n",
    "original_data_path = dataset[\"Source_Path\"]\n",
    "result_data_path = dataset[\"Output_Path\"]\n",
    "dataset_name = \"/\".join(dataset[\"Source_Path\"].split(\"/\")[2:]).split(\".\")[0]\n",
    "print(dataset_name)\n",
    "\n",
    "original_data = []\n",
    "if dataset[\"jsonl\"]:\n",
    "    with open(original_data_path) as f:\n",
    "        for line in f:\n",
    "            original_data.append(json.loads(line))\n",
    "else:\n",
    "    with open(original_data_path) as f:\n",
    "        original_data = json.load(f)\n",
    "\n",
    "print(len(original_data))\n",
    "\n",
    "result_data = []\n",
    "with open(result_data_path) as f:\n",
    "    data = json.load(f)\n",
    "    extra = 0\n",
    "    for i in range(len(data)):\n",
    "        if extra > 0:\n",
    "            extra -= 1\n",
    "            continue\n",
    "        new_data = data[i]\n",
    "        new_comment = data[i][\"nl\"][\"comment\"]\n",
    "        new_heuristics = data[i][\"Heuristic\"]\n",
    "        # for j in range(i + 1, len(data)):\n",
    "        #     if data[i][\"nl\"][\"id\"] == data[j][\"nl\"][\"id\"]:\n",
    "        #         new_comment = new_comment + \"\\n\" + data[i][\"nl\"][\"comment\"]\n",
    "        #         new_heuristics = new_heuristics + data[j][\"Heuristic\"]\n",
    "        #         extra += 1\n",
    "        #     else:\n",
    "        #         break\n",
    "        new_heuristics = list(set(new_heuristics))\n",
    "        new_data[\"nl\"][\"comment\"] = new_comment\n",
    "        new_data[\"Heuristic\"] = new_heuristics\n",
    "        result_data.append(new_data)\n",
    "\n",
    "print(len(result_data))\n",
    "assert len(result_data) == len(original_data)\n",
    "sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "print(len(sample_ids))\n",
    "\n",
    "\n",
    "for i in range(len(original_data)):\n",
    "    if i not in sample_ids:\n",
    "        continue\n",
    "    original = original_data[i]\n",
    "    result = result_data[i]\n",
    "    original[\"nl\"] = result[\"nl\"][\"comment\"]\n",
    "    combined_data.append(\n",
    "        {\n",
    "            \"model\": \"datasets_study.prompt\",\n",
    "            \"pk\": pk,\n",
    "            \"fields\": {\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"prompt_id\": result[\"nl\"][\"id\"],\n",
    "                \"content\": original,\n",
    "                \"language\": \"java\",\n",
    "                \"problems\": fix_heuristic_list(result[\"Heuristic\"]),\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    pk += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoderEval/CoderEval4Python\n",
      "230\n",
      "230\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"Source_Path\": \"../datasets/CoderEval/CoderEval4Python.json\",\n",
    "    \"Output_Path\": \"../results/CoderEval4Python__heuristic.json\",\n",
    "    \"jsonl\": False,\n",
    "    }\n",
    "\n",
    "original_data_path = dataset[\"Source_Path\"]\n",
    "result_data_path = dataset[\"Output_Path\"]\n",
    "dataset_name = \"/\".join(dataset[\"Source_Path\"].split(\"/\")[2:]).split(\".\")[0]\n",
    "print(dataset_name)\n",
    "\n",
    "original_data = []\n",
    "if dataset[\"jsonl\"]:\n",
    "    with open(original_data_path) as f:\n",
    "        for line in f:\n",
    "            original_data.append(json.loads(line))\n",
    "else:\n",
    "    with open(original_data_path) as f:\n",
    "        original_data = json.load(f)[\"RECORDS\"]\n",
    "\n",
    "print(len(original_data))\n",
    "\n",
    "result_data = []\n",
    "with open(result_data_path) as f:\n",
    "    data = json.load(f)\n",
    "    extra = 0\n",
    "    for i in range(len(data)):\n",
    "        if extra > 0:\n",
    "            extra -= 1\n",
    "            continue\n",
    "        new_data = data[i]\n",
    "        new_comment = data[i][\"nl\"][\"comment\"]\n",
    "        new_heuristics = data[i][\"Heuristic\"]\n",
    "        for j in range(i + 1, len(data)):\n",
    "            if data[i][\"nl\"][\"id\"] == data[j][\"nl\"][\"id\"]:\n",
    "                new_comment = new_comment + \"\\n\" + data[i][\"nl\"][\"comment\"]\n",
    "                new_heuristics = new_heuristics + data[j][\"Heuristic\"]\n",
    "                extra += 1\n",
    "            else:\n",
    "                break\n",
    "        new_heuristics = list(set(new_heuristics))\n",
    "        new_data[\"nl\"][\"comment\"] = new_comment\n",
    "        new_data[\"Heuristic\"] = new_heuristics\n",
    "        result_data.append(new_data)\n",
    "\n",
    "print(len(result_data))\n",
    "assert len(result_data) == len(original_data)\n",
    "sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "print(len(sample_ids))\n",
    "\n",
    "\n",
    "for i in range(len(original_data)):\n",
    "    if i not in sample_ids:\n",
    "        continue\n",
    "    original = original_data[i]\n",
    "    result = result_data[i]\n",
    "    original[\"nl\"] = result[\"nl\"][\"comment\"]\n",
    "    combined_data.append(\n",
    "        {\n",
    "            \"model\": \"datasets_study.prompt\",\n",
    "            \"pk\": pk,\n",
    "            \"fields\": {\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"prompt_id\": result[\"nl\"][\"id\"],\n",
    "                \"content\": original,\n",
    "                \"language\": \"py\",\n",
    "                \"problems\": fix_heuristic_list(result[\"Heuristic\"]),\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    pk += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeComplex/extend_data\n",
      "1003\n",
      "605\n",
      "401\n"
     ]
    }
   ],
   "source": [
    "dataset = { \"Source_Path\": \"../datasets/CodeComplex/extend_data.jsonl\",\n",
    "    \"Output_Path\": \"../results/CodeComplex_extend_data_heuristic.json\",\n",
    "    \"jsonl\": True,\n",
    "    }\n",
    "\n",
    "original_data_path = dataset[\"Source_Path\"]\n",
    "result_data_path = dataset[\"Output_Path\"]\n",
    "dataset_name = \"/\".join(dataset[\"Source_Path\"].split(\"/\")[2:]).split(\".\")[0]\n",
    "print(dataset_name)\n",
    "\n",
    "original_data = []\n",
    "if dataset[\"jsonl\"]:\n",
    "    with open(original_data_path) as f:\n",
    "        for line in f:\n",
    "            original_data.append(json.loads(line))\n",
    "else:\n",
    "    with open(original_data_path) as f:\n",
    "        original_data = json.load(f)[\"RECORDS\"]\n",
    "\n",
    "print(len(original_data))\n",
    "\n",
    "result_data = []\n",
    "with open(result_data_path) as f:\n",
    "    data = json.load(f)\n",
    "    extra = 0\n",
    "    for i in range(len(data)):\n",
    "        if extra > 0:\n",
    "            extra -= 1\n",
    "            continue\n",
    "        new_data = data[i]\n",
    "        new_comment = data[i][\"nl\"][\"comment\"]\n",
    "        new_heuristics = data[i][\"Heuristic\"]\n",
    "        for j in range(i + 1, len(data)):\n",
    "            if data[i][\"nl\"][\"id\"] == data[j][\"nl\"][\"id\"]:\n",
    "                new_comment = new_comment + \"\\n\" + data[i][\"nl\"][\"comment\"]\n",
    "                new_heuristics = new_heuristics + data[j][\"Heuristic\"]\n",
    "                extra += 1\n",
    "            else:\n",
    "                break\n",
    "        new_heuristics = list(set(new_heuristics))\n",
    "        new_data[\"nl\"][\"comment\"] = new_comment\n",
    "        new_data[\"Heuristic\"] = new_heuristics\n",
    "        result_data.append(new_data)\n",
    "\n",
    "print(len(result_data))\n",
    "# assert len(result_data) == len(original_data)\n",
    "sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "print(len(sample_ids))\n",
    "\n",
    "\n",
    "for i in range(len(original_data)):\n",
    "    if i not in sample_ids:\n",
    "        continue\n",
    "    original = original_data[i]\n",
    "    for data in result_data:\n",
    "        if data[\"nl\"][\"id\"] == i:\n",
    "            result = data\n",
    "            break\n",
    "    original[\"nl\"] = result[\"nl\"][\"comment\"]\n",
    "    combined_data.append(\n",
    "        {\n",
    "            \"model\": \"datasets_study.prompt\",\n",
    "            \"pk\": pk,\n",
    "            \"fields\": {\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"prompt_id\": result[\"nl\"][\"id\"],\n",
    "                \"content\": original,\n",
    "                \"language\": \"java\",\n",
    "                \"problems\": fix_heuristic_list(result[\"Heuristic\"]),\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    pk += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeComplex/new_data\n",
      "4517\n",
      "2529\n",
      "581\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"Source_Path\": \"../datasets/CodeComplex/new_data.json\",\n",
    "    \"Output_Path\": \"../results/CodeComplex_new_data_heuristic.json\",\n",
    "    \"jsonl\": False,\n",
    "    }\n",
    "\n",
    "original_data_path = dataset[\"Source_Path\"]\n",
    "result_data_path = dataset[\"Output_Path\"]\n",
    "dataset_name = \"/\".join(dataset[\"Source_Path\"].split(\"/\")[2:]).split(\".\")[0]\n",
    "print(dataset_name)\n",
    "\n",
    "original_data = []\n",
    "if dataset[\"jsonl\"]:\n",
    "    with open(original_data_path) as f:\n",
    "        for line in f:\n",
    "            original_data.append(json.loads(line))\n",
    "else:\n",
    "    with open(original_data_path) as f:\n",
    "        original_data = json.load(f)\n",
    "\n",
    "print(len(original_data))\n",
    "\n",
    "result_data = []\n",
    "with open(result_data_path) as f:\n",
    "    data = json.load(f)\n",
    "    extra = 0\n",
    "    for i in range(len(data)):\n",
    "        if extra > 0:\n",
    "            extra -= 1\n",
    "            continue\n",
    "        new_data = data[i]\n",
    "        new_comment = data[i][\"nl\"][\"comment\"]\n",
    "        new_heuristics = data[i][\"Heuristic\"]\n",
    "        for j in range(i + 1, len(data)):\n",
    "            if data[i][\"nl\"][\"id\"] == data[j][\"nl\"][\"id\"]:\n",
    "                new_comment = new_comment + \"\\n\" + data[i][\"nl\"][\"comment\"]\n",
    "                new_heuristics = new_heuristics + data[j][\"Heuristic\"]\n",
    "                extra += 1\n",
    "            else:\n",
    "                break\n",
    "        new_heuristics = list(set(new_heuristics))\n",
    "        new_data[\"nl\"][\"comment\"] = new_comment\n",
    "        new_data[\"Heuristic\"] = new_heuristics\n",
    "        result_data.append(new_data)\n",
    "\n",
    "print(len(result_data))\n",
    "# assert len(result_data) == len(original_data)\n",
    "sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "print(len(sample_ids))\n",
    "\n",
    "\n",
    "for i in range(len(original_data)):\n",
    "    if i not in sample_ids:\n",
    "        continue\n",
    "    original = original_data[i]\n",
    "    for data in result_data:\n",
    "        if data[\"nl\"][\"id\"] == i:\n",
    "            result = data\n",
    "            break\n",
    "    original[\"nl\"] = result[\"nl\"][\"comment\"]\n",
    "    combined_data.append(\n",
    "        {\n",
    "            \"model\": \"datasets_study.prompt\",\n",
    "            \"pk\": pk,\n",
    "            \"fields\": {\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"prompt_id\": result[\"nl\"][\"id\"],\n",
    "                \"content\": original,\n",
    "                \"language\": \"java\",\n",
    "                \"problems\": fix_heuristic_list(result[\"Heuristic\"]),\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    pk += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JigsawDataset/PandasEval1\n",
      "68\n",
      "68\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"Source_Path\": \"../datasets/JigsawDataset/PandasEval1.json\",\n",
    "    \"Output_Path\": \"../results/JigsawDataset_pandas_eval1_heuristic.json\",\n",
    "    \"jsonl\": False,\n",
    "    }\n",
    "    # {\n",
    "    # \"Source_Path\": \"../datasets/JigsawDataset/PandasEval2.json\",\n",
    "    # \"Output_Path\": \"../results/JigsawDataset_pandas_eval2_heuristic.json\",\n",
    "    # \"jsonl\": False,\n",
    "    # },\n",
    "original_data_path = dataset[\"Source_Path\"]\n",
    "result_data_path = dataset[\"Output_Path\"]\n",
    "dataset_name = \"/\".join(dataset[\"Source_Path\"].split(\"/\")[2:]).split(\".\")[0]\n",
    "print(dataset_name)\n",
    "\n",
    "original_data = []\n",
    "if dataset[\"jsonl\"]:\n",
    "    with open(original_data_path) as f:\n",
    "        for line in f:\n",
    "            original_data.append(json.loads(line))\n",
    "else:\n",
    "    with open(original_data_path) as f:\n",
    "        original_data = json.load(f)\n",
    "\n",
    "print(len(original_data))\n",
    "\n",
    "result_data = []\n",
    "with open(result_data_path) as f:\n",
    "    data = json.load(f)\n",
    "    extra = 0\n",
    "    for i in range(len(data)):\n",
    "        if extra > 0:\n",
    "            extra -= 1\n",
    "            continue\n",
    "        new_data = data[i]\n",
    "        new_comment = data[i][\"nl\"][\"comment\"]\n",
    "        new_heuristics = data[i][\"Heuristic\"]\n",
    "        for j in range(i + 1, len(data)):\n",
    "            if data[i][\"nl\"][\"id\"] == data[j][\"nl\"][\"id\"]:\n",
    "                new_comment = new_comment + \"\\n\" + data[i][\"nl\"][\"comment\"]\n",
    "                new_heuristics = new_heuristics + data[j][\"Heuristic\"]\n",
    "                extra += 1\n",
    "            else:\n",
    "                break\n",
    "        new_heuristics = list(set(new_heuristics))\n",
    "        new_data[\"nl\"][\"comment\"] = new_comment\n",
    "        new_data[\"Heuristic\"] = new_heuristics\n",
    "        result_data.append(new_data)\n",
    "\n",
    "print(len(result_data))\n",
    "assert len(result_data) == len(original_data)\n",
    "sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "print(len(sample_ids))\n",
    "\n",
    "\n",
    "for i in range(len(original_data)):\n",
    "    if i not in sample_ids:\n",
    "        continue\n",
    "\n",
    "    original = original_data[str(i)]\n",
    "    result = result_data[i]\n",
    "    original[\"nl\"] = result[\"nl\"][\"comment\"]\n",
    "    combined_data.append(\n",
    "        {\n",
    "            \"model\": \"datasets_study.prompt\",\n",
    "            \"pk\": pk,\n",
    "            \"fields\": {\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"prompt_id\": result[\"nl\"][\"id\"],\n",
    "                \"content\": original,\n",
    "                \"language\": \"py\",\n",
    "                \"problems\": fix_heuristic_list(result[\"Heuristic\"]),\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    pk += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JigsawDataset/PandasEval2\n",
      "21\n",
      "21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "dataset =  {\n",
    "    \"Source_Path\": \"../datasets/JigsawDataset/PandasEval2.json\",\n",
    "    \"Output_Path\": \"../results/JigsawDataset_pandas_eval2_heuristic.json\",\n",
    "    \"jsonl\": False,\n",
    "    }\n",
    "original_data_path = dataset[\"Source_Path\"]\n",
    "result_data_path = dataset[\"Output_Path\"]\n",
    "dataset_name = \"/\".join(dataset[\"Source_Path\"].split(\"/\")[2:]).split(\".\")[0]\n",
    "print(dataset_name)\n",
    "\n",
    "original_data = []\n",
    "if dataset[\"jsonl\"]:\n",
    "    with open(original_data_path) as f:\n",
    "        for line in f:\n",
    "            original_data.append(json.loads(line))\n",
    "else:\n",
    "    with open(original_data_path) as f:\n",
    "        original_data = json.load(f)\n",
    "\n",
    "print(len(original_data))\n",
    "\n",
    "result_data = []\n",
    "with open(result_data_path) as f:\n",
    "    data = json.load(f)\n",
    "    extra = 0\n",
    "    for i in range(len(data)):\n",
    "        if extra > 0:\n",
    "            extra -= 1\n",
    "            continue\n",
    "        new_data = data[i]\n",
    "        new_comment = data[i][\"nl\"][\"comment\"]\n",
    "        new_heuristics = data[i][\"Heuristic\"]\n",
    "        for j in range(i + 1, len(data)):\n",
    "            if data[i][\"nl\"][\"id\"] == data[j][\"nl\"][\"id\"]:\n",
    "                new_comment = new_comment + \"\\n\" + data[i][\"nl\"][\"comment\"]\n",
    "                new_heuristics = new_heuristics + data[j][\"Heuristic\"]\n",
    "                extra += 1\n",
    "            else:\n",
    "                break\n",
    "        new_heuristics = list(set(new_heuristics))\n",
    "        new_data[\"nl\"][\"comment\"] = new_comment\n",
    "        new_data[\"Heuristic\"] = new_heuristics\n",
    "        result_data.append(new_data)\n",
    "\n",
    "print(len(result_data))\n",
    "assert len(result_data) == len(original_data)\n",
    "sample_ids = get_statistical_significance_samples_ids(len(original_data), 0.99, 0.05)\n",
    "print(len(sample_ids))\n",
    "\n",
    "\n",
    "for i in range(len(original_data)):\n",
    "    if i not in sample_ids:\n",
    "        continue\n",
    "\n",
    "    original = original_data[str(i)]\n",
    "    result = result_data[i]\n",
    "    original[\"nl\"] = result[\"nl\"][\"comment\"]\n",
    "    combined_data.append(\n",
    "        {\n",
    "            \"model\": \"datasets_study.prompt\",\n",
    "            \"pk\": pk,\n",
    "            \"fields\": {\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"prompt_id\": result[\"nl\"][\"id\"],\n",
    "                \"content\": original,\n",
    "                \"language\": \"py\",\n",
    "                \"problems\": fix_heuristic_list(result[\"Heuristic\"]),\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    pk += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(combined_data_path, 'w') as f:\n",
    "    json.dump(combined_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
